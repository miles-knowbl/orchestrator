{
  "id": "observe",
  "name": "observe",
  "version": "1.0.0",
  "description": "Strategic orientation at loop start — grounding in reality, mapping opportunities for leverage",
  "phase": "INIT",
  "category": "meta",
  "content": "# Observe\n\nEstablish situational awareness and surface high-leverage opportunities before any loop begins.\n\n## When to Use\n\n**Always** — this skill (or its grounding hook) runs at the start of every loop execution. It answers four questions:\n\n1. **Where are we at?** — Current state across all dimensions\n2. **Where are we going?** — Dream state at the appropriate tier\n3. **How do we get there faster?** — Progress assessment and acceleration paths\n4. **Are there any secret exits?** — 100x leverage moves, paradigm shifts, compression opportunities\n\n## Two Modes\n\n### Mode 1: Grounding (Pre-Execution Hook)\n\nRuns automatically before any loop starts. Surfaces:\n- Current reality (git state, memory, previous executions)\n- Relevant dream states (org → domain → system → module)\n- Progress toward dream state\n- Active blockers or dependencies\n\n**Output:** Brief situational summary displayed to user and available to loop\n\n### Mode 2: Opportunity Mapping (This Skill)\n\nRuns as first skill in INIT phase. Actively searches for:\n- Case-based reasoning matches (similar past situations)\n- Bundling opportunities (solve N problems with 1 system)\n- Reframing candidates (different perspective compresses timeline)\n- Paradigm shifts (100x leverage moves)\n\n**Output:** Opportunity assessment (may be \"nothing significant\" — that's valid)\n\n---\n\n## Reference Requirements\n\n| Reference | Purpose | When Needed |\n|-----------|---------|-------------|\n| [opportunity-types.md](references/opportunity-types.md) | Taxonomy of leverage opportunities | Always |\n| [case-matching.md](references/case-matching.md) | How to match current situation to past patterns | When memory has patterns |\n\n---\n\n## Required Deliverables\n\n| Deliverable | Location | Condition |\n|-------------|----------|-----------|\n| Situational Summary | Loop state context | Always |\n| Opportunity Assessment | Loop state context | Always (even if \"none found\") |\n| Decision Record | Memory ADR | When significant opportunity identified |\n\n---\n\n## Grounding Protocol\n\n### 1. Load Context Hierarchy\n\nLoad dream states in order, stopping at the tier relevant to this loop:\n\n```\n1. Organization: ~/workspaces/{org}/.claude/DREAM-STATE.md\n2. Domain:       ~/workspaces/{org}/.claude/domains/{domain}/DREAM-STATE.md\n3. System:       {project}/.claude/DREAM-STATE.md\n4. Module:       {project}/src/{module}/DREAM-STATE.md (if module-scoped)\n```\n\nEach tier provides:\n- Vision (where we're going)\n- Checklists (what remains)\n- Progress (how far we've come)\n- Patterns (what we've learned)\n\n### 2. Assess Current State\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│ CURRENT STATE ASSESSMENT                                     │\n├─────────────────────────────────────────────────────────────┤\n│ Git State                                                    │\n│   Branch: {current branch}                                   │\n│   Uncommitted: {Y/N} ({file count} files)                   │\n│   Last commit: {message} ({time ago})                       │\n│                                                              │\n│ Previous Execution                                           │\n│   Last loop: {loop name} @ {phase}                          │\n│   Outcome: {success/incomplete/failed}                      │\n│   Time since: {duration}                                    │\n│                                                              │\n│ Memory State                                                 │\n│   Patterns: {count} ({recent count} recent)                 │\n│   Decisions: {count}                                        │\n│   Calibration: {adjustment summary}                         │\n│                                                              │\n│ Dream State Progress                                         │\n│   {tier}: {done}/{total} ({percentage}%)                    │\n│   Next milestone: {description}                             │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### 3. Surface Blockers\n\nCheck for:\n- Incomplete previous executions (should resume or abandon?)\n- Uncommitted work (should commit first?)\n- Failed gates from previous runs (unresolved issues?)\n- Dependency gaps (missing prerequisites?)\n\n---\n\n## Opportunity Mapping Protocol\n\n### 1. Case-Based Reasoning\n\nQuery memory for similar situations:\n\n```\nMATCH current context against:\n  - Previous loop executions with similar goals\n  - Patterns tagged with relevant categories\n  - Decisions made in similar contexts\n\nIF match found:\n  - What worked? What didn't?\n  - Can we skip steps based on prior learning?\n  - Are there known pitfalls to avoid?\n```\n\n### 2. Bundling Detection\n\nAggregate all checklists-to-done across relevant tiers:\n\n```\nCOLLECT from:\n  - Current system's module checklists\n  - Sibling systems in same domain (if domain-scoped)\n  - Related domains (if org-scoped)\n\nANALYZE for:\n  - Repeated patterns (same issue across modules)\n  - Shared root causes (one fix, multiple benefits)\n  - Integration opportunities (solve at boundary, not in each system)\n```\n\n**Bundling Signal:** \"If we built X, it would close items in Y, Z, and W simultaneously.\"\n\n### 3. Reframing Candidates\n\nQuestion the current frame:\n\n```\nINSTEAD OF: \"{stated goal}\"\nWHAT IF:    \"{alternative framing}\"\nRESULT:     \"{compressed timeline or effort}\"\n```\n\nReframing questions:\n- Is this the right level of abstraction?\n- Are we solving a symptom instead of root cause?\n- Is there a platform/primitive that would make this trivial?\n- Are we optimizing a local maximum?\n\n### 4. Paradigm Shift Detection\n\nLook for 100x leverage moves:\n\n```\nSIGNALS:\n  - Emerging technology that obsoletes current approach\n  - Architectural insight that simplifies everything\n  - External system that could replace custom build\n  - Composition of existing pieces that achieves goal\n\nCRITERIA for surfacing:\n  - Must be concrete, not speculative\n  - Must have clear path to validation\n  - Must be relevant to current context\n  - Impact must be genuinely transformative\n```\n\n**Important:** Do NOT force paradigm shifts. \"Nothing significant found\" is a valid and common outcome. Only surface genuine opportunities.\n\n---\n\n## Output Format\n\n### Situational Summary (Always Produced)\n\n```markdown\n## Observe: Situational Summary\n\n**Loop:** {loop name}\n**Scope:** {org/domain/system/module}\n**Target:** {what we're trying to achieve}\n\n### Where We Are\n{2-3 sentences on current state}\n\n### Where We're Going\n{Reference to dream state, specific milestone}\n\n### Progress\n{Percentage, key completed items, key remaining items}\n\n### Blockers\n{Any blockers, or \"None identified\"}\n```\n\n### Opportunity Assessment (Always Produced)\n\n```markdown\n## Observe: Opportunity Assessment\n\n### Case Matches\n{Relevant patterns from memory, or \"No relevant matches\"}\n\n### Bundling Opportunities\n{Multi-solve opportunities, or \"None identified\"}\n\n### Reframing Candidates\n{Alternative perspectives worth considering, or \"Current frame appears optimal\"}\n\n### Paradigm Shifts\n{100x opportunities, or \"Nothing significant — proceed with current approach\"}\n\n### Recommendation\n{One of:}\n- \"Proceed as planned\"\n- \"Consider reframing: {suggestion}\"\n- \"High-leverage opportunity identified: {description}\"\n- \"Blocker requires resolution: {description}\"\n```\n\n### Decision Record (When Opportunity Identified)\n\nIf a significant opportunity is identified (bundling, reframe, or paradigm shift), create an ADR:\n\n```markdown\n# ADR-{NNN}: {Opportunity Title}\n\n## Status\nProposed\n\n## Context\n{What observation led to this opportunity}\n\n## Opportunity\n{What the opportunity is}\n\n## Expected Impact\n{Why this is high-leverage}\n\n## Options\n1. Pursue opportunity (reframe current goal)\n2. Note for future (continue current approach)\n3. Investigate further before deciding\n\n## Decision\n{User chooses}\n```\n\n---\n\n## Integration with Loop Execution\n\n### Pre-Loop (Hook)\n\n```\nobserve-grounding hook fires\n  → Load context hierarchy\n  → Assess current state\n  → Surface blockers\n  → Store situational summary in loop context\n```\n\n### INIT Phase (Skill)\n\n```\nobserve skill executes\n  → Run opportunity mapping protocol\n  → Produce opportunity assessment\n  → If significant opportunity: present to user, await decision\n  → If no significant opportunity: proceed with \"nothing significant\" note\n  → Store assessment in loop context\n```\n\n### Available to All Subsequent Phases\n\nThe situational summary and opportunity assessment remain available throughout loop execution, enabling:\n- Context-aware decisions\n- Reference back to \"why we're doing this\"\n- Validation against original assessment\n\n---\n\n## Key Principles\n\n1. **Reality First** — Ground in actual state before imagining possibilities\n2. **Dream State Oriented** — Always reference where we're trying to go\n3. **Opportunity, Not Obligation** — 100x moves are rare; don't manufacture them\n4. **User Agency** — Surface opportunities, let user decide\n5. **Minimal Ceremony** — Quick for \"nothing significant\" cases, deeper for genuine opportunities\n6. **Cumulative Learning** — Each observation feeds future case-based reasoning\n\n---\n\n## Relationship to Other Skills\n\n- **context-ingestion:** Observe focuses on strategic orientation; context-ingestion handles detailed codebase understanding\n- **requirements:** Observe may surface reframing that changes requirements\n- **retrospective:** Observe feeds patterns that retrospective consolidates\n- **calibration-tracker:** Observe uses calibration data; tracker updates it\n\n---\n\n## Anti-Patterns\n\n| Anti-Pattern | Why It's Wrong | Instead |\n|--------------|----------------|---------|\n| Forcing opportunities | Creates noise, wastes effort | Accept \"nothing significant\" as valid |\n| Skipping grounding | Leads to misaligned work | Always load context first |\n| Ignoring blockers | Accumulates technical debt | Surface and address blockers |\n| Over-analyzing | Paralysis by analysis | Time-box opportunity mapping |\n| Ignoring dream state | Work becomes disconnected | Always reference the destination |",
  "references": [
    {
      "name": "case-matching.md",
      "path": "references/case-matching.md",
      "content": "# Case-Based Matching\n\nHow to match the current situation against historical patterns and decisions.\n\n## Overview\n\nCase-based reasoning finds relevant past experiences to inform current work. This reference describes how to query, match, and apply historical context.\n\n---\n\n## Memory Sources\n\n### 1. Orchestrator Memory (`memory/orchestrator.json`)\n\nGlobal patterns and decisions that apply across all systems.\n\n```json\n{\n  \"patterns\": [\n    {\n      \"id\": \"PAT-001\",\n      \"name\": \"pattern-name\",\n      \"description\": \"what it is\",\n      \"context\": \"when it applies\",\n      \"tags\": [\"tag1\", \"tag2\"]\n    }\n  ],\n  \"decisions\": [\n    {\n      \"id\": \"ADR-001\",\n      \"title\": \"decision title\",\n      \"status\": \"accepted\",\n      \"context\": \"why we needed to decide\",\n      \"decision\": \"what we decided\"\n    }\n  ]\n}\n```\n\n### 2. System Memory (`{project}/memory/`)\n\nSystem-specific patterns, calibration, and execution history.\n\n### 3. Archived Runs (`~/.claude/runs/`)\n\nHistorical loop executions with context, outcomes, and lessons.\n\n```\n~/.claude/runs/\n  2026-01/\n    orchestrator-engineering-2026-01-15T10-30.json\n    deck-forge-audit-2026-01-18T14-22.json\n```\n\n### 4. Dream State History\n\nProgression through dream state milestones over time.\n\n---\n\n## Matching Algorithm\n\n### Step 1: Extract Current Context\n\n```\ncurrent_context = {\n  organization: \"superorganism\",\n  domain: \"{domain-if-known}\",\n  system: \"orchestrator\",\n  module: \"{module-if-scoped}\",\n  loop: \"engineering-loop\",\n  goal: \"{stated goal}\",\n  tags: [extracted from goal and context]\n}\n```\n\n### Step 2: Query Memory\n\n```\nFor each memory source:\n  matches = query(\n    tags: current_context.tags,\n    system: current_context.system (or null for global),\n    loop: current_context.loop (if relevant),\n    recency: prefer recent (last 30 days weighted higher)\n  )\n```\n\n### Step 3: Score Matches\n\n```\nscore(match) =\n  tag_overlap * 0.4 +\n  system_match * 0.2 +\n  loop_match * 0.2 +\n  recency_weight * 0.1 +\n  outcome_quality * 0.1\n```\n\n- **tag_overlap:** % of current tags that match pattern tags\n- **system_match:** 1.0 if same system, 0.5 if same domain, 0.2 otherwise\n- **loop_match:** 1.0 if same loop type, 0.5 if related phase\n- **recency_weight:** 1.0 for last week, decays to 0.3 over 30 days\n- **outcome_quality:** 1.0 for successful patterns, 0.5 for mixed, 0.0 for failed\n\n### Step 4: Filter and Rank\n\n```\nrelevant_matches = matches\n  .filter(score > 0.5)\n  .sort_by(score, descending)\n  .take(top 5)\n```\n\n---\n\n## Match Types\n\n### Exact Match\nSame system, same goal, same loop type.\n→ Strong signal: apply lessons directly\n\n### Analogical Match\nDifferent system, similar goal structure.\n→ Medium signal: adapt lessons to current context\n\n### Anti-Pattern Match\nSimilar situation that had bad outcome.\n→ Warning signal: avoid the pitfall\n\n### Calibration Match\nPrevious execution had calibration adjustment.\n→ Adjustment signal: apply calibration upfront\n\n---\n\n## Applying Matches\n\n### For Case-Based Shortcuts\n\n```markdown\n### Case Match: {pattern/decision ID}\n\n**Similarity:** {score as percentage}\n**Source:** {system/loop/date}\n\n**What happened:** {brief description}\n**Lesson:** {what to apply}\n**Shortcut:** {what step(s) we can skip or modify}\n```\n\n### For Anti-Patterns\n\n```markdown\n### Anti-Pattern Warning: {pattern ID}\n\n**Similarity:** {score as percentage}\n**Source:** {system/loop/date}\n\n**What happened:** {what went wrong}\n**Root cause:** {why it failed}\n**Avoidance:** {what to do differently}\n```\n\n### For Calibration\n\n```markdown\n### Calibration Adjustment: {calibration ID}\n\n**Source:** {previous execution}\n**Original estimate:** {what we thought}\n**Actual:** {what happened}\n**Adjustment:** {how to calibrate this time}\n```\n\n---\n\n## Building the Case Base\n\nEvery loop completion should contribute to future matching:\n\n### On Success\n\n```json\n{\n  \"type\": \"pattern\",\n  \"source\": \"{system}-{loop}-{date}\",\n  \"context\": {\n    \"goal\": \"what we were doing\",\n    \"approach\": \"how we did it\",\n    \"environment\": \"relevant context\"\n  },\n  \"outcome\": {\n    \"success\": true,\n    \"duration\": \"how long it took\",\n    \"lessons\": [\"what worked well\"]\n  },\n  \"tags\": [\"derived\", \"from\", \"context\"]\n}\n```\n\n### On Partial Success\n\n```json\n{\n  \"type\": \"pattern\",\n  \"outcome\": {\n    \"success\": \"partial\",\n    \"what_worked\": [\"things that went well\"],\n    \"what_didnt\": [\"things that need improvement\"],\n    \"adjustments\": [\"for next time\"]\n  }\n}\n```\n\n### On Failure\n\n```json\n{\n  \"type\": \"anti-pattern\",\n  \"outcome\": {\n    \"success\": false,\n    \"failure_mode\": \"what went wrong\",\n    \"root_cause\": \"why it happened\",\n    \"prevention\": \"how to avoid\"\n  }\n}\n```\n\n---\n\n## Query Examples\n\n### \"I'm about to scaffold a new Next.js project\"\n\n```\nQuery:\n  tags: [nextjs, scaffold, new-project]\n  loop: engineering-loop\n  phase: SCAFFOLD\n\nExpected matches:\n  - Previous Next.js scaffolds (exact)\n  - Other frontend scaffolds (analogical)\n  - Known scaffolding anti-patterns (warning)\n```\n\n### \"I'm debugging a state management issue\"\n\n```\nQuery:\n  tags: [debug, state, react, redux/zustand/etc]\n  loop: bugfix-loop\n  phase: IMPLEMENT\n\nExpected matches:\n  - Previous state bugs in same system (exact)\n  - State bugs in other systems (analogical)\n  - Common state debugging patterns (general)\n```\n\n### \"I'm deploying to production\"\n\n```\nQuery:\n  tags: [deploy, production, release]\n  loop: distribution-loop\n  phase: SHIP\n\nExpected matches:\n  - Previous deploys for this system (exact)\n  - Deploy incidents (anti-pattern)\n  - Calibration on deploy duration (calibration)\n```\n\n---\n\n## Cold Start\n\nWhen memory is empty or sparse:\n\n1. **Don't block** — Observe still produces value via grounding\n2. **Note the gap** — \"No historical matches available\"\n3. **Build from first run** — This execution becomes first case\n4. **Bootstrap from templates** — Use skill reference patterns as initial cases\n\nThe case base grows with use. Early runs have less matching; later runs benefit from history.\n\n---\n\n## Privacy and Scope\n\n- **Organization memory** stays within org boundaries\n- **System memory** stays within system\n- **User memory** (~/.claude/) is personal\n- **Patterns can be promoted** from system → org if generally applicable\n- **Sensitive patterns** should be tagged and filtered appropriately\n"
    },
    {
      "name": "opportunity-types.md",
      "path": "references/opportunity-types.md",
      "content": "# Opportunity Types\n\nA taxonomy of leverage opportunities the Observe skill looks for.\n\n## Overview\n\nNot all opportunities are equal. This reference categorizes opportunity types by their nature and expected impact.\n\n---\n\n## Type 1: Case-Based Shortcuts\n\n**What:** Applying lessons from similar past situations to skip steps or avoid pitfalls.\n\n**Impact:** 1.5-3x speedup (incremental, not transformative)\n\n**Examples:**\n- \"Last time we added auth, we hit rate limiting issues. Let's configure that upfront.\"\n- \"This is the third time we've scaffolded a Next.js app. Use the established pattern.\"\n- \"Previous audit found this category of issues. Check for them early.\"\n\n**Detection:**\n- Query memory for patterns with matching tags\n- Look for previous executions with similar goals\n- Check calibration adjustments for relevant warnings\n\n**Action:** Apply learning, note shortcut taken.\n\n---\n\n## Type 2: Bundling\n\n**What:** Solving multiple problems with a single solution.\n\n**Impact:** 3-10x efficiency (doing N things for the cost of 1)\n\n**Examples:**\n- \"Three systems need user preferences. Build one preferences service.\"\n- \"Five modules have similar validation. Extract a shared validator.\"\n- \"Auth, logging, and metrics all need middleware. Build a plugin system.\"\n\n**Detection:**\n- Aggregate checklists-to-done across systems/modules\n- Look for repeated items or similar descriptions\n- Identify shared root causes\n\n**Bundling Signals:**\n```\n- Same issue appears in multiple checklists\n- Multiple items share a dependency\n- Pattern of \"add X to module Y\" repeated across modules\n- Integration points that would benefit from standardization\n```\n\n**Action:** Propose bundled solution, estimate combined impact, get user decision.\n\n---\n\n## Type 3: Reframing\n\n**What:** Changing perspective to compress the problem.\n\n**Impact:** 5-20x compression (problem becomes smaller or disappears)\n\n**Examples:**\n- \"Instead of building custom search, use Algolia.\" (buy vs build)\n- \"Instead of optimizing the query, cache the result.\" (different solution space)\n- \"Instead of fixing the UI, remove the feature.\" (scope reduction)\n- \"Instead of per-module config, use convention over configuration.\" (abstraction shift)\n\n**Detection:**\n- Question stated goals: \"Why do we need X?\"\n- Look for assumed constraints that may not exist\n- Check if problem is symptom vs root cause\n- Consider different solution categories (build/buy/borrow/bypass)\n\n**Reframing Questions:**\n```\n1. Is this solving a symptom or root cause?\n2. Is there a higher abstraction that trivializes this?\n3. What would we do with unlimited resources? Limited resources?\n4. Can we solve this with convention instead of code?\n5. What would our competitors do?\n6. Is this actually needed, or just assumed to be needed?\n```\n\n**Action:** Present reframed problem, show impact comparison, let user choose frame.\n\n---\n\n## Type 4: Paradigm Shift\n\n**What:** A fundamentally different approach that obsoletes current work.\n\n**Impact:** 100x+ (transforms the landscape)\n\n**Examples:**\n- \"What if we used an LLM instead of rule-based parsing?\"\n- \"What if this was a static site instead of a server?\"\n- \"What if we made this a library instead of a service?\"\n- \"What if we contributed to the open-source tool instead of building a wrapper?\"\n\n**Detection:**\n- Monitor for emerging capabilities that change assumptions\n- Look for architectural insights from adjacent domains\n- Consider composing existing systems differently\n- Question whether custom code is needed at all\n\n**Paradigm Shift Signals:**\n```\n- New technology makes hard things easy\n- Architectural pattern simplifies multiple concerns\n- External system does 80% of what we need\n- Composition of existing pieces achieves goal\n- Industry is moving in a different direction\n```\n\n**Criteria for Surfacing:**\n1. **Concrete** — Not speculative; has clear implementation path\n2. **Validated** — Evidence it works (others have done it, technology is mature)\n3. **Relevant** — Applies to current context, not just interesting\n4. **Transformative** — Impact is genuinely 10x+, not incremental\n\n**Action:** Create decision record, present to user with options, await explicit decision before proceeding.\n\n---\n\n## Type 5: Anticipatory Layers\n\n**What:** Doing work now that multiplies future work.\n\n**Impact:** Force multiplier (enables future 10x moves)\n\n**Examples:**\n- \"If we add plugin architecture now, future features become plugins.\"\n- \"If we define a clear API boundary, systems can evolve independently.\"\n- \"If we instrument observability now, debugging becomes trivial.\"\n- \"If we write the spec thoroughly, implementation becomes mechanical.\"\n\n**Detection:**\n- Look at roadmap/dream state for upcoming work\n- Identify patterns in planned features\n- Find extension points that would benefit multiple futures\n- Consider \"what would make the next 5 tasks easier?\"\n\n**Anticipatory Signals:**\n```\n- Multiple future items share a dependency we don't have\n- Current architecture will fight future requirements\n- Other successful systems have a capability we lack\n- We're about to build something that should be pluggable\n```\n\n**Action:** Propose the layer, estimate investment vs payoff, note it enables future work.\n\n---\n\n## Opportunity Matrix\n\n| Type | Detection Effort | Impact | Frequency |\n|------|------------------|--------|-----------|\n| Case-Based Shortcuts | Low | 1.5-3x | Common |\n| Bundling | Medium | 3-10x | Occasional |\n| Reframing | Medium | 5-20x | Occasional |\n| Paradigm Shift | High | 100x+ | Rare |\n| Anticipatory Layers | Medium | Force multiplier | Occasional |\n\n---\n\n## \"Nothing Significant\" is Valid\n\nMost loop executions will find:\n- A few case-based shortcuts (apply them silently)\n- No bundling opportunities (scope is focused)\n- Current frame is appropriate\n- No paradigm shifts available\n\nThis is fine. Document \"nothing significant\" and proceed. The value of Observe is in the rare cases where opportunities exist, not in manufacturing them.\n\n---\n\n## Recording Opportunities\n\nWhen an opportunity is identified:\n\n1. **Create ADR** for Type 3-5 opportunities (reframe, paradigm, anticipatory)\n2. **Update patterns** for Type 1-2 (case-based, bundling) after execution\n3. **Tag with opportunity type** for future case-based matching\n\n```json\n{\n  \"type\": \"opportunity\",\n  \"category\": \"bundling|reframe|paradigm|anticipatory\",\n  \"context\": \"what we were doing\",\n  \"opportunity\": \"what we found\",\n  \"decision\": \"pursued|deferred|rejected\",\n  \"outcome\": \"result if pursued\"\n}\n```\n\nThis feeds future case-based reasoning.\n"
    }
  ],
  "tags": [
    "orientation",
    "context",
    "leverage",
    "opportunity",
    "strategic",
    "100x"
  ],
  "dependsOn": []
}