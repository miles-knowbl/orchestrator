{
  "id": "smoke-test",
  "name": "smoke-test",
  "version": "1.0.0",
  "description": "Verifies critical features actually work by calling live endpoints. Unlike integration-test (which writes test code), this skill executes manual verification against deployed/running services. Essential for audit-loop to catch functional regressions.",
  "phase": "VERIFY",
  "category": "engineering",
  "content": "# Smoke Test\n\nVerify critical features actually work by calling live endpoints.\n\n## When to Use\n\n- **During audits** — Verify features work, not just that code looks correct\n- **After deployment** — Confirm deployed services respond correctly\n- **Before sign-off** — Validate critical paths function end-to-end\n- **Regression detection** — Catch broken features that static analysis misses\n\n## Why This Skill Exists\n\nStatic code analysis can verify:\n- Code patterns are correct\n- Types are valid\n- Security patterns are followed\n\nStatic code analysis **CANNOT** verify:\n- The endpoint actually returns data\n- AI integrations are properly configured\n- Third-party services are connected\n- The feature works end-to-end\n\n**This skill fills that gap.**\n\n## Core Concept\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                    VERIFICATION SPECTRUM                        │\n│                                                                 │\n│  Static Analysis        Smoke Test           Full E2E          │\n│  ──────────────        ──────────           ────────           │\n│  Reads code            Calls endpoints      Full user flow     │\n│  Fast, shallow         Medium, targeted     Slow, comprehensive│\n│                                                                 │\n│  \"Does code look       \"Does endpoint       \"Does entire       │\n│   correct?\"             respond?\"            workflow work?\"   │\n│                                                                 │\n│  ┌───────────┐         ┌───────────┐        ┌───────────┐     │\n│  │   Code    │         │   API     │        │  Browser  │     │\n│  │  Review   │         │   Call    │        │   Test    │     │\n│  └───────────┘         └───────────┘        └───────────┘     │\n│                                                                 │\n│  audit-loop            audit-loop           CI/CD pipeline     │\n│  REVIEW phase          VERIFY phase         pre-deploy         │\n│                                                                 │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n## Smoke Test Process\n\n### Step 1: Identify Critical Paths\n\nFor any system, identify the **must-work** features:\n\n```markdown\n## Critical Paths: [System Name]\n\n### P0 - System Unusable If Broken\n| Feature | Endpoint/Action | Expected Behavior |\n|---------|-----------------|-------------------|\n| User login | POST /auth/login | Returns JWT |\n| Core generation | POST /generate | Returns content |\n| Data retrieval | GET /items | Returns items |\n\n### P1 - Major Feature Broken\n| Feature | Endpoint/Action | Expected Behavior |\n|---------|-----------------|-------------------|\n| Secondary feature | POST /feature-b | Returns result |\n| Export | GET /export | Returns file |\n```\n\n### Step 2: Execute Verification\n\nFor each critical path, actually call the endpoint:\n\n```bash\n# Example: Verify edge function works\ncurl -X POST https://project.supabase.co/functions/v1/generate-image \\\n  -H \"Authorization: Bearer $ANON_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"source_ids\": [\"test-source\"], \"mode\": \"archetype\"}' \\\n  | jq '.status, .error'\n```\n\n### Step 3: Document Results\n\n```markdown\n## Smoke Test Results\n\n| Feature | Status | Response | Notes |\n|---------|--------|----------|-------|\n| generate-image | FAIL | 500 | \"Cannot read property 'content'\" |\n| generate-article | PASS | 200 | Returns job ID |\n| chat endpoint | FAIL | 401 | Auth misconfigured |\n| enrich-source | PASS | 200 | Returns enrichment |\n```\n\n### Step 4: Classify Failures\n\n| Severity | Criteria | Action |\n|----------|----------|--------|\n| **CRITICAL** | Core feature completely broken | Block deployment |\n| **HIGH** | Major feature degraded | Urgent fix required |\n| **MEDIUM** | Secondary feature broken | Fix in next sprint |\n| **LOW** | Edge case failure | Backlog |\n\n## Deliverables\n\n| Deliverable | Location | Contents |\n|-------------|----------|----------|\n| `SMOKE-TEST.md` | Project root | Test results, failures, recommendations |\n\n### SMOKE-TEST.md Template\n\n```markdown\n# Smoke Test Report\n\n**Date:** YYYY-MM-DD\n**Environment:** production / staging / local\n**Tester:** [name/agent]\n\n## Summary\n\n| Status | Count |\n|--------|-------|\n| PASS | X |\n| FAIL | Y |\n| SKIP | Z |\n\n## Critical Path Results\n\n### P0 Features (Must Work)\n\n| Feature | Status | Response | Evidence |\n|---------|--------|----------|----------|\n| [name] | PASS/FAIL | [code] | [details] |\n\n### P1 Features (Should Work)\n\n| Feature | Status | Response | Evidence |\n|---------|--------|----------|----------|\n| [name] | PASS/FAIL | [code] | [details] |\n\n## Failures\n\n### [CRITICAL] Feature Name\n\n**Endpoint:** POST /api/feature\n**Expected:** 200 with data\n**Actual:** 500 Internal Server Error\n\n**Response:**\n```json\n{\n  \"error\": \"Cannot read property 'foo' of undefined\"\n}\n```\n\n**Root Cause Hypothesis:** [analysis]\n**Recommended Fix:** [suggestion]\n\n## Test Commands\n\n```bash\n# Commands used for verification\ncurl ...\n```\n\n## Conclusion\n\n[Summary of system health based on smoke test results]\n```\n\n## Integration with Audit Loop\n\nThe audit-loop should include smoke-test in its VALIDATE phase:\n\n```json\n{\n  \"phases\": {\n    \"VALIDATE\": {\n      \"status\": \"pending\",\n      \"skills\": [\"smoke-test\", \"integration-test\", \"code-verification\"]\n    }\n  }\n}\n```\n\n**Execution order:**\n1. `smoke-test` — Call live endpoints, identify broken features\n2. `integration-test` — Verify test coverage for working features\n3. `code-verification` — Verify findings against code\n\n**Why smoke-test first:**\n- Catches critical failures immediately\n- Prevents wasting time analyzing code that doesn't work\n- Provides concrete evidence of problems\n\n## Environment Detection\n\nSmoke test should auto-detect the environment:\n\n```javascript\n// Detect environment from project files\nconst envConfig = {\n  supabase: {\n    url: process.env.SUPABASE_URL || readFromEnvFile('.env'),\n    anonKey: process.env.SUPABASE_ANON_KEY || readFromEnvFile('.env')\n  },\n  endpoints: detectEdgeFunctions('supabase/functions/'),\n  localDev: detectLocalServer('package.json')\n};\n```\n\n## What to Test\n\n### For Supabase Edge Functions\n\n```bash\n# List all edge functions\nls supabase/functions/\n\n# Test each one that should be publicly callable\nfor fn in generate-image generate-article chat enrich-source; do\n  echo \"Testing $fn...\"\n  curl -X POST \"$SUPABASE_URL/functions/v1/$fn\" \\\n    -H \"Authorization: Bearer $ANON_KEY\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"test\": true}'\ndone\n```\n\n### For REST APIs\n\n```bash\n# Health check\ncurl \"$API_URL/health\"\n\n# Auth endpoints\ncurl -X POST \"$API_URL/auth/login\" -d '{\"test\": true}'\n\n# Core CRUD\ncurl \"$API_URL/items\"\n```\n\n### For Frontend + Backend Integration\n\n```bash\n# Start local dev server\nnpm run dev &\n\n# Wait for server\nsleep 5\n\n# Test key pages load\ncurl -s http://localhost:3000 | grep -q \"<!DOCTYPE\" && echo \"PASS\" || echo \"FAIL\"\n\n# Test API routes\ncurl http://localhost:3000/api/health\n```\n\n## Relationship to Other Skills\n\n| Skill | Relationship |\n|-------|--------------|\n| `integration-test` | Writes test code; smoke-test executes manual verification |\n| `code-verification` | Verifies code patterns; smoke-test verifies runtime behavior |\n| `deploy` | Deploys code; smoke-test verifies deployment worked |\n| `architecture-review` | Reviews design; smoke-test verifies implementation |\n\n## Key Principles\n\n**Call the actual endpoint.** Don't assume code that looks correct works.\n\n**Test in the real environment.** Mocks hide integration failures.\n\n**Document evidence.** Include actual response bodies, not just pass/fail.\n\n**Prioritize by impact.** Test P0 features first.\n\n**Fail fast.** If core features are broken, stop and report immediately.",
  "references": [],
  "tags": [
    "testing",
    "verification",
    "live-testing",
    "audit",
    "functional"
  ],
  "dependsOn": []
}