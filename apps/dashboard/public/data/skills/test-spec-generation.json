{
  "id": "test-spec-generation",
  "name": "test-spec-generation",
  "version": "1.0.0",
  "description": "Generate test specifications for unvalidated failure modes. Creates detailed test specs with setup, steps, and assertions for each unvalidated failure mode. Produces PIPELINE-TEST-SPECS.md and UI-TEST-SPECS.md.",
  "phase": "VALIDATE",
  "category": "engineering",
  "content": "# Test Spec Generation\n\nGenerate test specifications for unvalidated failure modes.\n\n## When to Use\n\n- **After failure mode analysis** — Runs in VALIDATE phase\n- **Creating test coverage plan** — Spec tests for all unvalidated modes\n- **Enabling implementation** — Detailed specs developers can implement\n- When you say: \"generate test specs\", \"what tests do we need?\", \"create test plan\"\n\n## Reference Requirements\n\n**MUST read before applying this skill:**\n\n| Reference | Why Required |\n|-----------|--------------|\n| `test-type-selection.md` | When to use unit/integration/e2e |\n| `test-spec-template.md` | Format for test specifications |\n\n**Read if applicable:**\n\n| Reference | When Needed |\n|-----------|-------------|\n| `ui-test-patterns.md` | Component, hook, integration, e2e patterns |\n\n**Verification:** Every unvalidated failure mode has a test specification.\n\n## Required Deliverables\n\n| Deliverable | Location | Condition |\n|-------------|----------|-----------|\n| `PIPELINE-TEST-SPECS.md` | Project root | If unvalidated backend modes exist |\n| `UI-TEST-SPECS.md` | Project root | If unvalidated UI modes exist |\n\n## Core Concept\n\nTest Spec Generation answers: **\"How do we validate each failure mode?\"**\n\nA test specification includes:\n- **What to test** — The failure mode being validated\n- **Setup** — Prerequisites and mock data\n- **Steps** — Actions to trigger the failure\n- **Assertions** — How to verify correct handling\n\n## Test Type Selection\n\n| Failure Mode Type | Recommended Test Type |\n|-------------------|----------------------|\n| L1-Input validation | Unit test |\n| L2-Processing logic | Unit test |\n| L3-Output/storage | Integration test |\n| L4-Integration | Integration or E2E |\n| L5-Interaction | Component + E2E |\n| L6-Streaming | Integration test |\n\n## Generation Process\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│            TEST SPEC GENERATION PROCESS                     │\n│                                                             │\n│  1. LOAD FAILURE MODES                                      │\n│     ├─→ From PIPELINE-FAILURE-MODES.md                     │\n│     └─→ From UI-FAILURE-MODES.md                           │\n│                                                             │\n│  2. FILTER TO UNVALIDATED                                   │\n│     └─→ Status == UNVALIDATED                              │\n│                                                             │\n│  3. FOR EACH UNVALIDATED MODE                               │\n│     ├─→ Select test type                                   │\n│     ├─→ Define setup requirements                          │\n│     ├─→ Specify test steps                                 │\n│     ├─→ Define pass/fail criteria                          │\n│     └─→ Generate ID: TEST-{mode-id}                        │\n│                                                             │\n│  4. ORGANIZE BY PIPELINE                                    │\n│     └─→ Group specs by pipeline for implementation         │\n│                                                             │\n│  5. GENERATE DELIVERABLES                                   │\n│     ├─→ PIPELINE-TEST-SPECS.md                             │\n│     └─→ UI-TEST-SPECS.md                                   │\n└─────────────────────────────────────────────────────────────┘\n```\n\n## Test Specification Format\n\n```markdown\n### TEST-P2-007: Template selection too narrow\n\n**Failure Mode:** P2-007 (L2-Processing, T4-Quality, S1-Silent)\n**Test Type:** Integration\n\n**Setup:**\n- Mock source data with varied topics\n- Ensure template pool is accessible\n- Configure generation settings\n\n**Steps:**\n1. Trigger generation 10 times with same source\n2. Collect all generated outputs\n3. Analyze template usage distribution\n\n**Pass Criteria:**\n- At least 5 different templates used\n- No template used more than 40% of time\n- Outputs show meaningful variation\n\n**Fail Criteria:**\n- Same template used for > 50% of outputs\n- Outputs are nearly identical\n- Only 1-3 templates ever used\n\n**Implementation Notes:**\n- Consider parameterized test for scale\n- May need to mock random selection for determinism\n```\n\n## Backend Test Types\n\n### Unit Test\nTests individual functions in isolation.\n\n```markdown\n**Test Type:** Unit\n**Framework:** Vitest / Jest\n\n**Setup:**\n- Import function under test\n- Mock dependencies\n\n**Pattern:**\n```typescript\ntest('rejects file over size limit', () => {\n  const largeFile = createMockFile(15_000_000);\n  expect(() => validateFileSize(largeFile)).toThrow('exceeds limit');\n});\n```\n```\n\n### Integration Test\nTests interactions between components.\n\n```markdown\n**Test Type:** Integration\n**Framework:** Vitest / Jest\n\n**Setup:**\n- Set up test database\n- Configure API mocks\n- Prepare test fixtures\n\n**Pattern:**\n```typescript\ntest('source ingestion creates schema', async () => {\n  const source = await ingestSource(testFile);\n  expect(source.schema).toBeDefined();\n  expect(source.schema.fields).toHaveLength(5);\n});\n```\n```\n\n### E2E Test\nTests full user flows.\n\n```markdown\n**Test Type:** E2E\n**Framework:** Playwright\n\n**Setup:**\n- Seed test database\n- Authenticate test user\n\n**Pattern:**\n```typescript\ntest('user can generate content', async ({ page }) => {\n  await page.goto('/sources');\n  await page.click('[data-testid=\"source-1\"]');\n  await page.click('text=Generate');\n  await expect(page.locator('.artifact')).toBeVisible();\n});\n```\n```\n\n## UI Test Types\n\n### Component Test\nTests individual React components.\n\n```markdown\n**Test Type:** Component\n**Framework:** Vitest + React Testing Library\n\n**Setup:**\n- Render component with test props\n- Mock context if needed\n\n**Pattern:**\n```typescript\ntest('shows loading state during generation', () => {\n  render(<GenerateButton isLoading={true} />);\n  expect(screen.getByRole('progressbar')).toBeVisible();\n});\n```\n```\n\n### Hook Test\nTests custom React hooks.\n\n```markdown\n**Test Type:** Hook\n**Framework:** Vitest + @testing-library/react-hooks\n\n**Setup:**\n- Wrap in test providers\n- Mock API calls\n\n**Pattern:**\n```typescript\ntest('useArtifact returns artifact data', async () => {\n  const { result } = renderHook(() => useArtifact('123'));\n  await waitFor(() => expect(result.current.data).toBeDefined());\n});\n```\n```\n\n## Output Format\n\n### PIPELINE-TEST-SPECS.md\n\n```markdown\n# Pipeline Test Specifications\n\n## Summary\n\n| Pipeline | Unvalidated | Test Specs |\n|----------|-------------|------------|\n| P1: Source Ingestion | 5 | 5 |\n| P2: Content Generation | 9 | 9 |\n| P3: Publishing | 3 | 3 |\n| **Total** | **17** | **17** |\n\n## P1: Source Ingestion\n\n### TEST-P1-003: File type validation\n\n**Failure Mode:** P1-003 (L1-Input, T1-Data, S3-Visible)\n**Test Type:** Unit\n\n[... spec details ...]\n\n## P2: Content Generation\n\n### TEST-P2-007: Template selection\n\n[... spec details ...]\n```\n\n### UI-TEST-SPECS.md\n\n```markdown\n# UI Test Specifications\n\n## Summary\n\n| Pipeline | Unvalidated | Component | Hook | Integration | E2E |\n|----------|-------------|-----------|------|-------------|-----|\n| U1: Chat-to-Edit | 6 | 2 | 1 | 2 | 1 |\n| U2: Chat-to-Generate | 7 | 3 | 1 | 2 | 1 |\n| **Total** | **13** | **5** | **2** | **4** | **2** |\n\n## U1: Chat-to-Edit\n\n### TEST-U1-005: Cache invalidation\n\n**Failure Mode:** U1-005 (L3-Output, T1-Data, S1-Silent)\n**Test Type:** Integration (Vitest + RTL)\n\n[... spec details ...]\n```\n\n## Validation Checklist\n\n- [ ] Every unvalidated mode has a test spec\n- [ ] Test type appropriate for failure mode\n- [ ] Setup is complete and reproducible\n- [ ] Steps are specific and actionable\n- [ ] Pass/fail criteria are unambiguous\n- [ ] Specs organized by pipeline\n- [ ] Implementation notes included where helpful",
  "references": [
    {
      "name": "test-spec-template.md",
      "path": "references/test-spec-template.md",
      "content": "# Test Specification Template\n\nStandard format for test specifications.\n\n## Full Template\n\n```markdown\n### TEST-{failure-mode-id}: {Short description}\n\n**Failure Mode:** {id} ({Location}, {Type}, {Severity})\n**Test Type:** Unit | Integration | E2E | Component | Hook\n**Framework:** {Vitest | Jest | Playwright | RTL}\n\n**Setup:**\n- {Prerequisite 1}\n- {Prerequisite 2}\n- {Mock/fixture description}\n\n**Steps:**\n1. {Action 1}\n2. {Action 2}\n3. {Action 3}\n\n**Pass Criteria:**\n- {What indicates success}\n- {Expected state/output}\n\n**Fail Criteria:**\n- {What indicates failure}\n- {Unexpected state/output}\n\n**Implementation Notes:**\n- {Helpful hints for implementer}\n```\n\n## Example: Unit Test Spec\n\n```markdown\n### TEST-P1-003: File size validation\n\n**Failure Mode:** P1-003 (L1-Input, T1-Data, S3-Visible)\n**Test Type:** Unit\n**Framework:** Vitest\n\n**Setup:**\n- Import validateFileSize function\n- Create mock files of various sizes\n\n**Steps:**\n1. Call validateFileSize with 5MB file\n2. Call validateFileSize with 15MB file\n3. Call validateFileSize with exactly 10MB file\n\n**Pass Criteria:**\n- 5MB file passes (no throw)\n- 15MB file throws 'exceeds limit' error\n- 10MB file passes (boundary case)\n\n**Fail Criteria:**\n- Any valid file throws\n- Large file doesn't throw\n- Wrong error message\n\n**Implementation Notes:**\n- Use Buffer.alloc() for mock file creation\n- Consider parameterized test for multiple sizes\n```\n\n## Example: Integration Test Spec\n\n```markdown\n### TEST-P2-007: Template selection variety\n\n**Failure Mode:** P2-007 (L2-Processing, T4-Quality, S1-Silent)\n**Test Type:** Integration\n**Framework:** Vitest\n\n**Setup:**\n- Seed database with 3 test sources\n- Ensure 10+ templates exist in pool\n- Reset random seed for reproducibility\n\n**Steps:**\n1. Call generateContent() 20 times with same source\n2. Collect template IDs used in each generation\n3. Calculate distribution of template usage\n\n**Pass Criteria:**\n- At least 6 different templates used\n- No single template used > 30% of time\n- Distribution appears random\n\n**Fail Criteria:**\n- Fewer than 4 templates used\n- One template dominates (> 50%)\n- Same sequence every run\n\n**Implementation Notes:**\n- May need to mock Math.random for determinism\n- Consider snapshot testing for output variety\n- Run multiple times to catch flaky randomness\n```\n\n## Example: E2E Test Spec\n\n```markdown\n### TEST-U1-E2E-001: Chat-to-Edit full flow\n\n**Failure Mode:** U1-* (Full pipeline validation)\n**Test Type:** E2E\n**Framework:** Playwright\n\n**Setup:**\n- Seed database with test artifact\n- Authenticate test user\n- Navigate to artifact editor\n\n**Steps:**\n1. Open artifact in editor view\n2. Verify \"Editing: {title}\" badge shows\n3. Type \"make it shorter\" in chat input\n4. Press Enter to send\n5. Wait for tool call to complete\n6. Observe artifact content update\n\n**Pass Criteria:**\n- Badge shows correct artifact title\n- Chat shows agent response\n- Tool call bubble shows success\n- Artifact content visibly shorter\n- No console errors\n\n**Fail Criteria:**\n- Badge missing or wrong title\n- No response after 30 seconds\n- Error shown to user\n- Artifact unchanged\n- Console errors present\n\n**Implementation Notes:**\n- Use data-testid for reliable selectors\n- Mock LLM response for speed\n- Screenshot on failure for debugging\n```\n\n## Example: Component Test Spec\n\n```markdown\n### TEST-U2-003: Loading state visibility\n\n**Failure Mode:** U2-003 (L3-Output, T5-UX, S3-Visible)\n**Test Type:** Component\n**Framework:** Vitest + React Testing Library\n\n**Setup:**\n- Import GenerateButton component\n- Mock useGeneration hook\n\n**Steps:**\n1. Render GenerateButton with isLoading=false\n2. Verify button is enabled and shows \"Generate\"\n3. Re-render with isLoading=true\n4. Verify button is disabled and shows spinner\n\n**Pass Criteria:**\n- Loading spinner visible when isLoading=true\n- Button disabled when loading\n- Text changes appropriately\n\n**Fail Criteria:**\n- No visual change when loading\n- Button remains clickable\n- Spinner doesn't appear\n\n**Implementation Notes:**\n- Use getByRole('progressbar') for spinner\n- Check aria-busy attribute\n```\n\n## Minimal Template\n\nFor quick specs:\n\n```markdown\n### TEST-{id}: {Description}\n\n**Type:** {Unit | Integration | E2E}\n**Failure Mode:** {id}\n\n**Test:** {What to test}\n**Expect:** {Expected result}\n```\n"
    },
    {
      "name": "test-type-selection.md",
      "path": "references/test-type-selection.md",
      "content": "# Test Type Selection\n\nWhen to use each type of test.\n\n## Test Type Overview\n\n| Type | Speed | Scope | Confidence | Cost |\n|------|-------|-------|------------|------|\n| Unit | Fast | Single function | Low | Low |\n| Integration | Medium | Multiple components | Medium | Medium |\n| E2E | Slow | Full user flow | High | High |\n\n## Selection by Location Code\n\n### L1: Input\n**Recommended:** Unit test\n\nWhy: Input validation is isolated, fast to test.\n\n```typescript\ntest('rejects empty name', () => {\n  expect(() => validateInput({ name: '' })).toThrow();\n});\n```\n\n### L2: Processing\n**Recommended:** Unit test\n\nWhy: Business logic should be testable in isolation.\n\n```typescript\ntest('calculates correct score', () => {\n  expect(calculateScore([3, 4, 5])).toBe(4);\n});\n```\n\n### L3: Output\n**Recommended:** Integration test\n\nWhy: Needs real database/API to verify storage.\n\n```typescript\ntest('stores artifact in database', async () => {\n  const artifact = await createArtifact(data);\n  const stored = await db.artifacts.findById(artifact.id);\n  expect(stored).toBeDefined();\n});\n```\n\n### L4: Integration\n**Recommended:** Integration or E2E\n\nWhy: Cross-boundary, needs full stack.\n\n```typescript\ntest('P2 uses P1 schema correctly', async () => {\n  const source = await ingestSource(file);\n  const artifact = await generateFromSource(source.id);\n  expect(artifact.content).toContain(source.schema.title);\n});\n```\n\n### L5: Interaction\n**Recommended:** Component + E2E\n\nWhy: Needs UI context and real interactions.\n\n```typescript\n// Component test\ntest('button triggers handler', () => {\n  const handler = vi.fn();\n  render(<EditButton onClick={handler} />);\n  fireEvent.click(screen.getByRole('button'));\n  expect(handler).toHaveBeenCalled();\n});\n\n// E2E test\ntest('edit updates artifact', async ({ page }) => {\n  await page.fill('.chat-input', 'make it shorter');\n  await page.click('text=Send');\n  await expect(page.locator('.artifact')).toContainText('...');\n});\n```\n\n### L6: Streaming\n**Recommended:** Integration test\n\nWhy: Needs to mock/test real SSE/WebSocket.\n\n```typescript\ntest('handles stream disconnect', async () => {\n  const { result } = renderHook(() => useStream('/api/chat'));\n  simulateDisconnect();\n  await waitFor(() => {\n    expect(result.current.status).toBe('reconnecting');\n  });\n});\n```\n\n## Selection by Severity\n\n| Severity | Minimum Test | Why |\n|----------|--------------|-----|\n| S1-Silent | Integration + E2E | Silent failures need thorough testing |\n| S2-Partial | Integration | Need to verify partial states |\n| S3-Visible | Unit or Integration | Error display testable at unit level |\n| S4-Blocking | Unit | Usually caught by basic tests |\n\n## Selection by Type\n\n| Type Code | Best Test |\n|-----------|-----------|\n| T1-Data | Unit (validation) + Integration (storage) |\n| T2-Logic | Unit (isolated logic testing) |\n| T3-Infrastructure | Integration (with mocks) |\n| T4-Quality | Integration + E2E (output evaluation) |\n| T5-UX | Component + E2E (user experience) |\n\n## Hybrid Strategy\n\nFor critical failure modes, use multiple levels:\n\n```\nP2-007 (Template selection)\n├── Unit: Test template_select() function\n├── Integration: Test full generation with template mock\n└── E2E: Verify user sees varied outputs\n```\n\n## Resource Constraints\n\nIf time is limited, prioritize:\n\n1. **S1-Silent failures** — These are invisible, need tests\n2. **L4-Integration failures** — Often untested\n3. **High-impact paths** — Critical user flows\n"
    },
    {
      "name": "ui-test-patterns.md",
      "path": "references/ui-test-patterns.md",
      "content": "# UI Test Patterns\n\nPatterns for testing React UI components and flows.\n\n## Component Test Patterns\n\n### Render and Assert\nBasic component rendering test.\n\n```typescript\ntest('renders button with text', () => {\n  render(<Button>Click me</Button>);\n  expect(screen.getByRole('button')).toHaveTextContent('Click me');\n});\n```\n\n### Event Handling\nTest user interactions.\n\n```typescript\ntest('calls onClick when clicked', async () => {\n  const handleClick = vi.fn();\n  render(<Button onClick={handleClick}>Click</Button>);\n\n  await userEvent.click(screen.getByRole('button'));\n\n  expect(handleClick).toHaveBeenCalledTimes(1);\n});\n```\n\n### Loading States\nTest async state transitions.\n\n```typescript\ntest('shows loading then content', async () => {\n  render(<DataLoader />);\n\n  // Initially loading\n  expect(screen.getByRole('progressbar')).toBeVisible();\n\n  // Eventually shows data\n  await waitFor(() => {\n    expect(screen.getByText('Data loaded')).toBeVisible();\n  });\n});\n```\n\n### Error States\nTest error handling.\n\n```typescript\ntest('shows error message on failure', async () => {\n  server.use(\n    rest.get('/api/data', (req, res, ctx) => res(ctx.status(500)))\n  );\n\n  render(<DataLoader />);\n\n  await waitFor(() => {\n    expect(screen.getByRole('alert')).toHaveTextContent('Failed to load');\n  });\n});\n```\n\n## Hook Test Patterns\n\n### Basic Hook\nTest hook return values.\n\n```typescript\ntest('useCounter increments', () => {\n  const { result } = renderHook(() => useCounter(0));\n\n  act(() => {\n    result.current.increment();\n  });\n\n  expect(result.current.count).toBe(1);\n});\n```\n\n### Async Hook\nTest hooks with async operations.\n\n```typescript\ntest('useArtifact fetches data', async () => {\n  const { result } = renderHook(() => useArtifact('123'));\n\n  // Initially loading\n  expect(result.current.isLoading).toBe(true);\n\n  // Eventually has data\n  await waitFor(() => {\n    expect(result.current.data).toBeDefined();\n  });\n});\n```\n\n### Context Hook\nTest hooks that use context.\n\n```typescript\ntest('useChatContext provides sendMessage', () => {\n  const wrapper = ({ children }) => (\n    <ChatProvider>{children}</ChatProvider>\n  );\n\n  const { result } = renderHook(() => useChatContext(), { wrapper });\n\n  expect(typeof result.current.sendMessage).toBe('function');\n});\n```\n\n## Integration Test Patterns\n\n### Multi-Component Flow\nTest components working together.\n\n```typescript\ntest('form submits and shows success', async () => {\n  render(\n    <FormProvider>\n      <CreateSourceForm />\n    </FormProvider>\n  );\n\n  await userEvent.type(screen.getByLabelText('Name'), 'Test Source');\n  await userEvent.click(screen.getByRole('button', { name: 'Create' }));\n\n  await waitFor(() => {\n    expect(screen.getByText('Source created')).toBeVisible();\n  });\n});\n```\n\n### Context Updates\nTest context changes affect components.\n\n```typescript\ntest('selecting source updates context', async () => {\n  render(\n    <SelectionProvider>\n      <SourceList />\n      <SelectionSummary />\n    </SelectionProvider>\n  );\n\n  await userEvent.click(screen.getByTestId('source-1-checkbox'));\n\n  expect(screen.getByTestId('selection-count')).toHaveTextContent('1 selected');\n});\n```\n\n## E2E Test Patterns\n\n### Full User Flow\nTest complete user journey.\n\n```typescript\ntest('user creates and edits artifact', async ({ page }) => {\n  // Navigate\n  await page.goto('/sources');\n\n  // Select source\n  await page.click('[data-testid=\"source-1\"]');\n\n  // Generate\n  await page.click('text=Generate');\n  await page.waitForSelector('.artifact');\n\n  // Edit via chat\n  await page.fill('.chat-input', 'make it shorter');\n  await page.press('.chat-input', 'Enter');\n\n  // Verify update\n  await expect(page.locator('.artifact')).toContainText('shorter version');\n});\n```\n\n### Visual Regression\nScreenshot testing for UI.\n\n```typescript\ntest('dashboard matches snapshot', async ({ page }) => {\n  await page.goto('/dashboard');\n  await page.waitForLoadState('networkidle');\n\n  await expect(page).toHaveScreenshot('dashboard.png');\n});\n```\n\n### Error Recovery\nTest error handling end-to-end.\n\n```typescript\ntest('user can retry after error', async ({ page }) => {\n  // Cause error\n  await page.route('/api/generate', route => route.abort());\n  await page.click('text=Generate');\n\n  // Verify error shown\n  await expect(page.locator('.error-message')).toBeVisible();\n\n  // Enable network and retry\n  await page.unroute('/api/generate');\n  await page.click('text=Retry');\n\n  // Verify success\n  await expect(page.locator('.artifact')).toBeVisible();\n});\n```\n\n## Mock Patterns\n\n### API Mocking (MSW)\n```typescript\nconst handlers = [\n  rest.get('/api/artifact/:id', (req, res, ctx) => {\n    return res(ctx.json({ id: req.params.id, content: 'Test' }));\n  }),\n];\n\nconst server = setupServer(...handlers);\nbeforeAll(() => server.listen());\nafterAll(() => server.close());\n```\n\n### Context Mocking\n```typescript\nconst mockContext = {\n  artifactId: '123',\n  sendMessage: vi.fn(),\n};\n\nrender(\n  <ChatContext.Provider value={mockContext}>\n    <ChatPanel />\n  </ChatContext.Provider>\n);\n```\n"
    }
  ],
  "tags": [
    "audit",
    "testing",
    "specs",
    "validation",
    "coverage"
  ],
  "dependsOn": [
    "failure-mode-analysis",
    "ui-failure-mode-analysis"
  ]
}