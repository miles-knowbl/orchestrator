{
  "id": "content-analysis",
  "name": "content-analysis",
  "version": "2.0.0",
  "description": "Analyze provided content to extract meaningful information, reusable skills, and recurring patterns. Applies structured decomposition, taxonomy-driven classification, and confidence-scored extraction to transform raw content into actionable knowledge components. Powers the inbox/second-brain extraction pipeline.",
  "phase": "VALIDATE",
  "category": "meta",
  "content": "# Content Analysis\n\nAnalyze provided content to extract meaningful information, skills, and patterns for reuse.\n\n## When to Use\n\n- **Inbox item arrives** --- New content enters the second-brain pipeline and needs decomposition into knowledge components\n- **Skill extraction needed** --- Content contains procedures, instructions, or workflows that should become reusable skills\n- **Pattern discovery requested** --- You have a body of content and want to surface recurring structures, techniques, or anti-patterns\n- **Content audit or review** --- Existing knowledge base needs quality assessment and gap identification\n- **Cross-domain transfer** --- Insights from one domain need to be generalized for application elsewhere\n- **Knowledge base enrichment** --- Second brain needs new entries with proper taxonomy and confidence scoring\n- When you say: \"analyze this content\", \"extract skills from\", \"find patterns in\", \"what's reusable here\", \"break this down\"\n\n## Reference Requirements\n\n**MUST read before applying this skill:**\n\n| Reference | Why Required |\n|-----------|--------------|\n| `content-taxonomy.md` | Classification hierarchy for all content types and knowledge components |\n| `confidence-scoring.md` | Framework for assigning confidence levels to extracted elements |\n\n**Read if applicable:**\n\n| Reference | When Needed |\n|-----------|-------------|\n| `extraction-heuristics.md` | When content is ambiguous or multi-layered and automated heuristics are needed |\n| `pattern-catalog.md` | When matching extracted patterns against known pattern archetypes |\n| `skill-template-guide.md` | When extracted procedures need to be formatted as reusable skill definitions |\n\n**Verification:** Ensure every extracted element has a taxonomy classification, a confidence score, and at least one supporting evidence citation from the source content.\n\n## Required Deliverables\n\n| Deliverable | Location | Condition |\n|-------------|----------|-----------|\n| `ANALYSIS-REPORT.md` | Project root | Always --- full extraction results with scored elements |\n| `EXTRACTED-PATTERNS.md` | Project root | When 2+ patterns identified --- catalog of discovered patterns |\n| `EXTRACTED-SKILLS.md` | Project root | When procedures or workflows found --- reusable skill candidates |\n| `EXTRACTION-LOG.md` | Project root | When content is complex or ambiguous --- decision trail for extraction choices |\n\n## Core Concept\n\nContent Analysis answers: **\"What reusable knowledge lives inside this content?\"**\n\nContent analysis is:\n- **Decompositive** --- Breaks content into atomic knowledge components that can be independently stored, searched, and recombined\n- **Taxonomic** --- Every extracted element is classified within a consistent hierarchy so it can be found and related to other knowledge\n- **Scored** --- Confidence levels accompany every extraction so downstream consumers know how much weight to assign\n- **Evidence-linked** --- Every extracted element traces back to specific passages in the source content\n- **Transfer-oriented** --- Extractions are generalized beyond their original context to maximize reuse across domains\n\nContent analysis is NOT:\n- Summarization (summaries compress; analysis decomposes and classifies)\n- Source collection (that is `context-ingestion`)\n- Synthesis across sources (that is `context-cultivation`)\n- Priority ranking (that is `priority-matrix`)\n- Opinion or recommendation (analysis surfaces what is there, not what to do about it)\n\n## The Content Analysis Process\n\n```\n┌──────────────────────────────────────────────────────────────────┐\n│                   CONTENT ANALYSIS PROCESS                       │\n│                                                                  │\n│  1. CONTENT INTAKE                                               │\n│     └─> Parse structure, identify format, assess scope           │\n│                                                                  │\n│  2. STRUCTURAL DECOMPOSITION                                     │\n│     └─> Break content into segments, sections, and atoms         │\n│                                                                  │\n│  3. TAXONOMY CLASSIFICATION                                      │\n│     └─> Classify each segment by type, domain, and granularity   │\n│                                                                  │\n│  4. PATTERN RECOGNITION                                          │\n│     └─> Identify recurring structures, techniques, anti-patterns │\n│                                                                  │\n│  5. SKILL EXTRACTION                                             │\n│     └─> Pull out procedures, workflows, and reusable methods     │\n│                                                                  │\n│  6. CONFIDENCE SCORING                                           │\n│     └─> Assign confidence to every extracted element             │\n│                                                                  │\n│  7. CROSS-REFERENCE MAPPING                                      │\n│     └─> Link extractions to existing knowledge and each other    │\n│                                                                  │\n│  8. VALIDATION & ASSEMBLY                                        │\n│     └─> Quality check, assemble deliverables, flag gaps          │\n│                                                                  │\n└──────────────────────────────────────────────────────────────────┘\n```\n\n## Step 1: Content Intake\n\nBefore decomposing content, understand what you are working with. This step establishes the scope, format, and structural characteristics of the input.\n\n### Intake Assessment\n\n| Dimension | Questions to Answer |\n|-----------|---------------------|\n| **Format** | Is this prose, code, structured data, conversation, mixed media? |\n| **Length** | How much content? Paragraph, page, chapter, corpus? |\n| **Density** | Information-dense (technical spec) or information-sparse (casual note)? |\n| **Structure** | Headings, lists, code blocks, or unstructured freeform? |\n| **Domain** | Technical, business, creative, scientific, procedural? |\n| **Provenance** | Original work, curated collection, generated output, transcription? |\n\n### Intake Output\n\n```markdown\n### Content Intake Summary\n\n- **Source:** [identifier or description]\n- **Format:** [prose / code / structured / conversation / mixed]\n- **Length:** [word count or section count]\n- **Density:** High / Medium / Low\n- **Structure Level:** [well-structured / semi-structured / unstructured]\n- **Primary Domain:** [domain]\n- **Secondary Domains:** [list if cross-domain]\n- **Provenance:** [original / curated / generated / transcribed]\n- **Estimated Extraction Yield:** High / Medium / Low\n```\n\n### Intake Decision Matrix\n\n| Density | Structure | Approach |\n|---------|-----------|----------|\n| High | Well-structured | Section-by-section deep extraction |\n| High | Unstructured | Chunking pass first, then deep extraction per chunk |\n| Low | Well-structured | Skip structural extraction, focus on key claims |\n| Low | Unstructured | Scan for high-value nuggets, skip bulk content |\n\n## Step 2: Structural Decomposition\n\nBreak the content into progressively smaller units. Each unit becomes a candidate for classification and extraction.\n\n### Decomposition Hierarchy\n\n```\nDocument\n  └── Section (H2-level or thematic boundary)\n        └── Segment (paragraph, code block, list group)\n              └── Atom (single claim, instruction, definition, or data point)\n```\n\n### Decomposition Techniques\n\n| Technique | Description | Best For |\n|-----------|-------------|----------|\n| **Heading-based splitting** | Use existing headings as natural boundaries | Well-structured documents |\n| **Topic shift detection** | Identify where the subject changes | Unstructured prose |\n| **Marker-based parsing** | Split on code fences, list markers, or formatting | Mixed-format content |\n| **Sentence-level analysis** | Treat each sentence as a potential atom | Dense technical content |\n| **Dialogue turn splitting** | Split on speaker changes | Conversations and interviews |\n\n### Segment Classification During Decomposition\n\nAs you decompose, tag each segment with its structural role:\n\n| Role | Description | Example |\n|------|-------------|---------|\n| **Declarative** | States a fact or definition | \"REST APIs use HTTP methods for CRUD operations\" |\n| **Procedural** | Describes steps or instructions | \"First, configure the database connection\" |\n| **Evaluative** | Expresses judgment or comparison | \"React outperforms Vue in large-scale applications\" |\n| **Exemplary** | Provides a concrete example or illustration | \"For instance, a shopping cart service...\" |\n| **Contextual** | Provides background or framing | \"In the early 2000s, microservices emerged...\" |\n| **Cautionary** | Warns against something | \"Never store passwords in plaintext\" |\n\n### Decomposition Checklist\n\n```markdown\n- [ ] Content divided into sections with clear boundaries\n- [ ] Each section broken into segments (paragraph-level)\n- [ ] Key segments decomposed to atomic level\n- [ ] Every segment tagged with structural role\n- [ ] No content orphaned or skipped\n- [ ] Hierarchical relationships preserved (atom → segment → section)\n```\n\n## Step 3: Taxonomy Classification\n\nEvery segment and atom receives a classification within a multi-dimensional taxonomy. Consistent classification enables search, retrieval, and relationship mapping across the knowledge base.\n\n### Primary Taxonomy Dimensions\n\n| Dimension | Values | Purpose |\n|-----------|--------|---------|\n| **Content Type** | concept, procedure, pattern, principle, example, reference, opinion, data | What kind of knowledge is this? |\n| **Domain** | engineering, design, business, operations, meta, cross-domain | What field does this belong to? |\n| **Granularity** | atomic, composite, framework | How self-contained is this? |\n| **Actionability** | actionable, informational, contextual | Can you do something with it directly? |\n| **Durability** | evergreen, seasonal, ephemeral | How long will this remain valid? |\n\n### Content Type Definitions\n\n| Type | Definition | Signal Phrases |\n|------|-----------|----------------|\n| **Concept** | An idea, model, or mental framework | \"X is...\", \"The idea of...\", \"Fundamentally...\" |\n| **Procedure** | Step-by-step instructions for achieving a result | \"First...\", \"To do X...\", \"The process is...\" |\n| **Pattern** | A recurring solution structure applicable across contexts | \"A common approach is...\", \"This pattern...\" |\n| **Principle** | A guiding rule or heuristic for decision-making | \"Always...\", \"Never...\", \"Prefer X over Y\" |\n| **Example** | A concrete instance illustrating a concept or procedure | \"For instance...\", \"Consider the case of...\" |\n| **Reference** | Factual data, API signatures, configuration values | Tables, lists of parameters, version numbers |\n| **Opinion** | A subjective assessment or recommendation | \"I believe...\", \"The best approach is...\", \"We prefer...\" |\n| **Data** | Quantitative information, metrics, measurements | Numbers, percentages, benchmarks, statistics |\n\n### Classification Template\n\nFor each significant segment or atom:\n\n```markdown\n### [Segment Title or Summary]\n\n- **Content Type:** [concept / procedure / pattern / principle / example / reference / opinion / data]\n- **Domain:** [engineering / design / business / operations / meta / cross-domain]\n- **Granularity:** [atomic / composite / framework]\n- **Actionability:** [actionable / informational / contextual]\n- **Durability:** [evergreen / seasonal / ephemeral]\n- **Keywords:** [3-5 descriptive terms]\n- **Source Location:** [section/paragraph/line reference]\n```\n\n### Classification Quality Rules\n\n| Rule | Rationale |\n|------|-----------|\n| **Single primary type** | Each element gets one content type; avoid double-classification |\n| **Domain may be multiple** | Cross-domain elements list primary + secondary domains |\n| **Durability requires justification** | If marked evergreen, explain why it will not age |\n| **Opinions are labeled honestly** | Subjective content is typed as opinion, even when authoritative |\n| **Keywords match existing vocabulary** | Reuse terms from the knowledge base before inventing new ones |\n\n## Step 4: Pattern Recognition\n\nPatterns are recurring structures that transcend their immediate context. This step identifies patterns that can be generalized and cataloged for reuse.\n\n### Pattern Detection Strategies\n\n| Strategy | Method | Yields |\n|----------|--------|--------|\n| **Repetition scanning** | Look for structures, phrases, or approaches that appear multiple times | Frequency patterns |\n| **Analogy detection** | Identify elements that resemble known patterns from the pattern catalog | Archetypal matches |\n| **Inversion analysis** | Examine what the content avoids or warns against | Anti-patterns |\n| **Abstraction laddering** | Climb from specific examples to the general principle they embody | Design principles |\n| **Relationship mapping** | Chart how elements depend on, enable, or conflict with each other | Structural patterns |\n\n### Pattern Types\n\n| Type | Description | Example |\n|------|-------------|---------|\n| **Solution pattern** | A reusable approach to a recurring problem | \"Use a queue to decouple producers from consumers\" |\n| **Process pattern** | A repeatable sequence of steps that produces consistent results | \"Always validate input before processing\" |\n| **Structural pattern** | A recurring organizational shape | \"Hub-and-spoke architecture for centralized control\" |\n| **Communication pattern** | A recurring way information flows or is presented | \"Decision records follow context-decision-consequences format\" |\n| **Anti-pattern** | A recurring approach that produces poor results | \"Premature optimization at the expense of readability\" |\n| **Transition pattern** | A recurring way systems or processes evolve | \"Start monolithic, extract services as boundaries emerge\" |\n\n### Pattern Documentation Template\n\n```markdown\n### Pattern: [Descriptive Name]\n\n**Type:** [solution / process / structural / communication / anti-pattern / transition]\n**Confidence:** [high / medium / low]\n**Evidence Count:** [N] occurrences in source content\n**Generalizability:** [universal / domain-specific / context-dependent]\n\n**Description:**\n[Clear explanation of the pattern in domain-neutral language]\n\n**Source Evidence:**\n1. [Source location]: \"[Relevant excerpt]\"\n2. [Source location]: \"[Relevant excerpt]\"\n\n**When to Apply:**\n- [Conditions under which this pattern is useful]\n\n**When to Avoid:**\n- [Conditions under which this pattern is harmful or inappropriate]\n\n**Related Patterns:**\n- [Complementary patterns]\n- [Alternative patterns]\n- [Conflicting patterns]\n```\n\n### Pattern Quality Criteria\n\n```markdown\n- [ ] Pattern appears at least twice in the source content (or once with strong analogy to known pattern)\n- [ ] Pattern is described in domain-neutral terms where possible\n- [ ] When-to-apply and when-to-avoid are both specified\n- [ ] Confidence level reflects evidence strength\n- [ ] Related patterns are identified\n```\n\n## Step 5: Skill Extraction\n\nSkills are reusable procedures or workflows that can be applied independently. This step identifies procedural knowledge and formats it for the skill library.\n\n### Skill Detection Signals\n\n| Signal | Description | Example |\n|--------|-------------|---------|\n| **Imperative sequences** | Ordered steps that produce a result | \"1. Create the config file 2. Set the port 3. Start the server\" |\n| **Decision trees** | Branching logic for handling different conditions | \"If X, then do Y; otherwise do Z\" |\n| **Checklists** | Items that must be verified or completed | \"Before deploying, ensure: tests pass, docs updated, changelog written\" |\n| **Recipes** | Input-process-output descriptions with specific parameters | \"Take the user ID, query the database, return the profile object\" |\n| **Troubleshooting guides** | Diagnosis and resolution paths | \"If you see error X, check Y, then try Z\" |\n\n### Skill Extraction Template\n\n```markdown\n### Extracted Skill: [Name]\n\n**Source Location:** [where in the content this was found]\n**Extraction Confidence:** [high / medium / low]\n**Completeness:** [complete / partial --- needs additional steps / fragment --- needs significant expansion]\n\n**Trigger:** [When would someone invoke this skill?]\n**Input:** [What information or preconditions are required?]\n**Output:** [What does successful execution produce?]\n\n**Procedure:**\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n...\n\n**Decision Points:**\n- [Conditions that change the procedure]\n\n**Error Handling:**\n- [What can go wrong and how to handle it]\n\n**Prerequisites:**\n- [Skills, tools, or knowledge needed before starting]\n\n**Skill Library Fit:**\n- **Phase:** [which skill library phase this belongs to]\n- **Category:** [core / specialized / meta / infra]\n- **Existing Overlap:** [does this duplicate or extend an existing skill?]\n```\n\n### Skill Quality Assessment\n\n| Quality | Criterion | Pass If |\n|---------|-----------|---------|\n| **Self-contained** | Can someone follow this without the source content? | Steps are complete and unambiguous |\n| **Repeatable** | Will this produce the same result each time? | No implicit assumptions or missing context |\n| **Transferable** | Can this be applied outside its original context? | Domain-specific terms are defined or generalizable |\n| **Testable** | Can you verify the skill was applied correctly? | Output is observable and measurable |\n| **Scoped** | Does this do one thing well? | Single clear purpose, not a multi-skill bundle |\n\n## Step 6: Confidence Scoring\n\nEvery extracted element --- pattern, skill, classification, claim --- receives a confidence score. Confidence scoring is the mechanism that separates rigorous analysis from speculation.\n\n### Confidence Framework\n\n| Level | Score | Definition | Evidence Threshold |\n|-------|-------|------------|--------------------|\n| **Definitive** | 0.9-1.0 | Explicitly stated, unambiguous, verifiable | Direct quote, formal definition, or code |\n| **Strong** | 0.7-0.89 | Clearly implied, well-supported, minor inference | Multiple supporting passages, consistent context |\n| **Moderate** | 0.5-0.69 | Reasonable inference with some uncertainty | Single passage with supporting context |\n| **Tentative** | 0.3-0.49 | Plausible but speculative, limited evidence | Indirect inference, pattern matching without confirmation |\n| **Weak** | 0.0-0.29 | Speculative, based on analogy or extrapolation | No direct evidence, derived from related content |\n\n### Scoring Dimensions\n\nEach confidence score is a composite of three sub-scores:\n\n| Dimension | Question | Weight |\n|-----------|----------|--------|\n| **Explicitness** | How directly does the source state this? | 40% |\n| **Consistency** | Does other content in the source support this? | 35% |\n| **Completeness** | Is the extraction capturing the full picture? | 25% |\n\n### Composite Score Calculation\n\n```\nconfidence = (explicitness * 0.40) + (consistency * 0.35) + (completeness * 0.25)\n```\n\nEach dimension is scored 0.0-1.0. The composite is the weighted average.\n\n### Confidence Adjustments\n\nApply these adjustments to the raw composite score:\n\n| Adjustment | Condition | Effect |\n|------------|-----------|--------|\n| **Corroboration boost** | Same finding appears in multiple sections | +0.1 |\n| **Contradiction penalty** | Other content contradicts this extraction | -0.15 |\n| **Ambiguity penalty** | Source language is vague or hedging | -0.1 |\n| **Domain authority boost** | Source is authoritative in the extraction domain | +0.05 |\n| **Staleness penalty** | Content is dated and domain is fast-moving | -0.1 |\n\n### Confidence Scoring Checklist\n\n```markdown\n- [ ] Every extracted element has a confidence score\n- [ ] Scores are justified with evidence citations\n- [ ] Adjustments are documented (e.g., \"+0.1 corroboration: also stated in section 3\")\n- [ ] No scores above 0.9 without direct quotes or formal definitions\n- [ ] No scores below 0.3 without flagging as speculative\n```\n\n## Step 7: Cross-Reference Mapping\n\nExtracted elements do not exist in isolation. This step maps relationships between extractions and connects them to existing knowledge.\n\n### Relationship Types\n\n| Relationship | Description | Notation |\n|--------------|-------------|----------|\n| **Supports** | Element A provides evidence for Element B | A → supports → B |\n| **Contradicts** | Element A conflicts with Element B | A → contradicts → B |\n| **Extends** | Element A builds on Element B | A → extends → B |\n| **Instantiates** | Element A is a concrete example of Element B | A → instantiates → B |\n| **Requires** | Element A depends on Element B | A → requires → B |\n| **Supersedes** | Element A replaces or updates Element B | A → supersedes → B |\n| **Complements** | Element A and B together provide more value than either alone | A ↔ complements ↔ B |\n\n### Cross-Reference Matrix\n\n```markdown\n### Extraction Cross-References\n\n| Element | Supports | Contradicts | Extends | Related Existing Knowledge |\n|---------|----------|-------------|---------|----------------------------|\n| PAT-001 | SKL-002 | --- | --- | [existing pattern X] |\n| SKL-001 | PAT-001, PAT-003 | --- | [existing skill Y] | --- |\n| CLM-001 | CLM-003 | CLM-005 | --- | [existing claim Z] |\n```\n\n### Integration with Existing Knowledge Base\n\nFor each extraction, check:\n\n```markdown\n- [ ] Does this duplicate an existing knowledge base entry?\n  - If yes: Flag as potential update to existing entry\n- [ ] Does this extend an existing entry?\n  - If yes: Note the entry ID and the extension\n- [ ] Does this contradict an existing entry?\n  - If yes: Flag for reconciliation with confidence comparison\n- [ ] Is this genuinely novel?\n  - If yes: Mark as candidate for new knowledge base entry\n```\n\n## Step 8: Validation and Assembly\n\nFinal quality pass before assembling deliverables. This step ensures every extraction meets quality standards and the output is internally consistent.\n\n### Validation Checklist\n\n```markdown\n## Extraction Quality Review\n\n### Completeness\n- [ ] All content sections have been analyzed (no skipped sections)\n- [ ] Every significant claim has been extracted or explicitly deprioritized\n- [ ] Extraction depth matches content density (high density = deep extraction)\n- [ ] Gaps between content and extractions are documented\n\n### Classification Quality\n- [ ] Every extraction has a taxonomy classification\n- [ ] Content types are correctly assigned (procedure vs. concept, etc.)\n- [ ] Domain assignments are accurate\n- [ ] Keywords are consistent with existing vocabulary\n\n### Confidence Quality\n- [ ] Every extraction has a confidence score\n- [ ] Scores are calibrated (not all clustered at one level)\n- [ ] High-confidence extractions have strong evidence\n- [ ] Low-confidence extractions are flagged appropriately\n\n### Pattern Quality\n- [ ] Patterns are described in generalizable terms\n- [ ] Each pattern has when-to-apply and when-to-avoid\n- [ ] Anti-patterns are labeled as such\n- [ ] Pattern evidence is cited\n\n### Skill Quality\n- [ ] Extracted skills are self-contained\n- [ ] Procedures are complete (no missing steps)\n- [ ] Decision points are documented\n- [ ] Skill library fit is assessed\n\n### Cross-Reference Quality\n- [ ] Relationships between extractions are mapped\n- [ ] Connections to existing knowledge are noted\n- [ ] Contradictions are surfaced, not hidden\n- [ ] Duplicate candidates are flagged\n```\n\n### Assembly Sequence\n\n1. Compile ANALYSIS-REPORT.md with all extractions, classifications, and scores\n2. Extract patterns into EXTRACTED-PATTERNS.md (if 2+ patterns found)\n3. Extract skills into EXTRACTED-SKILLS.md (if procedures found)\n4. Write EXTRACTION-LOG.md for complex or ambiguous content\n5. Final consistency pass across all deliverables\n\n### Coverage Thresholds\n\n| Metric | Target | Minimum |\n|--------|--------|---------|\n| Content analyzed | 100% of significant sections | 90% of significant sections |\n| Extractions classified | 100% | 100% (no unclassified extractions) |\n| Confidence scored | 100% | 100% (no unscored extractions) |\n| Cross-references mapped | All obvious relationships | Major relationships identified |\n| Patterns documented | All recurring structures | Patterns with 2+ occurrences |\n\n## Output Formats\n\n### Quick Format (Single document, low-medium density)\n\n```markdown\n# Content Analysis: [Source Title]\n\n**Analyzed:** [Date]\n**Source:** [identifier]\n**Content Type:** [format] | **Density:** [level] | **Domain:** [domain]\n\n## Key Extractions\n\n### Concepts\n1. **[Concept Name]** (confidence: X.XX) --- [one-line description]\n2. **[Concept Name]** (confidence: X.XX) --- [one-line description]\n\n### Patterns\n1. **[Pattern Name]** ([type], confidence: X.XX) --- [one-line description]\n\n### Skills\n1. **[Skill Name]** (confidence: X.XX, completeness: [level]) --- [one-line description]\n\n### Principles\n1. **[Principle]** (confidence: X.XX) --- [one-line description]\n\n## Confidence Summary\n- Definitive (0.9+): [N] extractions\n- Strong (0.7-0.89): [N] extractions\n- Moderate (0.5-0.69): [N] extractions\n- Tentative/Weak (<0.5): [N] extractions\n\n## Gaps\n- [Missing information or coverage gaps]\n\n## Cross-References\n- [Connections to existing knowledge]\n```\n\n### Full Format (Complex content, high density, or multi-section)\n\n```markdown\n# Content Analysis Report\n\n**Source:** [title or identifier]\n**Analyzed:** [date]\n**Analyst Context:** [what prompted this analysis]\n\n## Executive Summary\n\n[2-3 paragraph overview of findings. Lead with highest-value extraction.\nState overall confidence. Note key patterns and gaps.]\n\n## Content Intake Assessment\n\n[Intake summary from Step 1]\n\n## Structural Decomposition\n\n### Section Map\n| Section | Segments | Atoms | Dominant Type | Key Finding |\n|---------|----------|-------|---------------|-------------|\n| [Name] | [N] | [N] | [type] | [one-line] |\n\n## Classified Extractions\n\n### Concepts (N found)\n\n#### [Concept 1 Title]\n- **Classification:** concept / [domain] / [granularity] / [actionability] / [durability]\n- **Confidence:** X.XX ([explicitness] / [consistency] / [completeness])\n- **Evidence:** [source location and excerpt]\n- **Keywords:** [terms]\n- **Description:** [full description]\n\n[Repeat for each concept...]\n\n### Patterns (N found)\n\n[Full pattern documentation from Step 4 template]\n\n### Skills (N found)\n\n[Full skill documentation from Step 5 template]\n\n### Principles (N found)\n\n[Each principle with classification and confidence]\n\n### Reference Data (N found)\n\n[Factual extractions with source citations]\n\n## Cross-Reference Map\n\n[Matrix from Step 7]\n\n## Confidence Distribution\n\n| Level | Count | Percentage | Notes |\n|-------|-------|------------|-------|\n| Definitive (0.9+) | [N] | [%] | [notes] |\n| Strong (0.7-0.89) | [N] | [%] | [notes] |\n| Moderate (0.5-0.69) | [N] | [%] | [notes] |\n| Tentative (0.3-0.49) | [N] | [%] | [notes] |\n| Weak (<0.3) | [N] | [%] | [notes] |\n\n## Gaps and Limitations\n\n| Gap | Impact | Suggested Action |\n|-----|--------|-----------------|\n| [Description] | [Effect on analysis quality] | [How to address] |\n\n## Recommendations for Knowledge Base\n\n- **New entries:** [N] extractions recommended for addition\n- **Updates:** [N] existing entries should be updated\n- **Conflicts:** [N] contradictions need reconciliation\n- **Skills:** [N] procedures ready for skill library formatting\n\n## Extraction Log\n\n[Major decisions, ambiguities resolved, elements deprioritized]\n```\n\n## Common Patterns\n\n### The Deep Dissection\n\nProcess a single dense document with maximum extraction depth. Every paragraph yields classified atoms. Every claim is scored. Every procedure is extracted as a skill candidate. Use the full decomposition hierarchy and apply all taxonomy dimensions.\n\n**Use when:** Analyzing a comprehensive technical guide, a detailed specification, or an authoritative reference that is likely to yield many high-confidence extractions.\n\n### The Pattern Sweep\n\nSkim content for structural patterns rather than individual knowledge atoms. Focus on how the content is organized, what approaches recur, and what the implicit rules are. Classification focuses on pattern and principle types rather than concept and reference types.\n\n**Use when:** Content is a collection of examples (case studies, code samples, project retrospectives) where the value is in the recurring approaches rather than individual facts.\n\n### The Skill Harvest\n\nPrioritize procedural knowledge extraction above all other types. Scan for imperative sequences, decision trees, checklists, and troubleshooting guides. Every extracted skill is assessed for completeness and library fit. Non-procedural content is classified quickly but not deeply extracted.\n\n**Use when:** Content is a how-to guide, runbook, playbook, or instructional material where the primary goal is building reusable procedures.\n\n### The Triage Scan\n\nRapid, shallow analysis to determine whether content warrants deeper analysis. Classify at the section level only, score confidence broadly, and produce a quick-format output with recommendations for which sections deserve full analysis.\n\n**Use when:** Large volume of content arrives at once and you need to prioritize what to analyze deeply. Typical for inbox processing where not all items are equally valuable.\n\n## Relationship to Other Skills\n\n| Skill | Relationship |\n|-------|--------------|\n| `context-ingestion` | Ingestion collects and organizes raw sources; content analysis decomposes individual sources into knowledge components |\n| `context-cultivation` | Cultivation synthesizes across sources; content analysis extracts within a single source. Analysis feeds cultivation with classified components |\n| `metadata-extraction` | Metadata extraction captures structural metadata (author, date, format); content analysis extracts semantic content (concepts, patterns, skills) |\n| `priority-matrix` | Analysis produces classified extractions; priority matrix ranks them for action |\n| `proposal-builder` | Analyzed content provides evidence and patterns that strengthen proposals |\n| `code-verification` | Verification validates code structure; content analysis validates knowledge structure |\n\n## Key Principles\n\n**Decompose before classifying.** Break content into atoms before attempting to classify. Trying to classify large chunks leads to vague, multi-type labels. Atomic elements get precise classifications.\n\n**Confidence is not optional.** Every extraction must carry a score. Unscored extractions are indistinguishable from speculation. The score does not need to be perfect --- it needs to exist and be justified.\n\n**Taxonomy consistency enables retrieval.** The value of classification collapses if every analysis invents new categories. Reuse existing taxonomy terms before creating new ones. When new terms are genuinely needed, define them explicitly and add them to the taxonomy.\n\n**Extract for transfer, not for record.** The goal is not to summarize the source --- it is to extract knowledge that can be applied elsewhere. Always ask: \"Would this extraction be useful to someone who never sees the source content?\"\n\n**Anti-patterns are patterns.** What the content warns against, avoids, or demonstrates as failure is as valuable as positive patterns. Catalog anti-patterns with equal rigor.\n\n**Gaps in the content are findings.** When important topics are absent from the source, that absence is itself an extraction. Document what is missing with the same precision as what is present.\n\n## References\n\n- `references/content-taxonomy.md`: Full classification hierarchy with definitions, examples, and decision trees for ambiguous cases\n- `references/confidence-scoring.md`: Detailed scoring rubrics, calibration examples, and adjustment rules for all confidence dimensions\n- `references/extraction-heuristics.md`: Signal phrases, structural markers, and automated heuristics for identifying extractable elements\n- `references/pattern-catalog.md`: Catalog of known pattern archetypes for matching during pattern recognition\n- `references/skill-template-guide.md`: Formatting guide for converting extracted procedures into skill library entries",
  "references": [
    {
      "name": "confidence-scoring.md",
      "path": "references/confidence-scoring.md",
      "content": "# Confidence Scoring Reference\n\nDetailed rubrics for assigning confidence scores to every extracted element.\nEvery extraction must carry a score. This reference ensures scores are calibrated, justified, and comparable.\n\n## Scoring Dimensions\n\nEach confidence score is a weighted composite of three dimensions.\n\n### Dimension 1: Evidence Strength (Weight: 40%)\n\nHow directly does the source content support this extraction?\n\n| Score | Label | Criteria | Example |\n|-------|-------|----------|---------|\n| 1.0 | Verbatim | Direct quote or formal definition present | Source says: \"The timeout is 30 seconds\" |\n| 0.8 | Explicit | Clearly stated, minor paraphrasing needed | Source explains the concept in a full paragraph |\n| 0.6 | Implied | Logically follows from stated content | Source describes behavior that implies a design principle |\n| 0.4 | Inferred | Requires connecting multiple passages | Two sections together suggest a pattern |\n| 0.2 | Analogized | Based on similarity to stated content | Source discusses X; extraction generalizes to Y |\n| 0.0 | Absent | No supporting evidence in source | Pure speculation |\n\n### Dimension 2: Specificity (Weight: 35%)\n\nHow precise and unambiguous is the extracted knowledge?\n\n| Score | Label | Criteria | Example |\n|-------|-------|----------|---------|\n| 1.0 | Exact | Precise values, names, or definitions | \"Use port 8080 with TLS 1.3\" |\n| 0.8 | Specific | Clear scope with minor ambiguity | \"Configure the database connection pool\" |\n| 0.6 | Scoped | General topic with bounded applicability | \"Caching improves read-heavy workloads\" |\n| 0.4 | Broad | Applies to a wide domain, limited precision | \"Performance matters for user experience\" |\n| 0.2 | Vague | Unclear scope, multiple interpretations possible | \"Consider the architecture carefully\" |\n| 0.0 | Undefined | No discernible specific meaning | Content too ambiguous to extract |\n\n### Dimension 3: Actionability (Weight: 25%)\n\nCan someone act on this extraction without additional research?\n\n| Score | Label | Criteria | Example |\n|-------|-------|----------|---------|\n| 1.0 | Executable | Complete steps, ready to follow | Full procedure with all parameters specified |\n| 0.8 | Near-complete | Minor details need filling in | Procedure with project-specific values as placeholders |\n| 0.6 | Directional | Points toward action, needs elaboration | \"Use a queue between the services\" (which queue? what config?) |\n| 0.4 | Suggestive | Hints at an approach without specifics | \"Consider asynchronous processing\" |\n| 0.2 | Awareness | Informs thinking but not action | \"Distributed systems have consistency tradeoffs\" |\n| 0.0 | Inert | No actionable content | Pure background context |\n\n## Composite Score Calculation\n\n```\nconfidence = (evidence_strength * 0.40) + (specificity * 0.35) + (actionability * 0.25)\n```\n\nRound to two decimal places. Always report the composite and the three sub-scores.\n\n**Format:** `0.72 (evidence: 0.8 / specificity: 0.6 / actionability: 0.8)`\n\n## Calibration Examples\n\n### Score 0.95 --- Definitive\n**Extraction:** \"The API rate limit is 100 requests per minute per API key.\"\n**Scoring:** evidence=1.0 (verbatim quote), specificity=1.0 (exact values), actionability=0.8 (actionable with API key)\n**Composite:** (1.0 * 0.4) + (1.0 * 0.35) + (0.8 * 0.25) = 0.95\n\n### Score 0.78 --- Strong\n**Extraction:** \"Use retry with exponential backoff when calling external services.\"\n**Scoring:** evidence=0.8 (explicit recommendation), specificity=0.8 (clear technique), actionability=0.6 (needs implementation details)\n**Composite:** (0.8 * 0.4) + (0.8 * 0.35) + (0.6 * 0.25) = 0.78\n\n### Score 0.61 --- Moderate\n**Extraction:** \"The team prefers event-driven architecture for new services.\"\n**Scoring:** evidence=0.6 (implied from multiple examples), specificity=0.6 (scoped to new services), actionability=0.6 (directional)\n**Composite:** (0.6 * 0.4) + (0.6 * 0.35) + (0.6 * 0.25) = 0.60\n\n### Score 0.44 --- Tentative\n**Extraction:** \"Performance testing should happen before major releases.\"\n**Scoring:** evidence=0.4 (inferred from a postmortem), specificity=0.6 (scoped to releases), actionability=0.4 (suggestive only)\n**Composite:** (0.4 * 0.4) + (0.6 * 0.35) + (0.4 * 0.25) = 0.47\n\n### Score 0.25 --- Weak\n**Extraction:** \"The system may benefit from a service mesh.\"\n**Scoring:** evidence=0.2 (analogized from a different context), specificity=0.4 (broad), actionability=0.2 (awareness only)\n**Composite:** (0.2 * 0.4) + (0.4 * 0.35) + (0.2 * 0.25) = 0.27\n\n## Score Adjustments\n\nApply these after computing the raw composite. Document every adjustment.\n\n| Adjustment | Condition | Effect | Justification Required |\n|------------|-----------|--------|----------------------|\n| Corroboration boost | Same finding in 2+ independent sections | +0.10 | Cite both sections |\n| Repetition boost | Same finding stated 3+ times | +0.05 | Cite occurrences (weaker than corroboration; repetition may reflect emphasis, not independence) |\n| Contradiction penalty | Source content contradicts this extraction elsewhere | -0.15 | Cite the contradicting passage |\n| Ambiguity penalty | Source uses hedging language (\"might\", \"could\", \"sometimes\") | -0.10 | Quote the hedging phrase |\n| Authority boost | Source is an authoritative reference for this domain | +0.05 | State the authority basis |\n| Staleness penalty | Content is dated and domain evolves rapidly | -0.10 | State the content age and domain volatility |\n| Incomplete context penalty | Extraction requires context not present in source | -0.10 | Describe the missing context |\n\n**Adjustment cap:** Final score must remain in [0.0, 1.0]. Adjustments never push past these bounds.\n\n## Edge Case Rules\n\n### When evidence is strong but actionability is zero\nScore the composite normally. An informational extraction (e.g., a historical fact) can have high confidence even if there is nothing to \"do\" with it. The actionability dimension simply receives a low sub-score.\n\n### When the source contradicts itself\nExtract both positions. Each gets a contradiction penalty (-0.15). Add a cross-reference noting the conflict. Neither extraction should exceed 0.7 unless one position has substantially more evidence.\n\n### When content is opinion from an authority\nClassify as opinion in the taxonomy. Score evidence normally (the opinion IS the content). Add a note: \"Scored as stated opinion, not verified claim.\" Do not apply authority boost to opinion content.\n\n### When a single source states something definitively but it is domain-controversial\nCap at 0.85. Add note: \"Single-source definitive statement in contested domain. Corroboration from independent sources would raise confidence.\"\n\n### When extraction combines multiple source passages\nScore evidence based on the weakest passage required for the extraction to hold. If removing any one passage would invalidate the extraction, that passage's evidence level is the ceiling.\n\n## Reporting Format\n\nEvery scored extraction must include:\n\n```markdown\n**Confidence:** 0.XX (evidence: X.X / specificity: X.X / actionability: X.X)\n**Adjustments:** [+/-0.XX reason] or \"None\"\n**Evidence:** [source location]: \"[brief excerpt]\"\n```\n"
    },
    {
      "name": "content-taxonomy.md",
      "path": "references/content-taxonomy.md",
      "content": "# Content Taxonomy Reference\n\nClassification hierarchy for all content types encountered during content analysis.\nUse this reference to assign consistent, precise taxonomy labels to every extracted element.\n\n## Primary Content Types\n\n### Tutorial\n**Definition:** Step-by-step instructional content that teaches a skill through guided practice.\n**Distinguishing trait:** Combines explanation with progressive exercises; the reader builds something.\n**Signal phrases:** \"In this tutorial...\", \"Let's build...\", \"Follow along...\", \"By the end you will...\"\n**Example:** \"In this tutorial, we will build a REST API using Express. First, initialize the project...\"\n\n### Reference\n**Definition:** Factual lookup content --- API signatures, configuration options, data tables, specifications.\n**Distinguishing trait:** Optimized for scanning, not sequential reading. Value is in precision, not narrative.\n**Signal phrases:** \"Parameters:\", \"Returns:\", \"Default value:\", \"Supported values:\"\n**Example:** A table of CLI flags with descriptions, types, and default values.\n\n### Pattern\n**Definition:** A recurring solution structure that transcends its immediate context.\n**Distinguishing trait:** Describes the shape of a solution, not the specific implementation.\n**Signal phrases:** \"A common approach...\", \"This pattern...\", \"Recurring structure...\", \"Typically solved by...\"\n**Example:** \"The circuit breaker pattern wraps calls to external services, failing fast when the service is down.\"\n\n### Procedure\n**Definition:** A concrete sequence of actions that produces a specific outcome.\n**Distinguishing trait:** Imperative steps with a defined end state. Unlike tutorials, no teaching narrative.\n**Signal phrases:** \"Step 1:\", \"First... then... finally...\", \"To achieve X, do Y\", \"Run the following...\"\n**Example:** \"To deploy: 1) Run tests. 2) Build artifacts. 3) Push to registry. 4) Apply manifests.\"\n\n### Concept\n**Definition:** An idea, model, or mental framework that helps the reader understand a domain.\n**Distinguishing trait:** Explanatory, not actionable. Builds mental models rather than producing outputs.\n**Signal phrases:** \"X is...\", \"The idea behind...\", \"Fundamentally...\", \"This means that...\"\n**Example:** \"Eventual consistency means that all replicas will converge to the same state, given enough time.\"\n\n### Example\n**Definition:** A concrete instance that illustrates an abstract concept, pattern, or principle.\n**Distinguishing trait:** Specific and situated. References real or realistic scenarios.\n**Signal phrases:** \"For instance...\", \"Consider...\", \"Suppose...\", \"A real-world case...\"\n**Example:** \"Consider a shopping cart service: when the user adds an item, the event is published to a topic.\"\n\n### Anti-Pattern\n**Definition:** A recurring approach that produces poor outcomes despite appearing reasonable.\n**Distinguishing trait:** Describes what NOT to do, often with explanation of why it fails.\n**Signal phrases:** \"Avoid...\", \"Do not...\", \"A common mistake...\", \"This leads to...\", \"Pitfall:\"\n**Example:** \"Storing session state in local memory seems simple but breaks when you scale horizontally.\"\n\n## Secondary Content Types\n\n| Type | Definition | When to Use |\n|------|-----------|-------------|\n| **Principle** | A guiding rule or heuristic for decision-making | \"Always...\", \"Never...\", \"Prefer X over Y\" |\n| **Opinion** | A subjective assessment with explicit or implicit bias | \"I believe...\", \"The best...\", \"We prefer...\" |\n| **Data** | Quantitative information --- metrics, benchmarks, statistics | Numbers, percentages, measurements |\n| **Narrative** | Story-form content providing context or motivation | Case studies, postmortems, historical accounts |\n\n## Decision Tree for Ambiguous Cases\n\n### Does it teach through guided steps?\n- YES with exercises/building something --> **Tutorial**\n- YES with bare imperative steps only --> **Procedure**\n\n### Does it describe how something works without telling you to do anything?\n- YES and it is abstract/generalizable --> **Concept**\n- YES and it is a specific instance --> **Example**\n\n### Does it describe a recurring solution shape?\n- YES and it is recommended --> **Pattern**\n- YES and it is cautioned against --> **Anti-Pattern**\n\n### Is it optimized for lookup rather than reading?\n- YES --> **Reference**\n\n### Common Misclassifications\n\n| Content | Often Misclassified As | Correct Type | Why |\n|---------|----------------------|--------------|-----|\n| \"Always validate input before processing\" | Procedure | **Principle** | No concrete steps; it is a heuristic |\n| A code snippet showing usage | Reference | **Example** | It illustrates; it does not document an API |\n| \"Here is how we solved the outage\" | Procedure | **Narrative** | Retrospective context, not repeatable steps |\n| \"Avoid using global state\" | Pattern | **Anti-Pattern** | It describes what NOT to do |\n| Numbered config instructions | Tutorial | **Procedure** | No teaching narrative, just steps |\n| \"Event sourcing captures changes as events\" | Pattern | **Concept** | Explains the idea, not the solution shape |\n\n## Taxonomy Dimensions Beyond Type\n\nEvery classified element also receives:\n\n| Dimension | Values | Decision Rule |\n|-----------|--------|---------------|\n| **Domain** | engineering, design, business, operations, meta, cross-domain | What field produced this knowledge? |\n| **Granularity** | atomic, composite, framework | Atomic = single idea. Composite = related cluster. Framework = complete system. |\n| **Actionability** | actionable, informational, contextual | Can someone act on this immediately without further research? |\n| **Durability** | evergreen, seasonal, ephemeral | Evergreen survives 3+ years. Seasonal is version-bound. Ephemeral is event-bound. |\n\n## Compound Content Handling\n\nWhen a single segment contains multiple types (e.g., a concept explained with an example):\n\n1. **Classify by dominant type** --- the type that carries the primary value\n2. **Tag secondary types** --- note the supporting types as metadata\n3. **Split if both types carry independent value** --- create two extractions linked by \"supports\" relationship\n\nExample: \"Eventual consistency (concept) means replicas converge over time. Consider a DNS update (example) --- propagation takes hours but eventually all resolvers agree.\"\n- Primary extraction: Concept (eventual consistency)\n- Secondary extraction: Example (DNS propagation), linked as \"instantiates\" the concept\n\n## Vocabulary Governance\n\nBefore creating a new taxonomy term:\n1. Search existing extractions for synonymous terms\n2. Check this reference for the closest existing type\n3. If genuinely novel, document the new term with definition, signal phrases, and at least two examples\n4. Add it to this reference in the appropriate section\n"
    },
    {
      "name": "extraction-heuristics.md",
      "path": "references/extraction-heuristics.md",
      "content": "# Extraction Heuristics Reference\n\nSignal phrases, structural markers, and detection patterns for identifying extractable content.\nUse this reference during structural decomposition and skill/pattern extraction to avoid missed extractions and false positives.\n\n## Signal Phrases by Content Type\n\n### Procedure Signals\nThese phrases indicate step-by-step instructions worth extracting.\n\n| Signal | Strength | Example |\n|--------|----------|---------|\n| \"Step N:\" / \"1. 2. 3.\" | Strong | Explicit numbered sequence |\n| \"First... then... finally...\" | Strong | Temporal ordering of actions |\n| \"To [achieve X], [do Y]\" | Strong | Goal-action structure |\n| \"Run the following...\" | Strong | Direct imperative |\n| \"Make sure to...\" | Moderate | Imperative with emphasis |\n| \"You will need to...\" | Moderate | Future action framing |\n| \"The process involves...\" | Moderate | Process description (may lack detail) |\n| \"It helps to...\" | Weak | Suggestion, not procedure |\n\n### Pattern Signals\nThese phrases indicate a recurring solution or structure worth cataloging.\n\n| Signal | Strength | Example |\n|--------|----------|---------|\n| \"A common approach is...\" | Strong | Explicitly labeled as recurring |\n| \"This pattern...\" / \"The X pattern\" | Strong | Named pattern reference |\n| \"We always...\" / \"We typically...\" | Strong | Habitual practice implies pattern |\n| \"The standard way to...\" | Moderate | Implies convention |\n| \"This is similar to...\" | Moderate | Analogy suggests pattern recognition |\n| \"In general...\" | Weak | May be too vague |\n\n### Anti-Pattern Signals\nThese phrases indicate cautionary knowledge.\n\n| Signal | Strength | Example |\n|--------|----------|---------|\n| \"Do not...\" / \"Never...\" | Strong | Direct prohibition |\n| \"Avoid...\" / \"Watch out for...\" | Strong | Explicit warning |\n| \"A common mistake is...\" | Strong | Named anti-pattern |\n| \"This leads to problems when...\" | Moderate | Consequence-based warning |\n| \"We learned the hard way...\" | Moderate | Experience-based caution |\n| \"It might seem like... but...\" | Moderate | Counterintuitive warning |\n\n### Concept and Principle Signals\n\n| Signal | Type | Strength |\n|--------|------|----------|\n| \"X is defined as...\" | Concept | Strong |\n| \"The idea behind X is...\" | Concept | Strong |\n| \"This means that...\" / \"In other words...\" | Concept | Moderate |\n| \"Always...\" / \"Never...\" | Principle | Strong |\n| \"Prefer X over Y\" | Principle | Strong |\n| \"The rule of thumb is...\" / \"As a general principle...\" | Principle | Strong |\n| \"When in doubt...\" | Principle | Moderate |\n\n## Structural Markers\n\n### High-Value Structural Indicators\n\n| Marker | What It Suggests | Extraction Priority |\n|--------|-----------------|---------------------|\n| **Numbered lists** | Procedure or ranked items | High --- likely an ordered process |\n| **Code blocks** | Reference data, examples, or procedures | High --- concrete and specific |\n| **Tables** | Reference data or comparison matrices | High --- structured knowledge |\n| **Headings with \"How to...\"** | Procedure | High --- explicit instructional content |\n| **Bullet lists with imperative verbs** | Checklist or procedure | High --- actionable steps |\n| **Blockquotes** | Key quotes, principles, or callouts | Medium --- may be opinion or emphasis |\n| **Bold/italic inline text** | Author-emphasized terms or concepts | Medium --- signals importance |\n| **Admonition blocks (Note, Warning, Tip)** | Principles, anti-patterns, or tips | Medium --- curated knowledge |\n| **Footnotes or asides** | Supplementary context | Low --- often tangential |\n\n### Section-Level Indicators\n\n| Section Title Pattern | Likely Content Type | Extraction Focus |\n|----------------------|--------------------|--------------------|\n| \"Getting Started\" | Tutorial / Procedure | Steps and prerequisites |\n| \"API Reference\" | Reference | Signatures, parameters, return types |\n| \"Best Practices\" | Principles / Patterns | Rules and recurring solutions |\n| \"Troubleshooting\" | Procedure / Anti-Pattern | Diagnostic steps and known pitfalls |\n| \"Architecture\" / \"Design\" | Concept / Pattern | Models and structural approaches |\n| \"FAQ\" | Mixed | Scan for procedures and concepts |\n| \"Changelog\" / \"Release Notes\" | Data / Reference | Low extraction yield; mostly ephemeral |\n\n## Automated Detection Patterns\n\n### Regex-Style Indicators\n\nUse these patterns during structural decomposition to flag candidate segments:\n\n| Pattern | Detects |\n|---------|---------|\n| `^\\d+\\.\\s` (numbered line start) | Procedure step |\n| `^[-*]\\s\\[[ x]\\]` (checkbox) | Checklist item |\n| `^#{1,3}\\s(How to|Setting up|Configure|Install)` | Procedure heading |\n| `^(Note|Warning|Tip|Important|Caution):` | Principle or anti-pattern callout |\n| `^(Always|Never|Avoid|Prefer|Do not)\\s` | Principle or anti-pattern |\n| Triple backtick blocks | Code example or reference data |\n| `\\b(pattern|anti-pattern|approach|technique|strategy)\\b` | Pattern candidate |\n| `\\b(because|therefore|consequently|as a result)\\b` | Causal reasoning (concept support) |\n\n### Density Estimation Heuristic\n\nEstimate information density to calibrate extraction depth:\n\n```\ndensity_score = (code_blocks + tables + lists) / total_paragraphs\n```\n\n| Density Score | Interpretation | Extraction Approach |\n|---------------|---------------|---------------------|\n| > 0.5 | High density | Deep extraction; most segments yield content |\n| 0.2 - 0.5 | Medium density | Selective extraction; focus on structured segments |\n| < 0.2 | Low density | Skim for high-value nuggets; skip filler |\n\n## False Positive Filtering\n\n### Common False Positives\n\n| Looks Like | Actually Is | How to Detect |\n|-----------|-------------|---------------|\n| Procedure (numbered steps) | Narrative timeline (historical sequence) | Steps lack imperative verbs; describe what happened, not what to do |\n| Pattern (repeated structure) | Formatting convention (stylistic repetition) | Structure repeats but content does not generalize |\n| Principle (\"Always do X\") | Contextual advice (applies only in described scenario) | Missing generalizability; bound to specific context |\n| Reference (data table) | Example data (illustrative, not authoritative) | Table labeled \"example\" or contains placeholder values |\n| Anti-pattern (\"Don't do X\") | Personal preference without justification | No consequence described; no evidence of poor outcomes |\n| Concept (definition) | Marketing language (branding, not explaining) | Vague superlatives; no technical substance |\n\n### Filtering Rules\n\n1. **Imperative test:** If it looks like a procedure but has no imperative verbs (\"create\", \"run\", \"configure\"), it is likely narrative. Downgrade to concept or example.\n2. **Generalizability test:** If it looks like a pattern but only applies to one described scenario, it is an example. Reclassify.\n3. **Consequence test:** If it looks like an anti-pattern but describes no negative outcome, it is opinion. Reclassify and lower confidence.\n4. **Placeholder test:** If data contains \"example\", \"sample\", \"foo/bar\", or \"xxx\", it is illustrative. Classify as example, not reference.\n5. **Substance test:** If a \"definition\" contains no technical specifics, it may be marketing. Skip or classify as opinion with low confidence.\n\n## Extraction Priority Matrix\n\nWhen time or scope is limited, prioritize extraction by this matrix:\n\n| Signal Strength | Structural Support | Priority |\n|----------------|-------------------|----------|\n| Strong signal phrase + structured marker | Has heading, code, or table | Extract first |\n| Strong signal phrase only | Prose without structure | Extract second |\n| Structural marker only | No signal phrases | Evaluate carefully; may be formatting artifact |\n| Weak signals only | No structure | Extract only if density is high |\n"
    },
    {
      "name": "pattern-catalog.md",
      "path": "references/pattern-catalog.md",
      "content": "# Pattern Catalog Reference\n\nCatalog of known pattern archetypes used during pattern recognition (Step 4 of content analysis).\nMatch extracted patterns against these archetypes to leverage existing vocabulary and avoid reinvention.\n\n## Pattern Type Index\n\n| Type | Focus | Count in Catalog |\n|------|-------|-----------------|\n| Behavioral | How components interact at runtime | 5 archetypes |\n| Structural | How components are organized | 4 archetypes |\n| Architectural | System-level design decisions | 4 archetypes |\n| Workflow | How processes flow through stages | 4 archetypes |\n| Anti-Pattern | Recurring approaches that produce poor outcomes | 4 archetypes |\n\n## Behavioral Patterns\n\n### BEH-01: Producer-Consumer Decoupling\n**Recognition criteria:** One component generates work; another processes it; a buffer sits between them.\n**Variants:** Queue-based, event-driven, stream-based.\n**Signal phrases:** \"decouple\", \"buffer\", \"async processing\", \"work queue\", \"event bus\"\n**Generalizes to:** Any situation where production rate differs from consumption rate.\n\n### BEH-02: Circuit Breaker\n**Recognition criteria:** A wrapper that monitors failures and short-circuits calls when a threshold is reached.\n**Variants:** Count-based, time-based, hybrid.\n**Signal phrases:** \"fail fast\", \"fallback\", \"degraded mode\", \"threshold\", \"half-open state\"\n**Generalizes to:** Any unreliable dependency where repeated failures are costly.\n\n### BEH-03: Retry with Backoff\n**Recognition criteria:** Failed operations are retried with increasing delay between attempts.\n**Variants:** Linear backoff, exponential backoff, jittered backoff.\n**Signal phrases:** \"retry\", \"backoff\", \"exponential delay\", \"jitter\", \"max retries\"\n**Generalizes to:** Transient failures in networks, services, or resources.\n\n### BEH-04: Observer / Pub-Sub\n**Recognition criteria:** Components subscribe to events and react when events are published.\n**Variants:** In-process observers, message brokers, webhook callbacks.\n**Signal phrases:** \"subscribe\", \"notify\", \"event-driven\", \"listener\", \"on change\"\n**Generalizes to:** Loose coupling between producers and consumers of information.\n\n### BEH-05: Bulkhead Isolation\n**Recognition criteria:** Resources are partitioned so failure in one partition does not cascade.\n**Variants:** Thread pool isolation, process isolation, service isolation.\n**Signal phrases:** \"isolate\", \"partition\", \"blast radius\", \"contain failure\", \"independent pools\"\n**Generalizes to:** Any system where shared resources create single points of failure.\n\n## Structural Patterns\n\n### STR-01: Hub-and-Spoke\n**Recognition criteria:** A central coordinator connects to multiple peripheral components.\n**Signal phrases:** \"centralized\", \"gateway\", \"router\", \"orchestrator\", \"fan-out\"\n**Generalizes to:** Control flow concentration, API gateways, message routers.\n\n### STR-02: Layered Architecture\n**Recognition criteria:** Components organized into horizontal layers with strict dependency direction.\n**Signal phrases:** \"layers\", \"presentation/business/data\", \"separation of concerns\", \"upper layers depend on lower\"\n**Generalizes to:** Any system needing clean separation between abstraction levels.\n\n### STR-03: Pipeline / Chain\n**Recognition criteria:** Data flows through sequential processing stages, each transforming the input.\n**Signal phrases:** \"pipeline\", \"stage\", \"transform\", \"middleware\", \"chain of responsibility\"\n**Generalizes to:** Data processing, request handling, build systems.\n\n### STR-04: Plugin / Extension\n**Recognition criteria:** A core system exposes extension points; behavior is added without modifying the core.\n**Signal phrases:** \"plugin\", \"extension\", \"hook\", \"middleware\", \"add-on\", \"registry\"\n**Generalizes to:** Systems requiring customization without core modification.\n\n## Architectural Patterns\n\n### ARC-01: Strangler Fig Migration\n**Recognition criteria:** New system incrementally replaces old system by intercepting requests.\n**Signal phrases:** \"migrate incrementally\", \"proxy to legacy\", \"strangle\", \"route new traffic\"\n**Generalizes to:** Any legacy-to-modern migration where big-bang replacement is too risky.\n\n### ARC-02: Event Sourcing\n**Recognition criteria:** State changes are stored as immutable events rather than current-state snapshots.\n**Signal phrases:** \"event log\", \"append-only\", \"replay events\", \"event store\", \"rebuild state\"\n**Generalizes to:** Systems requiring audit trails, temporal queries, or state reconstruction.\n\n### ARC-03: CQRS (Command-Query Separation)\n**Recognition criteria:** Read and write operations use separate models or paths.\n**Signal phrases:** \"read model\", \"write model\", \"command side\", \"query side\", \"projection\"\n**Generalizes to:** Systems where read and write workloads have different performance or scaling needs.\n\n### ARC-04: Sidecar / Ambassador\n**Recognition criteria:** A helper process runs alongside the main process, handling cross-cutting concerns.\n**Signal phrases:** \"sidecar\", \"ambassador\", \"proxy\", \"co-located process\", \"service mesh\"\n**Generalizes to:** Cross-cutting concerns (logging, auth, networking) decoupled from application logic.\n\n## Workflow Patterns\n\n### WKF-01: Gate-Based Progression\n**Recognition criteria:** Work advances through stages; each stage has explicit pass/fail criteria.\n**Signal phrases:** \"gate\", \"checkpoint\", \"must pass before\", \"approval required\", \"quality gate\"\n**Generalizes to:** CI/CD, review workflows, phased project delivery.\n\n### WKF-02: Saga / Compensating Transaction\n**Recognition criteria:** A multi-step process where failure at any step triggers compensating actions for prior steps.\n**Signal phrases:** \"compensate\", \"rollback\", \"saga\", \"undo\", \"compensation logic\"\n**Generalizes to:** Distributed transactions, multi-service workflows, booking systems.\n\n### WKF-03: Fork-Join Parallelism\n**Recognition criteria:** Work splits into independent branches, then merges results.\n**Signal phrases:** \"parallelize\", \"fan-out/fan-in\", \"fork\", \"join\", \"merge results\"\n**Generalizes to:** Any workflow where independent subtasks can execute concurrently.\n\n### WKF-04: Escalation Chain\n**Recognition criteria:** Issues flow upward through levels of authority or capability.\n**Signal phrases:** \"escalate\", \"tier 1/2/3\", \"if unresolved, then\", \"fallback handler\"\n**Generalizes to:** Support workflows, error handling hierarchies, decision authority chains.\n\n## Anti-Patterns\n\n| ID | Name | Recognition | Why It Fails | Misidentified As |\n|----|------|-------------|-------------|-----------------|\n| ANTI-01 | God Object | One component handles too many responsibilities | Coupling; changes ripple everywhere | Hub-and-spoke (which centralizes routing, not logic) |\n| ANTI-02 | Premature Optimization | Performance tuning before profiling | Optimizes wrong thing; adds complexity | Optimization pattern (timing matters) |\n| ANTI-03 | Distributed Monolith | Independent deployment but tight coupling | Costs of distribution without benefits | Microservices (which requires actual independence) |\n| ANTI-04 | Golden Hammer | One tool applied to every problem | Forces inappropriate solutions | Standard practice (which is context-appropriate) |\n\n## Template for New Pattern Entries\n\nWhen content analysis discovers a pattern not in this catalog, document it using this template:\n\n```markdown\n### [TYPE]-[NN]: [Descriptive Name]\n**Recognition criteria:** [How to identify this pattern in content]\n**Variants:** [Known variations, if any]\n**Signal phrases:** [Phrases that indicate this pattern]\n**Generalizes to:** [Broader applicability beyond the source context]\n**Why it works / Why it fails:** [For patterns / anti-patterns respectively]\n**Often misidentified as:** [Common misclassifications]\n```\n\n## Matching Rules\n\n1. **Match by recognition criteria first.** Signal phrases are secondary; the structural match matters more.\n2. **One primary archetype per extraction.** If a pattern matches two archetypes, choose the more specific one and note the secondary match.\n3. **Novel patterns are welcome.** If no archetype matches, create a new entry. The catalog grows through use.\n4. **Anti-patterns require consequence evidence.** Do not classify something as anti-pattern without documented negative outcomes or clear reasoning for why it fails.\n5. **Variants inherit the parent archetype.** A jittered backoff is still BEH-03; note the variant rather than creating a new entry.\n"
    },
    {
      "name": "skill-template-guide.md",
      "path": "references/skill-template-guide.md",
      "content": "# Skill Template Guide\n\nHow to convert extracted procedures into properly formatted skill library entries.\nUse this reference during Step 5 (Skill Extraction) when an extracted procedure is a candidate for the skill library.\n\n## When to Convert\n\nNot every extracted procedure should become a skill entry. Convert when ALL of these hold:\n\n| Criterion | Test |\n|-----------|------|\n| **Repeatable** | Would someone perform this procedure more than once? |\n| **Self-contained** | Can someone follow it without reading the source content? |\n| **Transferable** | Does it apply outside the original context? |\n| **Non-trivial** | Does it involve 3+ steps or decision points? |\n| **Not already covered** | Does the skill library lack this capability? |\n\nIf any criterion fails, the extraction stays in EXTRACTED-SKILLS.md as a candidate but does not get formatted as a full skill entry.\n\n## Required Sections\n\nEvery skill entry must include these sections. Omitting any section produces an incomplete entry.\n\n### 1. Frontmatter\n\n```yaml\n---\nname: skill-name-in-kebab-case\ndescription: \"One sentence describing what this skill does and when to use it.\"\nphase: IMPLEMENT  # Which loop phase: INIT, SCAFFOLD, IMPLEMENT, TEST, VERIFY, VALIDATE, DOCUMENT, REVIEW, SHIP, COMPLETE\ncategory: core    # core, specialized, meta, or infra\nversion: \"1.0.0\"\ndepends_on: []    # Other skills this one requires\ntags: [keyword1, keyword2, keyword3]\n---\n```\n\n**Rules:**\n- Name uses kebab-case, matches the directory name\n- Description is a single sentence, starts with an imperative verb\n- Phase reflects when in the engineering loop this skill is most relevant\n- Version starts at 1.0.0 for new skills\n\n### 2. Title and Summary\n\n```markdown\n# Skill Name\n\nOne paragraph summary of what this skill does, why it exists, and what outcome it produces.\n```\n\n### 3. When to Use\n\n```markdown\n## When to Use\n\n- **Trigger condition 1** --- Description of when this skill applies\n- **Trigger condition 2** --- Description of another trigger\n- When you say: \"quoted trigger phrases\"\n```\n\n**Rules:**\n- List 3-6 trigger conditions\n- Each starts bold with a short label, then a dash and description\n- Include natural language triggers (\"When you say...\")\n\n### 4. Required Deliverables\n\n```markdown\n## Required Deliverables\n\n| Deliverable | Location | Condition |\n|-------------|----------|-----------|\n| File or artifact name | Where it goes | When it is produced |\n```\n\n### 5. Core Process\nNumbered, named steps. Each step includes: what to do (imperative), how to do it (specific), decision points (\"If X, do Y. Otherwise, do Z.\"), and expected output. Every step must be executable without interpretation.\n\n### 6. Output Format\nTemplate showing the exact structure of the skill's deliverable. Use fenced code blocks with `markdown` language identifier.\n\n### 7. Key Principles\n3-6 principles, each starting bold with a short name. Principles explain **why**, not just what. One paragraph per principle.\n\n## Formatting Standards\n\n| Element | Rule |\n|---------|------|\n| **H1** | Skill name only (one per file) |\n| **H2** | Major sections: When to Use, Process, Output Format, Key Principles |\n| **H3/H4** | Process steps and sub-steps |\n| **Tables** | Structured comparisons and parameter lists; always include header row |\n| **Code blocks** | Fenced with language identifier; under 30 lines; use `markdown` for templates |\n| **Bullet lists** | Unordered items (conditions, principles); numbered for ordered steps; checkboxes for verification |\n| **Bold** | Key terms on first use, section labels, deliverable names |\n| `Code font` | File names, commands, variable names, config values |\n| **---** separator | Between bold label and description in \"When to Use\" lists |\n\n## Quality Checklist\n\nRun before finalizing any skill entry.\n\n- [ ] Frontmatter has all required fields; description starts with imperative verb\n- [ ] \"When to Use\" has 3-6 trigger conditions with natural language triggers\n- [ ] Process has numbered, named steps with enough detail to execute independently\n- [ ] Output format includes a concrete template with exact file names\n- [ ] Key principles section present (3-6 principles with \"why\" explanations)\n- [ ] Reader unfamiliar with source content can follow the procedure\n- [ ] No undefined jargon; decision points are explicit (if/then, not \"consider\")\n- [ ] Name in frontmatter matches directory name; formatting follows standards\n- [ ] Terminology matches existing skill library vocabulary\n- [ ] Phase assignment is correct for the engineering loop\n- [ ] Skill does one thing well; no unacknowledged overlap with existing skills\n- [ ] Prerequisites listed in `depends_on`; scope neither too granular nor too broad\n\n## Conversion Workflow\n\n1. **Assess fit** --- Run \"When to Convert\" criteria. Stop if any fails.\n2. **Draft frontmatter** --- Assign name, phase, category, tags. Check for name conflicts.\n3. **Expand procedure** --- Add detail until each step is independently executable.\n4. **Add decision points** --- Make every if/then branch explicit.\n5. **Write triggers** --- Define when someone would invoke this. Focus on the problem, not the solution.\n6. **Define deliverables** --- Specify exact files and artifacts produced.\n7. **State principles** --- Extract 3-6 guiding principles (\"why\" behind the \"what\").\n8. **Create output template** --- Concrete example of the skill's deliverable format.\n9. **Run quality checklist** --- Verify against every item above.\n\n## Common Conversion Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| Copying source verbatim | Rewrite in imperative voice with full context |\n| Missing implicit steps | Walk through mentally; add every action between stated steps |\n| Scope creep (does 3 things) | Split into focused skills with dependencies |\n| No decision points | Add branches for common variations and errors |\n| Vague output | Specify exact file name, format, and structure |\n| Wrong phase assignment | Review phase definitions in the loop controller |\n"
    }
  ],
  "tags": [
    "meta",
    "analysis",
    "extraction",
    "patterns",
    "knowledge",
    "taxonomy",
    "second-brain"
  ],
  "dependsOn": []
}