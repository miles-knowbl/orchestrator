{
  "id": "estimation",
  "name": "estimation",
  "version": "1.0.0",
  "description": "Estimate effort, complexity, and duration for systems and features. Provides frameworks for sizing work, accounting for risk, and calibrating estimates over time. Supports planning and expectation setting throughout the engineering loop.",
  "phase": "INIT",
  "category": "core",
  "content": "# Estimation\n\nPredict effort before you build.\n\n## When to Use\n\n- **New system** — Estimate before starting implementation\n- **Feature planning** — Size work for prioritization\n- **Sprint planning** — Break down into time-boxed chunks\n- **Stakeholder communication** — Set realistic expectations\n- **Resource allocation** — Plan team capacity\n- **Trade-off decisions** — Compare build vs buy, now vs later\n\n## Reference Requirements\n\n**MUST read before applying this skill:**\n\n| Reference | Why Required |\n|-----------|--------------|\n| `estimation-methods.md` | Different estimation approaches |\n| `estimate-template.md` | Format for estimate documentation |\n\n**Read if applicable:**\n\n| Reference | When Needed |\n|-----------|-------------|\n| `complexity-factors.md` | When assessing complexity |\n\n**Verification:** Check calibration data before finalizing estimate.\n\n## Required Deliverables\n\n| Deliverable | Location | Condition |\n|-------------|----------|-----------|\n| `ESTIMATE.md` | Project root | Always |\n\n## Core Concept\n\nEstimation answers: **\"How much effort will this take?\"**\n\n```\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                         ESTIMATION                                           │\n│                                                                             │\n│  INPUT                           OUTPUT                                     │\n│  ─────                           ──────                                     │\n│  FeatureSpec ──────────────────▶ Complexity: Large                          │\n│  Context     ──────────────────▶ Effort: 40-60 hours                        │\n│  Constraints ──────────────────▶ Duration: 2-3 weeks                        │\n│                                  Risk: Medium (1.5x buffer)                 │\n│                                  Confidence: Medium                         │\n│                                                                             │\n│  Estimation is NOT a commitment — it's a forecast with uncertainty          │\n│                                                                             │\n└─────────────────────────────────────────────────────────────────────────────┘\n```\n\n## Estimation Dimensions\n\n| Dimension | What It Measures | Units |\n|-----------|------------------|-------|\n| **Complexity** | How hard is this? | S / M / L / XL |\n| **Effort** | How much work? | Person-hours or person-days |\n| **Duration** | How long on calendar? | Days or weeks |\n| **Risk** | How uncertain? | Multiplier (1.2x - 3x) |\n| **Confidence** | How sure are we? | High / Medium / Low |\n\n### Complexity vs Effort vs Duration\n\n```\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                                                                             │\n│  COMPLEXITY ≠ EFFORT ≠ DURATION                                             │\n│                                                                             │\n│  Example: Database migration                                                │\n│                                                                             │\n│  Complexity: Small (straightforward script)                                 │\n│  Effort: 4 hours (write, test, document)                                    │\n│  Duration: 2 weeks (needs DBA review, maintenance window)                   │\n│                                                                             │\n│  Example: New microservice                                                  │\n│                                                                             │\n│  Complexity: Large (many moving parts)                                      │\n│  Effort: 80 hours                                                           │\n│  Duration: 2 weeks (if 1 person) or 1 week (if 2 people)                    │\n│                                                                             │\n└─────────────────────────────────────────────────────────────────────────────┘\n```\n\n## The Estimation Process\n\n```\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                      ESTIMATION PROCESS                                      │\n│                                                                             │\n│  1. UNDERSTAND SCOPE                                                        │\n│     └─→ Read FeatureSpec thoroughly                                         │\n│     └─→ Identify all capabilities                                           │\n│     └─→ Note interfaces and integrations                                    │\n│     └─→ List unknowns and assumptions                                       │\n│                                                                             │\n│  2. BREAK DOWN                                                              │\n│     └─→ Decompose into estimable chunks                                     │\n│     └─→ Each chunk should be < 1 day of work                                │\n│     └─→ Identify dependencies between chunks                                │\n│                                                                             │\n│  3. SIZE EACH CHUNK                                                         │\n│     └─→ Apply estimation method                                             │\n│     └─→ Note complexity factors                                             │\n│     └─→ Record assumptions                                                  │\n│                                                                             │\n│  4. ACCOUNT FOR RISK                                                        │\n│     └─→ Identify uncertainties                                              │\n│     └─→ Apply risk multiplier                                               │\n│     └─→ Consider worst-case scenarios                                       │\n│                                                                             │\n│  5. AGGREGATE                                                               │\n│     └─→ Sum effort estimates                                                │\n│     └─→ Calculate duration (accounting for parallelism)                     │\n│     └─→ State confidence level                                              │\n│                                                                             │\n│  6. COMMUNICATE                                                             │\n│     └─→ Present as range, not point                                         │\n│     └─→ Explain assumptions and risks                                       │\n│     └─→ Update as you learn more                                            │\n│                                                                             │\n└─────────────────────────────────────────────────────────────────────────────┘\n```\n\n## Applying Calibration Data\n\n**IMPORTANT:** Before finalizing any estimate, check for historical calibration data.\n\n### Step 1.5: Load Calibration\n\nAfter understanding scope (Step 1), load calibration data:\n\n```\n1. Check for calibration file:\n   Path: learning/calibration.json\n\n2. If found, extract relevant multipliers:\n   - adjustments.global.agenticMultiplier (if agentic execution)\n   - adjustments.byComplexity[SIZE] (S/M/L/XL)\n   - adjustments.byPhase[PHASE] (per-phase adjustments)\n   - adjustments.byCategory[CATEGORY] (domain-specific)\n\n3. Check confidence levels:\n   - < 3 samples: Do NOT apply (flag for future tracking)\n   - 3-5 samples: Apply cautiously with ±30% range note\n   - 6+ samples: Apply with confidence\n```\n\n### Applying Phase Multipliers\n\nWhen using Skill-Phase Estimation, apply historical adjustments:\n\n```markdown\n## Calibrated Skill-Phase Estimate\n\n| Phase | Base Hours | Multiplier (samples) | Adjusted | Confidence |\n|-------|-----------|----------------------|----------|------------|\n| spec | 0.5h | 1.15 (8) | 0.58h | Good |\n| architect | 1h | 1.25 (8) | 1.25h | Good |\n| implement | 6h | 0.75 (12) | 4.5h | Good |\n| test | 2h | 0.80 (10) | 1.6h | Good |\n| verify | 0.5h | 1.0 (3) | 0.5h | Low |\n| **Total** | **12.5h** | | **10.3h** | |\n\nCalibration impact: -18% from historical data\n```\n\n### Document Calibration in ESTIMATE.md\n\nAdd a calibration section to every estimate:\n\n```markdown\n## Calibration Applied\n\n| Adjustment | Multiplier | Samples | Confidence | Applied |\n|------------|------------|---------|------------|---------|\n| Global agentic | 0.3x | 6 | Good | Yes |\n| Complexity (M) | 0.85x | 4 | Low | Yes (±30%) |\n| Phase: IMPLEMENT | 0.75x | 12 | Good | Yes |\n| Phase: TEST | 0.80x | 10 | Good | Yes |\n| Category: MCP | 1.1x | 2 | None | No (n<3) |\n\n### Unadjusted Estimate\n- Total: 12.5 hours\n\n### Calibrated Estimate\n- Total: 10.3 hours\n- Adjustments applied: 4\n- Adjustments skipped (low confidence): 1\n- Overall confidence: Medium-High\n```\n\n### Confidence Rules\n\n| Samples | Confidence | Action |\n|---------|------------|--------|\n| 0 | None | Use 1.0x (no adjustment) |\n| 1-2 | Very Low | Do NOT apply, flag for tracking |\n| 3-5 | Low | Apply with ±30% range note |\n| 6-10 | Medium | Apply with ±20% range |\n| 10+ | High | Apply with confidence |\n\n### No Calibration Data\n\nIf `learning/calibration.json` doesn't exist or has no relevant data:\n\n```markdown\n## Calibration Applied\n\nNo historical calibration data available for this domain.\n\nUsing base estimates. After completion:\n- Actual hours will be recorded\n- Calibration multipliers will be calculated\n- Future estimates will benefit from this data\n\nThis estimate contributes to: First calibration baseline\n```\n\n## Estimation Methods\n\n### 1. T-Shirt Sizing\n\nQuick relative sizing for early planning.\n\n| Size | Relative Effort | Typical Duration | Example |\n|------|-----------------|------------------|---------|\n| **S** | 1x | < 1 day | Add a field, fix a bug |\n| **M** | 2-3x | 1-3 days | New endpoint, simple feature |\n| **L** | 5-8x | 1-2 weeks | New service, complex feature |\n| **XL** | 13-20x | 2-4 weeks | Major system, many integrations |\n\n**When to use:** Initial scoping, backlog grooming, rough planning.\n\n### 2. Analogous Estimation\n\nCompare to similar past work.\n\n```markdown\n## Analogous Estimate\n\n**Item:** User notification service\n**Similar to:** Email service (completed 3 months ago)\n\n| Aspect | Email Service | Notification Service | Adjustment |\n|--------|---------------|---------------------|------------|\n| Core logic | 20 hours | Similar | 20 hours |\n| Integrations | 2 (SMTP, templates) | 4 (push, SMS, email, in-app) | 40 hours (+20) |\n| Testing | 8 hours | More channels | 16 hours |\n| **Total** | **40 hours** | | **76 hours** |\n\n**Confidence:** Medium (similar but more integrations)\n```\n\n**When to use:** You've done similar work before.\n\n### 3. Parametric Estimation\n\nCalculate based on countable units.\n\n```markdown\n## Parametric Estimate\n\n**Item:** REST API for Order Service\n\n| Component | Count | Hours Each | Total |\n|-----------|-------|------------|-------|\n| Endpoints | 8 | 3 | 24 |\n| Database models | 4 | 2 | 8 |\n| Integration tests | 8 | 1.5 | 12 |\n| Documentation | 8 | 0.5 | 4 |\n| **Subtotal** | | | **48** |\n| Setup/config | | | 8 |\n| **Total** | | | **56 hours** |\n\n**Basis:** Historical average of 3 hours per endpoint (including tests)\n```\n\n**When to use:** Repetitive, well-understood work.\n\n### 4. Three-Point Estimation\n\nAccount for uncertainty with optimistic/likely/pessimistic.\n\n```markdown\n## Three-Point Estimate\n\n**Item:** Payment integration\n\n| Scenario | Estimate | Notes |\n|----------|----------|-------|\n| Optimistic (O) | 24 hours | Clean API, good docs, no issues |\n| Most Likely (M) | 40 hours | Typical integration challenges |\n| Pessimistic (P) | 80 hours | Poor API, compliance issues, rework |\n\n**PERT Estimate:** (O + 4M + P) / 6 = (24 + 160 + 80) / 6 = **44 hours**\n**Standard Deviation:** (P - O) / 6 = 9.3 hours\n\n**Range:** 35-53 hours (±1 SD)\n**Confidence:** Medium\n```\n\n**When to use:** Significant uncertainty, need to communicate risk.\n\n### 5. Bottom-Up Estimation\n\nSum detailed task estimates.\n\n```markdown\n## Bottom-Up Estimate\n\n**Item:** Work Order Service\n\n### Capability 1: Work Order CRUD\n| Task | Hours |\n|------|-------|\n| Database schema | 2 |\n| Model and repository | 3 |\n| Create endpoint | 2 |\n| Read endpoints (list, detail) | 3 |\n| Update endpoint | 2 |\n| Delete endpoint | 1 |\n| Unit tests | 4 |\n| Integration tests | 3 |\n| **Subtotal** | **20** |\n\n### Capability 2: Assignment\n| Task | Hours |\n|------|-------|\n| Assignment logic | 4 |\n| Availability check | 3 |\n| Notification trigger | 2 |\n| Tests | 4 |\n| **Subtotal** | **13** |\n\n[... more capabilities ...]\n\n### Summary\n| Capability | Hours |\n|------------|-------|\n| CRUD | 20 |\n| Assignment | 13 |\n| Status transitions | 10 |\n| Completion flow | 12 |\n| **Implementation total** | **55** |\n| Scaffolding | 4 |\n| Documentation | 6 |\n| Code review / fixes | 8 |\n| **Grand total** | **73 hours** |\n```\n\n**When to use:** Detailed planning, accurate forecasts, sprint commitment.\n\n### 6. Skill-Phase Estimation\n\nEstimate by engineering skill/phase for calibration accuracy.\n\n```markdown\n## Skill-Phase Estimate\n\n**Item:** Work Order Service\n\n### Phase Breakdown\n\n| Phase | Skill | Estimated | Notes |\n|-------|-------|-----------|-------|\n| Specification | spec | 0.5h | FEATURESPEC.md |\n| Specification | estimation | 0.25h | This document |\n| Architecture | architect | 1h | ARCHITECTURE.md |\n| Setup | scaffold | 0.5h | Project structure |\n| Implementation | implement | 6h | 4 capabilities |\n| Testing | test-generation | 2h | Unit + integration |\n| Verification | code-verification | 0.5h | Lint, types, tests |\n| Validation | code-validation | 0.5h | Full system check |\n| Documentation | document | 0.5h | README, API docs |\n| Review | code-review | 0.5h | Self-review, PR |\n| Ship | deploy | 0.25h | PR, merge |\n| **Total** | | **12.5h** | |\n\n### Per-Capability Breakdown\n\nFor skills called multiple times (implement, test-generation, code-verification):\n\n| ID | Capability | Implement | Test | Verify | Total |\n|----|------------|-----------|------|--------|-------|\n| C1 | Work Order CRUD | 90m | 30m | 10m | 130m |\n| C2 | Assignment | 60m | 20m | 5m | 85m |\n| C3 | Status transitions | 45m | 15m | 5m | 65m |\n| C4 | Completion flow | 60m | 20m | 5m | 85m |\n| **Total** | | 4.25h | 1.4h | 0.4h | 6.1h |\n```\n\n**Why use this:** \n- Maps directly to skillsLog for calibration\n- Calibration compares estimate vs actual per-skill\n- Identifies which phases we systematically over/under-estimate\n\n**When to use:** All agentic execution. This is the primary estimation format.\n\n→ See `references/estimation-methods.md`\n\n## Complexity Factors\n\nApply multipliers for conditions that increase difficulty:\n\n| Factor | Impact | Multiplier |\n|--------|--------|------------|\n| **New technology** | Learning curve, unknowns | +50-200% |\n| **Integration complexity** | Each external system | +20-40% per integration |\n| **Security requirements** | Auth, encryption, audit | +30-50% |\n| **Performance requirements** | Optimization, caching | +20-40% |\n| **Regulatory/compliance** | Documentation, controls | +50-100% |\n| **UI complexity** | Complex interactions, polish | +20-50% |\n| **Data migration** | ETL, validation, rollback | +30-100% |\n| **Legacy code** | Understanding, compatibility | +30-50% |\n| **Distributed system** | Coordination, consistency | +40-80% |\n| **Real-time requirements** | WebSockets, streaming | +30-50% |\n\n### Applying Factors\n\n```markdown\n## Complexity-Adjusted Estimate\n\n**Base estimate:** 40 hours\n\n**Applicable factors:**\n- New technology (learning Kafka): +50% → +20 hours\n- 2 integrations (Auth, Inventory): +30% each → +24 hours\n- Security (handles PII): +30% → +12 hours\n\n**Adjusted estimate:** 40 + 20 + 24 + 12 = **96 hours**\n\nNote: Factors may overlap; apply judgment to avoid double-counting.\n```\n\n→ See `references/complexity-factors.md`\n\n## Risk and Uncertainty\n\n### Risk Categories\n\n| Category | Examples | Impact |\n|----------|----------|--------|\n| **Technical** | New tech, complex algorithms, performance | High variance |\n| **Integration** | Third-party APIs, legacy systems | Dependencies |\n| **Requirements** | Unclear scope, changing needs | Rework |\n| **Resource** | Key person unavailable, skill gaps | Delays |\n| **External** | Vendor delays, regulatory changes | Blockers |\n\n### Risk Multipliers\n\n| Confidence | Risk Level | Multiplier | When to Apply |\n|------------|------------|------------|---------------|\n| High | Low | 1.0-1.2x | Well-understood, done before |\n| Medium | Medium | 1.3-1.5x | Some unknowns, new elements |\n| Low | High | 1.5-2.0x | Many unknowns, new territory |\n| Very Low | Very High | 2.0-3.0x | Unprecedented, research-like |\n\n### Communicating Uncertainty\n\nAlways present estimates as ranges:\n\n```\n❌ \"It will take 40 hours\"\n✅ \"I estimate 30-50 hours, most likely around 40\"\n\n❌ \"We'll be done in 2 weeks\"  \n✅ \"Target is 2 weeks; risk factors could push to 3 weeks\"\n```\n\n## Estimate Output Format\n\n```markdown\n# Estimate: [System/Feature Name]\n\n## Summary\n\n| Dimension | Value |\n|-----------|-------|\n| Complexity | [S/M/L/XL] |\n| Effort | [X-Y hours] |\n| Duration | [X-Y days/weeks] |\n| Confidence | [High/Medium/Low] |\n| Risk Multiplier | [1.Xx] |\n\n## Scope\n\n[What's included]\n- Capability 1\n- Capability 2\n- [...]\n\n[What's NOT included]\n- Out of scope item 1\n- [...]\n\n## Breakdown\n\n| Component | Base Hours | Factors | Adjusted |\n|-----------|------------|---------|----------|\n| [Component 1] | X | [factors] | Y |\n| [Component 2] | X | [factors] | Y |\n| **Total** | | | **Z** |\n\n## Assumptions\n\n- [Assumption 1]\n- [Assumption 2]\n\n## Risks\n\n| Risk | Impact | Likelihood | Mitigation |\n|------|--------|------------|------------|\n| [Risk 1] | [H/M/L] | [H/M/L] | [Action] |\n\n## Dependencies\n\n- Requires [X] to be complete\n- Blocked by [Y] until [date]\n\n## Historical Comparison\n\n[Similar past work and how this compares]\n\n---\n*Estimated by: [Agent/Person]*\n*Date: [Date]*\n*Valid until: [Date or \"requirements change\"]*\n```\n\n→ See `references/estimate-template.md`\n\n## Calibration\n\nTrack estimates vs actuals to improve over time.\n\n### Tracking Template\n\n```markdown\n## Estimate Retrospective\n\n**System:** Work Order Service\n**Estimated:** 73 hours\n**Actual:** 92 hours\n**Variance:** +26%\n\n### What Was Different?\n\n| Component | Estimated | Actual | Variance | Why |\n|-----------|-----------|--------|----------|-----|\n| CRUD | 20 | 18 | -10% | Went smoothly |\n| Assignment | 13 | 24 | +85% | Availability logic more complex |\n| Status | 10 | 14 | +40% | Edge cases discovered |\n| Completion | 12 | 15 | +25% | Signature handling tricky |\n| Other | 18 | 21 | +17% | Normal variance |\n\n### Lessons Learned\n\n1. Assignment logic always more complex than expected → increase multiplier\n2. Need to account for edge case discovery → add 20% buffer\n3. Integration tests took longer than unit tests → adjust ratio\n\n### Adjustment for Future\n\n- Assignment/scheduling features: apply 1.5x multiplier\n- Add 15% buffer for edge case discovery\n```\n\n### Calibration Metrics\n\n| Metric | Calculation | Target |\n|--------|-------------|--------|\n| **Accuracy** | Actual / Estimated | 0.9 - 1.1 |\n| **Precision** | Std dev of (Actual / Estimated) | < 0.3 |\n| **Bias** | Average (Actual - Estimated) | ~0 |\n\n```\nConsistent underestimate → Increase base estimates\nConsistent overestimate → Decrease base estimates\nHigh variance → Break down further, reduce unknowns\n```\n\n→ See `references/calibration-guide.md`\n\n## Common Estimation Mistakes\n\n| Mistake | Problem | Fix |\n|---------|---------|-----|\n| **Forgetting overhead** | Only count coding time | Add 20-30% for meetings, reviews, context switching |\n| **Optimism bias** | Assume best case | Use three-point or add buffer |\n| **Anchoring** | First number sticks | Estimate independently, then compare |\n| **Scope creep** | Requirements grow | Document assumptions, re-estimate on change |\n| **Hero estimates** | \"I could do it in X\" | Estimate for average developer |\n| **Ignoring dependencies** | Assume parallel work | Map dependencies, account for handoffs |\n| **Not updating** | Stale estimates | Re-estimate as you learn |\n\n## Relationship to Other Skills\n\n| Skill | Relationship |\n|-------|--------------|\n| `spec` | Provides scope to estimate |\n| `triage` | Uses estimates for prioritization |\n| `entry-portal` | Estimates feed into queue planning |\n| `loop-controller` | Estimates inform session planning |\n\n## Key Principles\n\n**Estimate in ranges.** Point estimates are false precision.\n\n**Break it down.** Smaller pieces are easier to estimate.\n\n**Document assumptions.** They're as important as the number.\n\n**Track and learn.** Calibrate based on actuals.\n\n**Update when things change.** Estimates have a shelf life.\n\n**Communicate uncertainty.** Stakeholders need to understand risk.\n\n## Mode-Specific Behavior\n\nEstimation approach differs by orchestrator mode:\n\n### Greenfield Mode\n\n| Aspect | Behavior |\n|--------|----------|\n| **Scope** | Full system—all capabilities and layers |\n| **Approach** | Comprehensive—bottom-up + skill-phase |\n| **Patterns** | Free choice—establish estimation baselines |\n| **Deliverables** | Full estimate with risk factors |\n| **Validation** | Historical comparison from similar projects |\n| **Constraints** | Minimal—medium to high uncertainty expected |\n\n**Greenfield estimation:**\n- Estimate all layers (data, service, API, UI)\n- Include scaffolding and setup time\n- Account for learning curve on new patterns\n- Plan for comprehensive test coverage\n- Include documentation time\n\n**Greenfield risk factors:**\n```\nBase estimate: X hours\n+ New technology learning: +30-50%\n+ Architecture decisions: +20-30%\n+ Comprehensive testing: +20-30%\n+ Documentation: +10-15%\n= Adjusted estimate: 1.8x - 2.2x base\n```\n\n### Brownfield-Polish Mode\n\n| Aspect | Behavior |\n|--------|----------|\n| **Scope** | Gap-specific—missing capabilities only |\n| **Approach** | Extend existing—gap-based estimation |\n| **Patterns** | Should match existing velocity patterns |\n| **Deliverables** | Gap-based estimate with compatibility buffer |\n| **Validation** | Velocity in this codebase |\n| **Constraints** | Low to medium uncertainty—known territory |\n\n**Polish estimation:**\n- Estimate only what's missing\n- Include time to understand existing code\n- Account for maintaining compatibility\n- Reduced testing (fill gaps only)\n- Minimal documentation updates\n\n**Polish estimation formula:**\n```\nFor each gap:\n  Understanding time: 0.5-2 hours (existing code review)\n  Implementation time: Based on gap complexity\n  Testing time: Match existing coverage\n  Integration time: Ensure compatibility\n\nTotal = Sum of gaps × 1.2 (compatibility buffer)\n```\n\n**Polish-specific factors:**\n| Factor | Impact |\n|--------|--------|\n| Code quality | Low quality = +30-50% |\n| Test coverage | Low coverage = +20-40% |\n| Documentation | Poor docs = +20-30% |\n| Coupling | High coupling = +20-40% |\n\n### Brownfield-Enterprise Mode\n\n| Aspect | Behavior |\n|--------|----------|\n| **Scope** | Change-specific—single change only |\n| **Approach** | Surgical—change-impact analysis |\n| **Patterns** | Must conform exactly to team velocity |\n| **Deliverables** | Change estimate with review cycles |\n| **Validation** | Team velocity in this system |\n| **Constraints** | Low uncertainty—constrained scope |\n\n**Enterprise estimation:**\n- Estimate the specific change\n- Include impact analysis time\n- Account for review cycles\n- Plan for comprehensive testing (regression)\n- Include CI/CD pipeline time\n\n**Enterprise estimation formula:**\n```\nImpact analysis: 1-4 hours\nImplementation: Based on change size\nRegression testing: Proportional to risk\nReview cycles: 2-4 hours per cycle\nCI/CD: Fixed (pipeline duration)\nBuffer for process: +20%\n```\n\n**Enterprise constraints:**\n- Fixed time for security review\n- Fixed time for compliance checks\n- Multiple approval stages\n- Scheduled deployment windows\n\n### Mode Comparison\n\n| Aspect | Greenfield | Polish | Enterprise |\n|--------|------------|--------|------------|\n| **Typical multiplier** | 1.8x - 2.2x | 1.2x - 1.5x | 1.1x - 1.3x |\n| **Biggest uncertainty** | Architecture | Compatibility | Process |\n| **Estimation unit** | Capabilities | Gaps | Changes |\n| **Calibration source** | Similar projects | This codebase | This system |\n\n### Estimation Output by Mode\n\n**Greenfield estimate structure:**\n```markdown\n## Estimate: [System Name]\nComplexity: L (new system)\nBase effort: 80 hours\nRisk multiplier: 1.8x\nAdjusted: 120-160 hours\nConfidence: Medium\n```\n\n**Polish estimate structure:**\n```markdown\n## Estimate: [Gap Fill]\nGaps identified: 5\nBase effort: 24 hours\nCompatibility buffer: 1.2x\nAdjusted: 28-32 hours\nConfidence: Medium-High\n```\n\n**Enterprise estimate structure:**\n```markdown\n## Estimate: [Change Request]\nChange scope: Minimal (2 files)\nImplementation: 8 hours\nReview/process: 6 hours\nTotal: 14-16 hours\nConfidence: High\n```\n\n## References\n\n- `references/estimation-methods.md`: Detailed method explanations\n- `references/complexity-factors.md`: Factor catalog with examples\n- `references/estimate-template.md`: Standard estimate document\n- `references/calibration-guide.md`: Improving estimates over time",
  "references": [
    {
      "name": "ESTIMATE.md",
      "path": "references/ESTIMATE.md",
      "content": "# ESTIMATE.md Template\n\n## Estimate: {{system-name}}\n\n**Domain:** {{domain}}\n**Created:** {{date}}\n**Confidence:** {{confidence}}%\n\n---\n\n## Summary\n\n| Metric | Value |\n|--------|-------|\n| **Total Hours** | {{total}}h |\n| **Complexity** | {{S/M/L/XL}} |\n| **Capabilities** | {{count}} |\n| **Risk Level** | {{Low/Medium/High}} |\n\n---\n\n## Phase Breakdown\n\n| Phase | Hours | Confidence | Notes |\n|-------|-------|------------|-------|\n| SPEC | {{h}} | {{%}} | |\n| ARCHITECT | {{h}} | {{%}} | |\n| SCAFFOLD | {{h}} | {{%}} | |\n| IMPLEMENT | {{h}} | {{%}} | |\n| TEST | {{h}} | {{%}} | |\n| VERIFY | {{h}} | {{%}} | |\n| VALIDATE | {{h}} | {{%}} | |\n| DOCUMENT | {{h}} | {{%}} | |\n| DEPLOY | {{h}} | {{%}} | |\n| **Total** | **{{h}}** | **{{%}}** | |\n\n---\n\n## Capability Breakdown\n\n| ID | Capability | Complexity | Hours |\n|----|------------|------------|-------|\n| C1 | {{name}} | {{S/M/L}} | {{h}} |\n| C2 | {{name}} | {{S/M/L}} | {{h}} |\n\n---\n\n## Assumptions\n\n- {{assumption-1}}\n- {{assumption-2}}\n\n## Risks\n\n| Risk | Impact | Mitigation |\n|------|--------|------------|\n| {{risk}} | +{{h}}h | {{mitigation}} |\n\n---\n\n## Calibration Applied\n\n| Factor | Multiplier | Reason |\n|--------|------------|--------|\n| Global | {{x}} | Historical variance |\n| Complexity | {{x}} | {{complexity}} items |\n| Domain | {{x}} | {{familiarity}} |\n\n**Pre-calibration:** {{h}}h\n**Post-calibration:** {{h}}h\n"
    },
    {
      "name": "calibration-guide.md",
      "path": "references/calibration-guide.md",
      "content": "# Calibration Guide\n\n## Purpose\n\nThis reference provides comprehensive guidance for improving estimation accuracy over time through systematic calibration. Calibration is the process of comparing estimates to actuals, identifying patterns in variance, and adjusting estimation practices to reduce error.\n\n**Use this guide when:**\n- Completing a project/system to record calibration data\n- Reviewing estimation accuracy trends over time\n- Adjusting estimation baselines for future work\n- Training new team members on estimation practices\n- Conducting retrospectives on estimation performance\n\n## Core Concept\n\nCalibration treats estimation as a learnable skill that improves with deliberate practice and feedback loops.\n\n```\n                    CALIBRATION FEEDBACK LOOP\n\n    ┌─────────────┐       ┌─────────────┐       ┌─────────────┐\n    │   Estimate  │──────▶│   Execute   │──────▶│   Measure   │\n    │    Work     │       │    Work     │       │   Actuals   │\n    └─────────────┘       └─────────────┘       └─────────────┘\n           ▲                                           │\n           │                                           │\n           │              ┌─────────────┐              │\n           └──────────────│   Analyze   │◀─────────────┘\n                          │   Variance  │\n                          └─────────────┘\n                                │\n                                ▼\n                          ┌─────────────┐\n                          │   Adjust    │\n                          │  Practices  │\n                          └─────────────┘\n```\n\n## Calibration Metrics\n\n### Primary Metrics\n\n| Metric | Formula | Interpretation | Target |\n|--------|---------|----------------|--------|\n| **Accuracy Ratio** | Actual / Estimated | How close to reality | 0.9 - 1.1 |\n| **Bias** | Mean(Actual - Estimated) | Systematic over/under | +/- 10% |\n| **Precision** | StdDev(Accuracy Ratio) | Consistency | < 0.25 |\n| **MAPE** | Mean(Abs(Actual-Est)/Actual) | % error magnitude | < 25% |\n\n### Calculating Accuracy Ratio\n\n```\nAccuracy Ratio = Actual Hours / Estimated Hours\n\nExample:\n  Estimated: 40 hours\n  Actual: 48 hours\n  Accuracy Ratio: 48/40 = 1.20 (20% underestimate)\n\nInterpretation:\n  < 1.0 = Overestimate (finished faster than expected)\n  = 1.0 = Perfect estimate\n  > 1.0 = Underestimate (took longer than expected)\n```\n\n### Calculating Bias\n\n```\nBias = Average of (Actual - Estimated) across all estimates\n\nExample over 5 projects:\n  Project A: 48 - 40 = +8\n  Project B: 22 - 20 = +2\n  Project C: 35 - 30 = +5\n  Project D: 18 - 24 = -6\n  Project E: 52 - 40 = +12\n\n  Bias = (8 + 2 + 5 + (-6) + 12) / 5 = +4.2 hours\n\nInterpretation:\n  Positive bias = Systematic underestimation\n  Negative bias = Systematic overestimation\n  Near zero = Well-calibrated (no systematic error)\n```\n\n### Calculating Precision (Consistency)\n\n```\nPrecision = Standard Deviation of Accuracy Ratios\n\nExample:\n  Ratios: [1.20, 1.10, 1.17, 0.75, 1.30]\n  Mean: 1.10\n  Variance: [(1.20-1.10)^2 + (1.10-1.10)^2 + ...] / 5 = 0.0356\n  StdDev: sqrt(0.0356) = 0.19\n\nInterpretation:\n  Low StdDev (< 0.15) = Very consistent\n  Medium StdDev (0.15-0.25) = Reasonably consistent\n  High StdDev (> 0.25) = Inconsistent, needs improvement\n```\n\n### Mean Absolute Percentage Error (MAPE)\n\n```\nMAPE = Average of |Actual - Estimated| / Actual * 100%\n\nExample:\n  Project A: |48-40|/48 = 16.7%\n  Project B: |22-20|/22 = 9.1%\n  Project C: |35-30|/35 = 14.3%\n  Project D: |18-24|/18 = 33.3%\n  Project E: |52-40|/52 = 23.1%\n\n  MAPE = (16.7 + 9.1 + 14.3 + 33.3 + 23.1) / 5 = 19.3%\n\nInterpretation:\n  < 10% = Excellent\n  10-20% = Good\n  20-30% = Acceptable\n  > 30% = Needs significant improvement\n```\n\n## Data Collection\n\n### What to Track\n\nFor each estimation unit (system, feature, capability):\n\n```markdown\n## Calibration Data Point\n\n| Field | Value |\n|-------|-------|\n| ID | EST-2024-001 |\n| Description | Work Order Service |\n| Estimated | 73 hours |\n| Actual | 92 hours |\n| Accuracy Ratio | 1.26 |\n| Start Date | 2024-01-15 |\n| End Date | 2024-01-28 |\n| Estimator | Agent-1 |\n| Complexity | L |\n| Mode | Greenfield |\n\n### Breakdown Comparison\n\n| Component | Est | Act | Ratio | Notes |\n|-----------|-----|-----|-------|-------|\n| CRUD | 20 | 18 | 0.90 | Smooth |\n| Assignment | 13 | 24 | 1.85 | Complex logic |\n| Status | 10 | 14 | 1.40 | Edge cases |\n| Completion | 12 | 15 | 1.25 | Signatures |\n| Other | 18 | 21 | 1.17 | Normal |\n\n### Contributing Factors\n\n- [x] Scope change during implementation\n- [ ] External dependency delay\n- [x] Underestimated complexity\n- [ ] Overestimated complexity\n- [ ] Technical issues / bugs\n- [ ] Requirements unclear\n- [x] New technology learning\n\n### Notes\n\nAssignment logic required implementing availability calculations\nthat were more complex than anticipated. Recommend 1.5x multiplier\nfor scheduling/assignment features in future.\n```\n\n### Per-Skill Tracking\n\nTrack estimates by skill phase for fine-grained calibration:\n\n```markdown\n## Skill-Level Calibration: Work Order Service\n\n| Skill | Est | Act | Ratio | Notes |\n|-------|-----|-----|-------|-------|\n| spec | 0.5h | 0.75h | 1.5 | More discussion needed |\n| estimation | 0.25h | 0.25h | 1.0 | On target |\n| architect | 1h | 1.5h | 1.5 | Multiple iterations |\n| scaffold | 0.5h | 0.5h | 1.0 | On target |\n| implement | 6h | 8h | 1.33 | Assignment complexity |\n| test-generation | 2h | 2.5h | 1.25 | Edge case tests |\n| code-verification | 0.5h | 0.5h | 1.0 | On target |\n| code-validation | 0.5h | 0.75h | 1.5 | Integration issues |\n| document | 0.5h | 0.5h | 1.0 | On target |\n| code-review | 0.5h | 0.75h | 1.5 | Revision needed |\n| deploy | 0.25h | 0.25h | 1.0 | On target |\n\n### Skill-Level Insights\n\n- spec: Often underestimated; stakeholder alignment takes time\n- architect: Iteration cycles not accounted for\n- implement: Varies significantly by feature complexity\n- test-generation: Edge cases emerge during implementation\n- code-validation: Integration surprises common\n```\n\n### Calibration Log Format\n\nMaintain a rolling log of calibration data:\n\n```markdown\n# Calibration Log\n\n## Summary Statistics\n\n| Period | Count | Avg Accuracy | Bias | MAPE | Precision |\n|--------|-------|--------------|------|------|-----------|\n| Q1 2024 | 12 | 1.24 | +18% | 22% | 0.28 |\n| Q2 2024 | 15 | 1.18 | +14% | 19% | 0.24 |\n| Q3 2024 | 18 | 1.12 | +10% | 16% | 0.21 |\n| Q4 2024 | 16 | 1.08 | +6% | 14% | 0.18 |\n\n## Trend Analysis\n\nAccuracy improving: Bias reduced from +18% to +6% over 4 quarters.\nPrecision improving: StdDev reduced from 0.28 to 0.18.\nFocus area: Continue reducing variance in implementation estimates.\n\n## Individual Records\n\n[Individual data points as shown above]\n```\n\n## Analyzing Variance\n\n### Variance Categories\n\nWhen actual differs significantly from estimated, categorize the cause:\n\n| Category | Description | Example | Adjustment |\n|----------|-------------|---------|------------|\n| **Scope Change** | Requirements changed | New feature added | Re-estimate; don't count against accuracy |\n| **Complexity Surprise** | Harder than expected | Algorithm edge cases | Increase complexity factors |\n| **External Dependency** | Blocked by others | API delay | Add buffer for external deps |\n| **Technical Issues** | Bugs, environment | Flaky tests | Track separately; improve tooling |\n| **Learning Curve** | New tech/domain | First Kafka project | Add learning multiplier |\n| **Process Overhead** | Reviews, meetings | Multiple review cycles | Include in base estimate |\n| **Estimation Error** | Simply wrong | Misjudged effort | Adjust base estimates |\n\n### Root Cause Analysis\n\nFor significant variances (> 30%), conduct root cause analysis:\n\n```markdown\n## Variance Analysis: Project X\n\n**Estimated:** 40 hours\n**Actual:** 64 hours\n**Variance:** +60%\n\n### Timeline\n\n| Date | Event | Impact |\n|------|-------|--------|\n| Day 1 | Started implementation | On track |\n| Day 2 | Discovered auth complexity | +8h |\n| Day 3 | External API changed | +4h (rework) |\n| Day 5 | Code review feedback | +6h (revisions) |\n| Day 7 | Integration test issues | +6h |\n\n### Root Causes\n\n1. **Auth Complexity (8h)**: Did not account for OAuth2\n   PKCE flow requirements. Add auth integration to\n   complexity factors (+30% for auth).\n\n2. **External API Change (4h)**: Third-party changed\n   endpoint during development. Add buffer for external\n   dependencies (+15% per external API).\n\n3. **Review Cycles (6h)**: Underestimated review effort.\n   Standard review buffer should be 20%, not 10%.\n\n4. **Integration Issues (6h)**: Environment configuration\n   not documented. DevOps issue, track separately.\n\n### Adjustments\n\n- Auth integration: Increase from +20% to +30%\n- External APIs: Add +15% per integration\n- Code review: Increase from 10% to 20% buffer\n- Track environment issues separately (not estimation error)\n```\n\n### Pattern Recognition\n\nLook for recurring patterns across multiple estimates:\n\n```markdown\n## Pattern Analysis: Q4 2024\n\n### Identified Patterns\n\n1. **Assignment/Scheduling Features**: Consistently 1.5-2x\n   - Count: 4 features\n   - Average ratio: 1.72\n   - Action: Apply 1.7x multiplier\n\n2. **First-time Technology**: Learning curve underestimated\n   - Count: 3 projects\n   - Average ratio: 1.45\n   - Action: Add +50% for first use of new tech\n\n3. **Integration Endpoints**: More reliable estimates\n   - Count: 8 endpoints\n   - Average ratio: 1.08\n   - Action: Current estimation method working well\n\n4. **UI Polish**: Highly variable\n   - Count: 5 features\n   - Ratios: 0.8, 1.2, 1.6, 1.1, 2.0\n   - StdDev: 0.43\n   - Action: Needs better breakdown; decompose further\n```\n\n## Adjustment Strategies\n\n### Multiplicative Adjustment\n\nWhen you consistently under/over-estimate by a factor:\n\n```\nNew Estimate = Base Estimate * Calibration Factor\n\nExample:\n  Historical accuracy: 1.25 (25% underestimate)\n  Calibration factor: 1.25\n\n  For new estimate:\n    Base estimate: 40 hours\n    Calibrated estimate: 40 * 1.25 = 50 hours\n```\n\n### Additive Adjustment\n\nWhen there's a consistent fixed overhead:\n\n```\nNew Estimate = Base Estimate + Fixed Overhead\n\nExample:\n  Historical pattern: Always +8 hours for deployment setup\n\n  For new estimate:\n    Base estimate: 40 hours\n    Calibrated estimate: 40 + 8 = 48 hours\n```\n\n### Category-Specific Adjustment\n\nApply different adjustments to different work types:\n\n```markdown\n## Calibration Factors by Category\n\n| Category | Factor | Basis |\n|----------|--------|-------|\n| CRUD operations | 0.95 | Slightly overestimate |\n| Business logic | 1.20 | Often underestimate |\n| Integrations | 1.30 | External unknowns |\n| Data migration | 1.50 | Always surprises |\n| UI/UX polish | 1.40 | Subjective, iterative |\n| Performance opt | 1.25 | Profiling takes time |\n| Security features | 1.35 | Compliance overhead |\n\n## Applying Factors\n\nBase estimate: 40 hours\n  - CRUD (10h): 10 * 0.95 = 9.5h\n  - Business logic (15h): 15 * 1.20 = 18h\n  - Integration (10h): 10 * 1.30 = 13h\n  - Other (5h): 5 * 1.0 = 5h\n\nCalibrated total: 45.5 hours\n```\n\n### Skill-Phase Adjustment\n\nAdjust estimates by development phase:\n\n```markdown\n## Phase Calibration Factors\n\nBased on 50+ skill-phase observations:\n\n| Phase | Avg Ratio | Factor | Notes |\n|-------|-----------|--------|-------|\n| spec | 1.15 | 1.15 | Stakeholder time |\n| estimation | 1.0 | 1.0 | Quick, consistent |\n| architect | 1.25 | 1.25 | Iteration cycles |\n| scaffold | 1.0 | 1.0 | Automated, quick |\n| implement | 1.20 | 1.20 | Core work varies |\n| test-generation | 1.15 | 1.15 | Edge cases |\n| code-verification | 1.0 | 1.0 | Automated |\n| code-validation | 1.30 | 1.30 | Integration surprises |\n| document | 1.0 | 1.0 | Consistent |\n| code-review | 1.20 | 1.20 | Revision cycles |\n| deploy | 1.0 | 1.0 | Procedural |\n```\n\n## Confidence Calibration\n\n### Calibrating Confidence Levels\n\nYour stated confidence should match actual accuracy:\n\n```markdown\n## Confidence Calibration Check\n\n| Stated Confidence | Expected Accuracy | Actual Accuracy | Calibrated? |\n|-------------------|-------------------|-----------------|-------------|\n| High | Within 10% | Within 8% | Yes |\n| Medium | Within 25% | Within 32% | No (overconfident) |\n| Low | Within 50% | Within 45% | Yes |\n\n### Adjustment\n\nWhen stating \"Medium\" confidence:\n- Previously: Expected within 25%\n- Actual: Within 32%\n- Action: Either improve estimates for Medium confidence,\n  or relabel current Medium estimates as Low confidence\n```\n\n### Confidence Intervals\n\nBuild empirical confidence intervals from historical data:\n\n```markdown\n## Historical Confidence Intervals\n\nBased on 100 estimates with Actual/Estimated ratios:\n\n| Percentile | Ratio | Meaning |\n|------------|-------|---------|\n| 5th | 0.75 | 5% chance of finishing 25% early |\n| 25th | 0.90 | 25% chance of finishing 10% early |\n| 50th | 1.05 | Median is 5% over |\n| 75th | 1.25 | 25% chance of running 25% over |\n| 95th | 1.60 | 5% chance of running 60% over |\n\n## Using Intervals for Ranges\n\nBase estimate: 40 hours\n\n- Optimistic (25th): 40 * 0.90 = 36 hours\n- Expected (50th): 40 * 1.05 = 42 hours\n- Conservative (75th): 40 * 1.25 = 50 hours\n- Worst-case (95th): 40 * 1.60 = 64 hours\n\nCommunicate as: \"40-50 hours, possibly up to 64 if issues arise\"\n```\n\n## Calibration by Mode\n\n### Greenfield Calibration\n\nTrack calibration metrics separately for greenfield projects:\n\n```markdown\n## Greenfield Calibration Data\n\n| Metric | Value | Notes |\n|--------|-------|-------|\n| Count | 12 systems | Last 12 months |\n| Avg Accuracy | 1.35 | 35% underestimate typical |\n| Bias | +28% | Systematic underestimate |\n| MAPE | 32% | Higher variance expected |\n| Precision | 0.32 | More variable |\n\n### Greenfield-Specific Factors\n\n| Factor | Current | Calibrated |\n|--------|---------|------------|\n| Architecture decisions | +30% | +40% |\n| New tech learning | +50% | +70% |\n| Scaffolding | +10% | +15% |\n| Testing setup | +20% | +30% |\n\n### Greenfield Multiplier\n\nHistorical base: 1.35\nAdd 0.15 for safety: 1.50\n\nApply 1.5x multiplier to all greenfield estimates.\n```\n\n### Brownfield-Polish Calibration\n\n```markdown\n## Polish Mode Calibration Data\n\n| Metric | Value | Notes |\n|--------|-------|-------|\n| Count | 25 features | Last 12 months |\n| Avg Accuracy | 1.18 | 18% underestimate |\n| Bias | +15% | Moderate underestimate |\n| MAPE | 22% | Reasonable variance |\n| Precision | 0.24 | Fairly consistent |\n\n### Polish-Specific Factors\n\n| Factor | Current | Calibrated |\n|--------|---------|------------|\n| Code understanding | +20% | +25% |\n| Compatibility | +15% | +20% |\n| Existing test patterns | +10% | +10% |\n\n### Polish Multiplier\n\nHistorical base: 1.18\nAdd 0.07 for safety: 1.25\n\nApply 1.25x multiplier to polish estimates.\n```\n\n### Brownfield-Enterprise Calibration\n\n```markdown\n## Enterprise Mode Calibration Data\n\n| Metric | Value | Notes |\n|--------|-------|-------|\n| Count | 40 changes | Last 12 months |\n| Avg Accuracy | 1.08 | 8% underestimate |\n| Bias | +6% | Small bias |\n| MAPE | 15% | Good accuracy |\n| Precision | 0.18 | Very consistent |\n\n### Enterprise-Specific Factors\n\nProcess overhead well-captured in estimates:\n- Code review: 4h (accurate)\n- Security review: 2h (accurate)\n- Deployment window: 1h (accurate)\n\n### Enterprise Multiplier\n\nHistorical base: 1.08\nAdd 0.07 for safety: 1.15\n\nApply 1.15x multiplier to enterprise estimates.\n```\n\n## Calibration Reviews\n\n### Weekly Review (Quick Check)\n\n```markdown\n## Weekly Calibration Check\n\nWeek: 2024-W03\n\n| Item | Estimated | Actual | Ratio |\n|------|-----------|--------|-------|\n| Feature A | 8h | 10h | 1.25 |\n| Bug fix B | 2h | 1.5h | 0.75 |\n| Integration C | 12h | 14h | 1.17 |\n\n**Week accuracy:** 1.06 (on target)\n**Notes:** Integration slightly underestimated; watch pattern.\n```\n\n### Monthly Review (Trend Analysis)\n\n```markdown\n## Monthly Calibration Review\n\nMonth: January 2024\n\n### Summary Statistics\n\n| Metric | This Month | 3-Month Avg | Trend |\n|--------|------------|-------------|-------|\n| Count | 15 | 14 | Stable |\n| Avg Accuracy | 1.12 | 1.18 | Improving |\n| Bias | +10% | +14% | Improving |\n| MAPE | 18% | 21% | Improving |\n| Precision | 0.22 | 0.25 | Improving |\n\n### Top Variance Items\n\n1. Project X: 1.45 (integration complexity)\n2. Feature Y: 0.70 (overestimated)\n3. Change Z: 1.38 (scope creep)\n\n### Pattern Observations\n\n- Integration estimates improving (was 1.35, now 1.20)\n- Still underestimating auth features\n- Overestimating simple CRUD operations\n\n### Actions\n\n1. Reduce CRUD estimates by 10%\n2. Increase auth feature estimates by 20%\n3. Continue monitoring integration accuracy\n```\n\n### Quarterly Review (Strategic)\n\n```markdown\n## Quarterly Calibration Review\n\nQuarter: Q4 2024\n\n### Executive Summary\n\nOverall accuracy improved from 1.24 (Q3) to 1.12 (Q4).\nMAPE reduced from 24% to 18%.\nOn track to reach <15% MAPE target by Q2 2025.\n\n### Accuracy by Category\n\n| Category | Q3 | Q4 | Change |\n|----------|-----|-----|--------|\n| Greenfield | 1.38 | 1.28 | -7% |\n| Polish | 1.22 | 1.15 | -6% |\n| Enterprise | 1.12 | 1.05 | -6% |\n\n### Accuracy by Skill Phase\n\n[Chart showing skill-by-skill accuracy trends]\n\n### Key Improvements Made\n\n1. Added complexity factors for auth (+30%)\n2. Increased integration buffers (+25%)\n3. Added review cycle overhead (20%)\n\n### Focus Areas for Next Quarter\n\n1. Reduce greenfield variance (MAPE still 28%)\n2. Better capture UI polish effort\n3. Improve scheduling feature estimates\n```\n\n## Best Practices\n\n### Do's\n\n1. **Record immediately**: Capture actual effort when fresh\n2. **Be honest**: Accurate data is more valuable than looking good\n3. **Track granularly**: Component-level data reveals patterns\n4. **Review regularly**: Weekly quick checks, monthly deep dives\n5. **Share learnings**: Team calibration improves everyone\n6. **Update multipliers**: Apply insights to future estimates\n7. **Track by category**: Different work types need different calibration\n\n### Don'ts\n\n1. **Don't cherry-pick**: Include all estimates, not just accurate ones\n2. **Don't blame**: Variance is learning opportunity, not failure\n3. **Don't over-adjust**: Small sample sizes can mislead\n4. **Don't ignore outliers**: They often reveal important patterns\n5. **Don't forget context**: Note why variance occurred\n6. **Don't set and forget**: Calibration needs continuous attention\n\n### Sample Size Considerations\n\n| Sample Size | Confidence | Action |\n|-------------|------------|--------|\n| < 5 | Very Low | Gather more data before adjusting |\n| 5-10 | Low | Note patterns, tentative adjustments |\n| 10-20 | Medium | Make moderate adjustments |\n| 20-50 | Good | Reliable calibration factors |\n| > 50 | High | Fine-tune adjustments |\n\n## Calibration Templates\n\n### Per-Project Template\n\n```markdown\n# Calibration Record: [Project Name]\n\n## Summary\n\n| Field | Value |\n|-------|-------|\n| Project | [Name] |\n| Mode | [Greenfield/Polish/Enterprise] |\n| Estimated | [X hours] |\n| Actual | [Y hours] |\n| Accuracy | [Y/X] |\n| Start Date | [Date] |\n| End Date | [Date] |\n\n## Component Breakdown\n\n| Component | Est | Act | Ratio | Notes |\n|-----------|-----|-----|-------|-------|\n| | | | | |\n\n## Skill Phase Breakdown\n\n| Skill | Est | Act | Ratio |\n|-------|-----|-----|-------|\n| | | | |\n\n## Variance Analysis\n\n### Primary Causes\n- [ ] Scope change\n- [ ] Complexity surprise\n- [ ] External dependency\n- [ ] Technical issues\n- [ ] Learning curve\n- [ ] Process overhead\n- [ ] Estimation error\n\n### Details\n[Explain significant variances]\n\n## Lessons Learned\n[What will you do differently?]\n\n## Recommended Adjustments\n[Specific factors to update]\n```\n\n### Calibration Dashboard Template\n\n```markdown\n# Estimation Calibration Dashboard\n\nLast Updated: [Date]\n\n## Current Performance\n\n| Metric | Value | Target | Status |\n|--------|-------|--------|--------|\n| Accuracy | [X] | 0.9-1.1 | [On/Off track] |\n| Bias | [X%] | +/- 10% | [On/Off track] |\n| MAPE | [X%] | < 25% | [On/Off track] |\n| Precision | [X] | < 0.25 | [On/Off track] |\n\n## Trends\n\n[Sparkline or trend indicators]\n\n## Active Calibration Factors\n\n| Factor | Value | Basis | Last Updated |\n|--------|-------|-------|--------------|\n| Greenfield multiplier | 1.5x | 12 samples | 2024-01 |\n| Polish multiplier | 1.25x | 25 samples | 2024-01 |\n| Enterprise multiplier | 1.15x | 40 samples | 2024-01 |\n| Auth features | +30% | 8 samples | 2024-01 |\n| Integrations | +25% | 15 samples | 2024-01 |\n\n## Recent Observations\n\n[List recent calibration insights]\n\n## Action Items\n\n[List pending calibration adjustments]\n```\n\n## Common Calibration Issues\n\n### Issue: Inconsistent Data Collection\n\n**Symptom:** Gaps in calibration data, inconsistent detail level\n\n**Solution:**\n- Build tracking into workflow (skill hooks)\n- Automate where possible (skillsLog integration)\n- Review data quality in weekly checks\n- Use templates for consistency\n\n### Issue: Adjustment Overreaction\n\n**Symptom:** Swinging between over and under-estimating\n\n**Solution:**\n- Require minimum sample size (5+) before adjusting\n- Make incremental adjustments (max 20% change)\n- Watch for regression after adjustments\n- Consider separate factors for different conditions\n\n### Issue: Ignoring Context\n\n**Symptom:** Same multiplier for all situations\n\n**Solution:**\n- Track metadata (mode, complexity, technology)\n- Segment calibration data by context\n- Build category-specific factors\n- Review outliers for context patterns\n\n### Issue: Gaming the Metrics\n\n**Symptom:** Estimates match actuals but work quality suffers\n\n**Solution:**\n- Track quality metrics alongside accuracy\n- Include scope completion in calibration\n- Review actual vs estimated scope\n- Focus on value delivered, not just hours\n\n## See Also\n\n- `estimation-methods.md` - Estimation approaches to calibrate\n- `complexity-factors.md` - Factors that affect estimates\n- `estimate-template.md` - Standard estimate format\n- SKILL.md Calibration section - Integration with skillsLog\n"
    },
    {
      "name": "complexity-factors.md",
      "path": "references/complexity-factors.md",
      "content": "# Complexity Factors\n\nCatalog of factors that increase effort with adjustment guidelines.\n\n## Factor Categories\n\n```\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                    COMPLEXITY FACTOR CATEGORIES                              │\n│                                                                             │\n│  TECHNICAL           INTEGRATION         REQUIREMENTS       ORGANIZATIONAL  │\n│  ─────────           ───────────         ────────────       ──────────────  │\n│  New technology      External APIs       Unclear scope      Team experience │\n│  Performance needs   Legacy systems      Compliance         Communication   │\n│  Security needs      Data migration      UX complexity      Dependencies    │\n│  Scale requirements  Multi-system        Localization       Stakeholders    │\n│                                                                             │\n└─────────────────────────────────────────────────────────────────────────────┘\n```\n\n## Technical Factors\n\n### New Technology\n\n| Situation | Multiplier | Notes |\n|-----------|------------|-------|\n| Team has used extensively | 1.0x | No adjustment |\n| Team has some experience | 1.2-1.3x | Minor learning curve |\n| Team has tried once | 1.5x | Significant learning |\n| Completely new to team | 1.8-2.0x | Major learning + mistakes |\n| Bleeding edge / beta | 2.0-3.0x | Bugs, poor docs, changes |\n\n**Example:**\n```\nBase estimate: 40 hours\nFactor: New framework (team tried once) → 1.5x\nAdjusted: 60 hours\n```\n\n### Performance Requirements\n\n| Requirement | Multiplier | Typical Work Added |\n|-------------|------------|-------------------|\n| Standard (no specific targets) | 1.0x | None |\n| Moderate (<500ms p95) | 1.2x | Basic optimization, caching |\n| Strict (<100ms p95) | 1.4x | Serious optimization, load testing |\n| Extreme (<50ms, high throughput) | 1.6-2.0x | Architecture changes, extensive testing |\n\n### Security Requirements\n\n| Requirement | Multiplier | Typical Work Added |\n|-------------|------------|-------------------|\n| Standard (basic auth) | 1.0x | None |\n| Handles PII | 1.3x | Encryption, audit logs, compliance |\n| Financial data | 1.4x | Additional controls, testing |\n| Healthcare (HIPAA) | 1.5-1.8x | Compliance documentation, audits |\n| Payment processing (PCI) | 1.5-2.0x | Strict controls, certification |\n\n### Scale Requirements\n\n| Scale | Multiplier | Notes |\n|-------|------------|-------|\n| Small (<1K users) | 1.0x | Single instance fine |\n| Medium (1K-100K users) | 1.1x | Basic scaling patterns |\n| Large (100K-1M users) | 1.3x | Caching, load balancing |\n| Very Large (>1M users) | 1.5-2.0x | Distributed systems, sharding |\n\n## Integration Factors\n\n### External API Integration\n\n| Situation | Multiplier per Integration |\n|-----------|---------------------------|\n| Well-documented, stable API | +15-20% |\n| Poorly documented API | +30-40% |\n| Unreliable/flaky API | +40-50% |\n| Beta/unstable API | +50-80% |\n\n**Note:** Multiple integrations may compound. 3 integrations at 1.2x each ≈ 1.7x total.\n\n### Legacy System Integration\n\n| Legacy Situation | Multiplier |\n|------------------|------------|\n| Modern, well-maintained | 1.1x |\n| Older but documented | 1.3x |\n| Poorly documented | 1.5x |\n| \"Don't touch that code\" | 1.8-2.5x |\n\n### Data Migration\n\n| Migration Type | Multiplier |\n|----------------|------------|\n| Simple copy | 1.1x |\n| With transformation | 1.3x |\n| With validation/cleanup | 1.5x |\n| Complex mapping + rollback plan | 1.8-2.0x |\n\n## Requirements Factors\n\n### Scope Clarity\n\n| Clarity Level | Multiplier | Indicator |\n|---------------|------------|-----------|\n| Crystal clear | 1.0x | Detailed spec with examples |\n| Mostly clear | 1.2x | Spec exists, some questions |\n| Somewhat unclear | 1.4x | High-level only, many TBDs |\n| Vague | 1.6-2.0x | \"Make it work like X\" |\n\n### Regulatory/Compliance\n\n| Compliance Type | Multiplier |\n|-----------------|------------|\n| None | 1.0x |\n| Basic audit logging | 1.1x |\n| SOC 2 / ISO 27001 | 1.3x |\n| HIPAA / PCI | 1.5x |\n| Government / Defense | 1.8-2.5x |\n\n### UX Complexity\n\n| UI Type | Multiplier |\n|---------|------------|\n| No UI (API only) | 1.0x |\n| Simple forms | 1.1x |\n| Standard CRUD | 1.2x |\n| Complex interactions | 1.4x |\n| Highly polished / animations | 1.5x |\n| Accessibility (WCAG AA+) | +20% |\n\n### Localization\n\n| Localization | Multiplier |\n|--------------|------------|\n| Single language | 1.0x |\n| 2-3 languages | 1.15x |\n| Many languages | 1.3x |\n| RTL support | 1.4x |\n\n## Organizational Factors\n\n### Team Experience\n\n| Team Situation | Multiplier |\n|----------------|------------|\n| Expert team, worked together before | 0.9x |\n| Experienced team | 1.0x |\n| Mixed experience | 1.1x |\n| Junior-heavy team | 1.3-1.5x |\n| New team members | +10% per new person |\n\n### Communication Overhead\n\n| Situation | Multiplier |\n|-----------|------------|\n| Solo developer | 0.95x |\n| Small co-located team | 1.0x |\n| Distributed team (same timezone) | 1.1x |\n| Distributed team (different timezones) | 1.2x |\n| Multiple stakeholder groups | 1.2-1.4x |\n\n### External Dependencies\n\n| Dependency Type | Multiplier |\n|-----------------|------------|\n| Self-contained | 1.0x |\n| Depends on 1 other team | 1.15x |\n| Depends on multiple teams | 1.3x |\n| Depends on external vendor | 1.3-1.5x |\n| Blocked by external (timeline unknown) | Add buffer |\n\n## Applying Multiple Factors\n\n### Additive vs Multiplicative\n\nFor **similar category** factors: Add the excess\n```\nSecurity (1.3x) + Compliance (1.3x) from same domain\n= 1.0 + 0.3 + 0.3 = 1.6x (not 1.3 × 1.3 = 1.69x)\n```\n\nFor **different category** factors: Multiply\n```\nNew tech (1.5x) × Integration (1.3x) × Unclear scope (1.4x)\n= 1.5 × 1.3 × 1.4 = 2.73x\n```\n\n### Maximum Reasonable Multiplier\n\nIf combined factors exceed **3.0x**, consider:\n- Is this too risky to estimate?\n- Should we do a spike/prototype first?\n- Should we break it down differently?\n\n### Example: Complex Feature\n\n```markdown\n## Factor Analysis: Healthcare Patient Portal\n\n### Base Estimate: 60 hours (from bottom-up)\n\n### Technical Factors\n- New framework (1.3x): React Native, some team experience\n- Performance (1.2x): <200ms requirement\n\n### Integration Factors  \n- 2 external APIs (1.3x): EHR and billing systems\n- Legacy system (1.3x): Connection to existing patient database\n\n### Requirements Factors\n- HIPAA compliance (1.5x): Healthcare data\n- Accessibility (1.2x): WCAG AA required\n\n### Organizational Factors\n- Distributed team (1.1x): 2 timezones\n\n### Calculation\n\nTechnical: 1.3 × 1.2 = 1.56\nIntegration: 1.3 × 1.3 = 1.69\nRequirements: 1.5 × 1.2 = 1.8\nOrganizational: 1.1\n\nCombined: sqrt(1.56 × 1.69 × 1.8 × 1.1) = 2.2x\n(Using geometric mean to avoid over-inflation)\n\n### Final Estimate\n\nBase: 60 hours\nAdjusted: 60 × 2.2 = **132 hours**\nRange: 110-160 hours\n\n### Key Risks\n1. HIPAA compliance could require additional review cycles\n2. Legacy system integration is the biggest unknown\n3. Two external APIs with unknown reliability\n```\n\n## Quick Reference Card\n\n| Factor | Low | Medium | High |\n|--------|-----|--------|------|\n| New Technology | 1.2x | 1.5x | 2.0x |\n| Performance | 1.2x | 1.4x | 1.8x |\n| Security | 1.2x | 1.4x | 1.6x |\n| Integration (per) | 1.15x | 1.3x | 1.5x |\n| Legacy Code | 1.2x | 1.4x | 2.0x |\n| Unclear Scope | 1.2x | 1.4x | 1.8x |\n| Compliance | 1.2x | 1.4x | 1.8x |\n| UI Complexity | 1.2x | 1.4x | 1.6x |\n| Team Experience | 1.1x | 1.2x | 1.4x |\n"
    },
    {
      "name": "estimate-template.md",
      "path": "references/estimate-template.md",
      "content": "# Estimate Template\n\nStandard format for documenting estimates.\n\n## Full Estimate Template\n\n```markdown\n# Estimate: [System/Feature Name]\n\n**Estimated by:** [Agent/Person]\n**Date:** [YYYY-MM-DD]\n**Spec Reference:** [Link to FeatureSpec or GitHub Issue]\n**Valid until:** [Date or \"requirements change\"]\n\n---\n\n## Executive Summary\n\n| Dimension | Value |\n|-----------|-------|\n| **Complexity** | [S / M / L / XL] |\n| **Effort** | [X-Y hours] |\n| **Duration** | [X-Y days/weeks] |\n| **Confidence** | [High / Medium / Low] |\n| **Risk Level** | [Low / Medium / High] |\n\n**One-line summary:** [Brief description of what's being estimated]\n\n---\n\n## Scope\n\n### Included\n\n- [ ] Capability 1: [Description]\n- [ ] Capability 2: [Description]\n- [ ] Capability 3: [Description]\n- [ ] Testing (unit, integration)\n- [ ] Documentation\n- [ ] Code review\n\n### Explicitly NOT Included\n\n- Deployment/infrastructure changes\n- [Other exclusions]\n- [Future features]\n\n### Gray Areas (Need Clarification)\n\n- [ ] [Item needing clarification]\n- [ ] [Item needing clarification]\n\n---\n\n## Breakdown\n\n### By Capability\n\n| Capability | Base Hours | Complexity Factor | Adjusted Hours |\n|------------|------------|-------------------|----------------|\n| [Capability 1] | X | [factor] | Y |\n| [Capability 2] | X | [factor] | Y |\n| [Capability 3] | X | [factor] | Y |\n| Testing | X | — | X |\n| Documentation | X | — | X |\n| Review/Polish | X | — | X |\n| **Total** | **X** | | **Y** |\n\n### By Phase (Alternative)\n\n| Phase | Hours | Notes |\n|-------|-------|-------|\n| Design/Planning | X | |\n| Implementation | X | |\n| Testing | X | |\n| Documentation | X | |\n| Review/Fixes | X | |\n| **Total** | **X** | |\n\n---\n\n## Assumptions\n\nCritical assumptions this estimate depends on:\n\n1. **[Assumption 1]**\n   - If false: [Impact on estimate]\n   \n2. **[Assumption 2]**\n   - If false: [Impact on estimate]\n\n3. **[Assumption 3]**\n   - If false: [Impact on estimate]\n\n---\n\n## Risks\n\n| Risk | Probability | Impact | Mitigation | Estimate Impact |\n|------|-------------|--------|------------|-----------------|\n| [Risk 1] | [H/M/L] | [H/M/L] | [Action] | +X hours |\n| [Risk 2] | [H/M/L] | [H/M/L] | [Action] | +X hours |\n| [Risk 3] | [H/M/L] | [H/M/L] | [Action] | +X hours |\n\n**Risk-adjusted estimate:** [If risks materialize, estimate could be X-Y hours]\n\n---\n\n## Dependencies\n\n### Blocking Dependencies\n\n| Dependency | Status | Owner | Expected Resolution |\n|------------|--------|-------|---------------------|\n| [Dependency 1] | [Status] | [Team/Person] | [Date] |\n\n### Non-Blocking Dependencies\n\n| Dependency | Impact if Delayed |\n|------------|-------------------|\n| [Dependency 1] | [Impact] |\n\n---\n\n## Historical Comparison\n\n| Similar Work | Estimated | Actual | Variance | Relevance |\n|--------------|-----------|--------|----------|-----------|\n| [Past project 1] | X hours | Y hours | +/-Z% | [How similar] |\n| [Past project 2] | X hours | Y hours | +/-Z% | [How similar] |\n\n**Lessons applied from history:**\n- [Lesson 1]\n- [Lesson 2]\n\n---\n\n## Duration Calculation\n\n### Effort to Duration\n\n| Scenario | Effort | Resources | Duration |\n|----------|--------|-----------|----------|\n| Solo developer | X hours | 1 | Y days |\n| Pair | X hours | 2 | Y days |\n| Team | X hours | 3 | Y days |\n\n### Critical Path\n\n```\n[Dependency 1] ──► [Task A] ──► [Task B] ──► [Task C]\n                                    │\n                              [Task D] (parallel)\n```\n\n**Minimum duration:** [X days] (assuming no blockers)\n**Expected duration:** [Y days] (with typical delays)\n\n---\n\n## Confidence Assessment\n\n### Confidence: [High / Medium / Low]\n\n| Factor | Assessment |\n|--------|------------|\n| Scope clarity | [Clear / Somewhat clear / Unclear] |\n| Technical familiarity | [High / Medium / Low] |\n| Team availability | [Confirmed / Likely / Unknown] |\n| Dependency status | [Resolved / In progress / Unknown] |\n| Historical data | [Strong / Some / None] |\n\n### What Would Increase Confidence\n\n- [ ] [Action that would increase confidence]\n- [ ] [Spike or prototype]\n- [ ] [Clarification from stakeholder]\n\n---\n\n## Estimate History\n\n| Date | Estimate | Change | Reason |\n|------|----------|--------|--------|\n| [Date] | [X hours] | Initial | — |\n| [Date] | [Y hours] | +Z hours | [Reason for change] |\n\n---\n\n## Approvals\n\n| Role | Name | Date | Notes |\n|------|------|------|-------|\n| Estimator | [Name] | [Date] | |\n| Reviewer | [Name] | [Date] | |\n| Approver | [Name] | [Date] | |\n```\n\n---\n\n## Quick Estimate Template\n\nFor faster estimates when full detail isn't needed:\n\n```markdown\n# Quick Estimate: [Feature Name]\n\n**Date:** [Date]\n**Complexity:** [S/M/L/XL]\n**Effort:** [X-Y hours]\n**Confidence:** [H/M/L]\n\n## Scope\n[2-3 sentence description of what's included]\n\n## Key Assumptions\n1. [Assumption 1]\n2. [Assumption 2]\n\n## Main Risks\n1. [Risk 1] — could add [X hours]\n\n## Basis\n[How estimate was derived — analogous, parametric, etc.]\n```\n\n---\n\n## Estimate Update Template\n\nFor updating existing estimates:\n\n```markdown\n# Estimate Update: [Feature Name]\n\n**Original Estimate:** [X hours] ([Date])\n**Updated Estimate:** [Y hours] ([Today])\n**Change:** [+/-Z hours] ([+/-N%])\n\n## Reason for Update\n\n[Explanation of what changed]\n\n## Impact\n\n- **Schedule:** [Impact on timeline]\n- **Scope:** [Any scope changes]\n- **Resources:** [Any resource changes]\n\n## Revised Assumptions\n\n[Updated assumptions list]\n\n## Next Update\n\n[When estimate will be revisited, if applicable]\n```\n"
    },
    {
      "name": "estimation-methods.md",
      "path": "references/estimation-methods.md",
      "content": "# Estimation Methods\n\nDetailed guide to each estimation method with examples.\n\n## Method Selection Guide\n\n```\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                    WHICH METHOD TO USE?                                      │\n│                                                                             │\n│  How much detail do you have?                                               │\n│  │                                                                          │\n│  ├─ Just a concept, no spec yet                                             │\n│  │   └─→ T-Shirt Sizing                                                     │\n│  │                                                                          │\n│  ├─ Have done similar work before                                           │\n│  │   └─→ Analogous Estimation                                               │\n│  │                                                                          │\n│  ├─ Work is repetitive/countable                                            │\n│  │   └─→ Parametric Estimation                                              │\n│  │                                                                          │\n│  ├─ High uncertainty, need to show risk                                     │\n│  │   └─→ Three-Point Estimation                                             │\n│  │                                                                          │\n│  └─ Detailed spec, need accurate forecast                                   │\n│      └─→ Bottom-Up Estimation                                               │\n│                                                                             │\n└─────────────────────────────────────────────────────────────────────────────┘\n```\n\n## T-Shirt Sizing\n\n### Definition\n\nQuick relative sizing using Small/Medium/Large/XL categories.\n\n### When to Use\n\n- Early project planning\n- Backlog grooming\n- Comparing relative effort of items\n- When detailed specs don't exist yet\n\n### Reference Points\n\nEstablish calibration with team:\n\n| Size | Reference Example | Hours (Typical) |\n|------|-------------------|-----------------|\n| **S** | Add a config option | 1-4 |\n| **M** | New API endpoint with tests | 4-16 |\n| **L** | New feature with multiple endpoints | 16-40 |\n| **XL** | New service or major feature | 40-100 |\n\n### Process\n\n1. Review item description\n2. Compare to reference examples\n3. Assign size\n4. If between sizes, round up\n5. If larger than XL, decompose\n\n### Example\n\n```markdown\n## T-Shirt Sizing Session\n\n| Item | Size | Rationale |\n|------|------|-----------|\n| Add email validation | S | Simple regex, one field |\n| User profile page | M | CRUD + UI, straightforward |\n| OAuth integration | L | External API, security, multiple flows |\n| Reporting dashboard | XL | Multiple charts, data aggregation, filters |\n| Mobile app MVP | Beyond XL | Decompose into smaller items |\n```\n\n---\n\n## Analogous Estimation\n\n### Definition\n\nEstimate by comparing to similar completed work.\n\n### When to Use\n\n- Similar work has been done before\n- Historical data is available\n- New work has recognizable patterns\n\n### Process\n\n1. Identify similar past work\n2. Note the actual effort from that work\n3. Identify differences (scope, complexity, context)\n4. Adjust estimate based on differences\n5. Document the comparison\n\n### Example\n\n```markdown\n## Analogous Estimate: Notification Service\n\n### Reference: Email Service (completed Q3)\n\n| Aspect | Email Service (Actual) | Notification Service | Adjustment |\n|--------|------------------------|---------------------|------------|\n| **Core logic** | 16 hours | Similar complexity | 16 hours |\n| **Channels** | 1 (SMTP) = 8 hours | 4 channels | 32 hours |\n| **Templates** | 6 hours | Reuse pattern | 6 hours |\n| **Testing** | 10 hours | More channels | 16 hours |\n| **Deployment** | 4 hours | Same process | 4 hours |\n\n### Summary\n\n| | Email | Notification | Delta |\n|-|-------|--------------|-------|\n| **Total** | 44 hours | 74 hours | +68% |\n\n### Confidence: Medium\n- Same architecture pattern: +confidence\n- More channels to integrate: -confidence\n- Team is experienced now: +confidence\n```\n\n---\n\n## Parametric Estimation\n\n### Definition\n\nCalculate estimate using mathematical relationships between variables.\n\n### When to Use\n\n- Work is repetitive\n- Units are countable (endpoints, screens, reports)\n- Historical rates are known\n\n### Process\n\n1. Identify the countable units\n2. Determine rate per unit (from history)\n3. Count units in new work\n4. Multiply: Estimate = Count × Rate\n5. Add fixed costs (setup, deployment, etc.)\n\n### Common Parameters\n\n| Unit | Typical Rate | Notes |\n|------|--------------|-------|\n| REST endpoint | 2-4 hours | Including basic tests |\n| Database table | 1-2 hours | Schema + model |\n| UI screen | 4-8 hours | Depending on complexity |\n| Integration | 8-16 hours | Per external system |\n| Report | 4-12 hours | Depending on complexity |\n\n### Example\n\n```markdown\n## Parametric Estimate: Customer Portal API\n\n### Known Rates (from team history)\n- REST endpoint: 3 hours average\n- Database model: 1.5 hours average\n- Integration test: 1 hour per endpoint\n\n### Scope Count\n| Unit | Count |\n|------|-------|\n| Endpoints | 12 |\n| Database models | 5 |\n| Integrations | 2 |\n\n### Calculation\n\n| Component | Count | Rate | Total |\n|-----------|-------|------|-------|\n| Endpoints | 12 | 3 | 36 |\n| Models | 5 | 1.5 | 7.5 |\n| Integration tests | 12 | 1 | 12 |\n| External integrations | 2 | 12 | 24 |\n| **Subtotal** | | | **79.5** |\n| Setup/scaffolding | | | 8 |\n| Documentation | | | 6 |\n| **Total** | | | **93.5 hours** |\n\n### Confidence: High\n- Well-understood work\n- Rates from recent similar project\n```\n\n---\n\n## Three-Point Estimation (PERT)\n\n### Definition\n\nAccount for uncertainty using optimistic, most likely, and pessimistic scenarios.\n\n### When to Use\n\n- Significant uncertainty exists\n- Need to communicate risk to stakeholders\n- Novel or complex work\n- External dependencies\n\n### Formula\n\n```\nPERT Estimate = (O + 4M + P) / 6\n\nWhere:\n  O = Optimistic (best case, 10% probability)\n  M = Most Likely (realistic case)\n  P = Pessimistic (worst case, 10% probability)\n\nStandard Deviation = (P - O) / 6\n```\n\n### Process\n\n1. Estimate optimistic scenario (everything goes right)\n2. Estimate most likely scenario (typical experience)\n3. Estimate pessimistic scenario (things go wrong, but project completes)\n4. Calculate PERT estimate\n5. Report range based on standard deviation\n\n### Example\n\n```markdown\n## Three-Point Estimate: Payment Gateway Integration\n\n### Scenarios\n\n| Scenario | Estimate | Assumptions |\n|----------|----------|-------------|\n| **Optimistic (O)** | 30 hours | Clean API, good docs, no compliance issues |\n| **Most Likely (M)** | 50 hours | Some API quirks, normal back-and-forth |\n| **Pessimistic (P)** | 100 hours | Poor API, compliance review required, rework |\n\n### Calculation\n\nPERT = (30 + 4×50 + 100) / 6 = **55 hours**\nStd Dev = (100 - 30) / 6 = **11.7 hours**\n\n### Ranges\n\n| Confidence | Range | Interpretation |\n|------------|-------|----------------|\n| 68% (±1σ) | 43-67 hours | Likely range |\n| 95% (±2σ) | 32-78 hours | Almost certain |\n\n### Recommendation\n\n**Estimate: 55 hours** with range of 43-67 hours\n\nKey risks:\n- API documentation quality unknown\n- Compliance review may be required\n- Test environment availability\n\n### Confidence: Medium\n```\n\n---\n\n## Bottom-Up Estimation\n\n### Definition\n\nBuild estimate by summing detailed task-level estimates.\n\n### When to Use\n\n- Detailed spec available\n- Need accurate forecast\n- Sprint planning / commitment\n- Fixed-price work\n\n### Process\n\n1. Decompose work into tasks (< 1 day each)\n2. Estimate each task\n3. Identify dependencies\n4. Sum for total effort\n5. Calculate duration considering parallelism\n6. Add contingency\n\n### Task Granularity\n\n| Too Big | Right Size | Too Small |\n|---------|------------|-----------|\n| \"Build the API\" | \"Implement POST /orders endpoint\" | \"Write line 45 of controller\" |\n| \"Add authentication\" | \"Integrate JWT middleware\" | \"Import jwt library\" |\n\n### Example\n\n```markdown\n## Bottom-Up Estimate: Inventory Service\n\n### Task Breakdown\n\n#### 1. Setup & Scaffolding\n| Task | Hours | Dependencies |\n|------|-------|--------------|\n| Create repo structure | 1 | - |\n| Configure database | 2 | - |\n| Setup CI/CD | 2 | - |\n| **Subtotal** | **5** | |\n\n#### 2. Core Models\n| Task | Hours | Dependencies |\n|------|-------|--------------|\n| Product model | 2 | Setup |\n| Location model | 1.5 | Setup |\n| Stock model | 2 | Product, Location |\n| Movement model | 2 | Stock |\n| **Subtotal** | **7.5** | |\n\n#### 3. API Endpoints\n| Task | Hours | Dependencies |\n|------|-------|--------------|\n| GET /products | 2 | Product model |\n| POST /products | 2 | Product model |\n| GET /stock | 3 | Stock model |\n| POST /stock/adjust | 4 | Stock, Movement |\n| GET /movements | 2 | Movement model |\n| **Subtotal** | **13** | |\n\n#### 4. Business Logic\n| Task | Hours | Dependencies |\n|------|-------|--------------|\n| Stock calculation | 4 | Models |\n| Low stock alerts | 3 | Stock |\n| Reservation system | 6 | Stock |\n| **Subtotal** | **13** | |\n\n#### 5. Testing\n| Task | Hours | Dependencies |\n|------|-------|--------------|\n| Unit tests | 8 | All code |\n| Integration tests | 6 | All code |\n| **Subtotal** | **14** | |\n\n#### 6. Documentation & Polish\n| Task | Hours | Dependencies |\n|------|-------|--------------|\n| API documentation | 4 | All endpoints |\n| README | 2 | All |\n| Code review fixes | 4 | Review feedback |\n| **Subtotal** | **10** | |\n\n### Summary\n\n| Phase | Hours |\n|-------|-------|\n| Setup | 5 |\n| Models | 7.5 |\n| Endpoints | 13 |\n| Business Logic | 13 |\n| Testing | 14 |\n| Documentation | 10 |\n| **Total Effort** | **62.5 hours** |\n\n### Duration Calculation\n\n- 1 developer: 62.5 / 6 hours/day = **10.4 days** (~2 weeks)\n- 2 developers (some parallelism): **7-8 days** (~1.5 weeks)\n\n### Contingency\n\nAdd 15% for unknowns: 62.5 × 1.15 = **72 hours**\n\n### Final Estimate\n\n**Effort:** 72 hours (range: 62-80)\n**Duration:** 2 weeks (1 developer)\n**Confidence:** High\n```\n\n---\n\n## Combining Methods\n\nOften useful to use multiple methods and compare:\n\n```markdown\n## Multi-Method Estimate: Search Feature\n\n| Method | Estimate | Notes |\n|--------|----------|-------|\n| T-Shirt | L (~30 hours) | Quick assessment |\n| Analogous | 35 hours | Compared to filters feature |\n| Three-Point | 38 hours | (25 + 4×35 + 60)/6 |\n| Bottom-Up | 42 hours | Detailed task list |\n\n### Reconciliation\n\n- Methods converge around 35-42 hours\n- Bottom-up slightly higher (good - it's more detailed)\n- Use 40 hours as estimate\n- Range: 32-48 hours (±20%)\n\n### Final: 40 hours, Medium confidence\n```\n"
    }
  ],
  "tags": [
    "planning",
    "estimation",
    "sizing",
    "effort"
  ],
  "dependsOn": []
}