{
  "id": "prototype-scoping",
  "name": "prototype-scoping",
  "version": "1.0.0",
  "description": "Scope pilot/prototype projects for deals approaching Production stage. Defines success criteria, timeline, scope boundaries, and resources needed for technical validation.",
  "phase": "IMPLEMENT",
  "category": "sales",
  "content": "# Prototype Scoping\n\nScope pilot/prototype projects for technical validation.\n\n## When to Use\n\n- **Moving to Production stage** — Define pilot parameters\n- **Technical validation needed** — Prove fit before full deal\n- **Risk reduction** — Both sides want to test first\n- When you say: \"scope the pilot\", \"define POC\", \"prototype parameters\"\n\n## Reference Requirements\n\n**MUST read before applying this skill:**\n\n| Reference | Why Required |\n|-----------|--------------|\n| `pilot-structure.md` | Standard pilot framework |\n| `success-criteria.md` | How to define pilot success |\n\n## Required Deliverables\n\n| Deliverable | Location | Condition |\n|-------------|----------|-----------|\n| Pilot scope document | `deals/{slug}/pilot/pilot-scope.md` | Always |\n| Success criteria | `deals/{slug}/pilot/pilot-scope.md` | Always |\n\n## Core Concept\n\nPrototype Scoping answers: **\"What will we build, how will we measure success, and what does it prove?\"**\n\nGood pilot scoping:\n- **Bounded** — Clear what's in and out of scope\n- **Measurable** — Defined success criteria\n- **Timeboxed** — Fixed duration\n- **Convertible** — Path from pilot to full deal\n\n## The Scoping Process\n\n```\n┌─────────────────────────────────────────────────────────┐\n│            PROTOTYPE SCOPING PROCESS                    │\n│                                                         │\n│  1. DEFINE OBJECTIVES                                   │\n│     └─→ What does the pilot need to prove?              │\n│                                                         │\n│  2. SCOPE BOUNDARIES                                    │\n│     └─→ What's in/out of scope                          │\n│                                                         │\n│  3. SUCCESS CRITERIA                                    │\n│     └─→ How will we measure success?                    │\n│                                                         │\n│  4. TIMELINE AND PHASES                                 │\n│     └─→ How long, what milestones                       │\n│                                                         │\n│  5. RESOURCES NEEDED                                    │\n│     └─→ Both sides' commitments                         │\n│                                                         │\n│  6. PATH TO FULL DEAL                                   │\n│     └─→ What happens after successful pilot             │\n└─────────────────────────────────────────────────────────┘\n```\n\n## pilot-scope.md Format\n\n```markdown\n# Pilot Scope: [Company Name]\n\n## Overview\n- **Company:** ShopCo\n- **Pilot Start:** February 15, 2026\n- **Pilot Duration:** 4 weeks\n- **Pilot End:** March 15, 2026\n- **Decision Date:** March 22, 2026\n\n## Pilot Objectives\n\n### Primary Objective\nValidate that AI can successfully automate Tier 1 support inquiries\nwith acceptable accuracy and customer satisfaction.\n\n### What This Pilot Proves\n1. Technical integration with Shopify Plus and Zendesk works\n2. AI can handle returns/exchanges/order status accurately\n3. Customer satisfaction is maintained or improved\n4. Ticket reduction targets are achievable\n\n### What This Pilot Does NOT Prove\n- Full scale (limited to subset of traffic)\n- All use cases (future phases not included)\n- Long-term performance (4 weeks only)\n\n## Scope Definition\n\n### In Scope\n| Item | Details |\n|------|---------|\n| Use cases | Returns, exchanges, order status |\n| Channel | Web chat only |\n| Traffic | 20% of chat volume |\n| Geography | US customers only |\n| Languages | English only |\n\n### Out of Scope\n| Item | Rationale |\n|------|-----------|\n| Email support | Phase 2 |\n| Phone support | Not planned |\n| All chat traffic | Risk mitigation |\n| Non-English | Future enhancement |\n| Custom integrations | Standard integration only |\n\n### Scope Boundaries\n- AI handles Tier 1 inquiries only\n- Escalation to human for complex cases\n- No access to sensitive payment data\n- Standard authentication via Okta\n\n## Success Criteria\n\n### Must Achieve (Required for Success)\n| Metric | Target | Measurement |\n|--------|--------|-------------|\n| Automation rate | >30% | % of chat handled by AI |\n| Accuracy | >90% | Spot-check of AI responses |\n| Customer satisfaction | No decrease | CSAT survey comparison |\n| Escalation rate | <20% | % requiring human handoff |\n\n### Should Achieve (Strongly Desired)\n| Metric | Target | Measurement |\n|--------|--------|-------------|\n| Response time | <30 seconds | Average first response |\n| Resolution rate | >80% | % resolved without escalation |\n| Agent satisfaction | Positive | Agent feedback survey |\n\n### Nice to Have (Bonus)\n| Metric | Target | Measurement |\n|--------|--------|-------------|\n| CSAT improvement | +5% | Survey comparison |\n| Handle time reduction | >20% | Average conversation length |\n\n## Timeline and Milestones\n\n### Week 1: Setup\n- [ ] Integration configuration\n- [ ] Knowledge base import\n- [ ] Initial training\n- [ ] Test environment validation\n\n### Week 2: Soft Launch (10% traffic)\n- [ ] Launch to 10% of chat volume\n- [ ] Daily monitoring\n- [ ] Issue identification and fixes\n- [ ] Baseline metrics established\n\n### Week 3-4: Expanded Pilot (20% traffic)\n- [ ] Expand to 20% of chat volume\n- [ ] Continuous monitoring\n- [ ] Weekly check-in calls\n- [ ] Collect feedback\n\n### Post-Pilot\n- [ ] Final metrics report\n- [ ] Success criteria evaluation\n- [ ] Go/no-go decision meeting\n- [ ] Full rollout planning (if successful)\n\n## Resource Commitments\n\n### ShopCo Provides\n| Resource | Commitment |\n|----------|------------|\n| Project lead | Sarah Chen (4 hrs/week) |\n| Technical lead | Michael Torres (2 hrs/week) |\n| Support manager | TBD (2 hrs/week) |\n| API access | Zendesk, Shopify Plus |\n| Test accounts | 5 test customer accounts |\n| Historical data | 6 months ticket history |\n\n### [Your Company] Provides\n| Resource | Commitment |\n|----------|------------|\n| Implementation lead | [Name] (dedicated) |\n| Technical support | [Name] (on-call) |\n| Training | Initial + ongoing |\n| Reporting | Weekly metrics |\n| Support | Slack channel for issues |\n\n## Risks and Mitigations\n\n| Risk | Likelihood | Impact | Mitigation |\n|------|------------|--------|------------|\n| Integration delays | Medium | High | Start integration Week -1 |\n| Accuracy issues | Medium | High | Start with 10% traffic |\n| Customer complaints | Low | High | Real-time monitoring |\n| Resource availability | Low | Medium | Confirm commitments upfront |\n\n## Decision Criteria\n\n### Success = Proceed to Full Rollout\nAll \"Must Achieve\" criteria met, no major issues.\n\n### Partial Success = Extend Pilot\nSome criteria met, issues are fixable.\n\n### Failure = Do Not Proceed\nMajor criteria missed, fundamental issues.\n\n## Path to Full Deal\n\n### If Pilot Succeeds\n1. Final metrics review (March 22)\n2. Full rollout proposal (March 25)\n3. Contract negotiation (April)\n4. Full production launch (May)\n\n### Commercial Terms\n- Pilot: No charge / reduced rate\n- Full deal: [Pricing approach]\n- Pilot credits toward annual contract\n\n## Sign-Off\n\n| Role | Name | Date |\n|------|------|------|\n| ShopCo Champion | Sarah Chen | |\n| ShopCo Technical | Michael Torres | |\n| [Your Company] | [Name] | |\n```\n\n## Output Format\n\nAfter scoping:\n\n```\n✓ Pilot Scoped: {company}\n\n  OVERVIEW:\n    Duration: 4 weeks (Feb 15 - Mar 15)\n    Decision Date: March 22, 2026\n\n  PILOT OBJECTIVES:\n    ★ Prove technical integration works\n    ★ Validate AI accuracy for use cases\n    ★ Confirm customer satisfaction maintained\n    ★ Demonstrate ticket reduction achievable\n\n  SCOPE:\n    IN: Returns, exchanges, order status on web chat (20% traffic)\n    OUT: Email, phone, other use cases, non-English\n\n  SUCCESS CRITERIA:\n    MUST ACHIEVE:\n    □ Automation rate >30%\n    □ Accuracy >90%\n    □ CSAT no decrease\n    □ Escalation <20%\n\n    SHOULD ACHIEVE:\n    □ Response time <30 sec\n    □ Resolution rate >80%\n\n  TIMELINE:\n    Week 1: Setup and integration\n    Week 2: Soft launch (10% traffic)\n    Week 3-4: Expanded pilot (20% traffic)\n    Post: Decision meeting\n\n  RESOURCES:\n    ShopCo: Sarah (4 hrs/wk), Michael (2 hrs/wk), API access\n    Us: Implementation lead, tech support, training, reporting\n\n  PATH TO FULL DEAL:\n    Success → Full rollout proposal → Contract → May launch\n\n  Files Created:\n    • pilot/pilot-scope.md\n```\n\n## Quality Checklist\n\n- [ ] Objectives clearly defined\n- [ ] Scope boundaries explicit\n- [ ] Success criteria measurable\n- [ ] Timeline with milestones\n- [ ] Resources committed both sides\n- [ ] Risks identified with mitigations\n- [ ] Decision criteria clear\n- [ ] Path to full deal documented",
  "references": [
    {
      "name": "pilot-structure.md",
      "path": "references/pilot-structure.md",
      "content": "# Pilot Structure Reference\n\nStandard framework for pilots/POCs.\n\n## Pilot Types\n\n### Technical Validation Pilot\n\n**Purpose:** Prove technical fit and integration\n\n**Duration:** 2-4 weeks\n**Traffic:** Limited (10-20%)\n**Focus:** Integration, accuracy, performance\n\n**Success = Technical requirements met**\n\n### Business Validation Pilot\n\n**Purpose:** Prove business value and ROI\n\n**Duration:** 4-8 weeks\n**Traffic:** Significant (30-50%)\n**Focus:** Metrics, ROI, user adoption\n\n**Success = Business metrics achieved**\n\n### Full Pilot\n\n**Purpose:** Comprehensive validation\n\n**Duration:** 6-12 weeks\n**Traffic:** Production-like (50%+)\n**Focus:** All aspects\n\n**Success = Ready for full production**\n\n---\n\n## Pilot Phases\n\n### Phase 1: Setup (Week 1)\n\n**Activities:**\n- Integration configuration\n- Data import\n- System training\n- Test environment validation\n- User training\n\n**Deliverables:**\n- Working integration\n- Test cases passing\n- Users trained\n\n**Exit criteria:**\n- Technical setup complete\n- Test environment validated\n- Ready for live traffic\n\n### Phase 2: Soft Launch (Week 2)\n\n**Activities:**\n- Limited traffic (10%)\n- Active monitoring\n- Issue identification\n- Quick fixes\n- Baseline metrics\n\n**Deliverables:**\n- Baseline metrics\n- Issue log\n- Initial learnings\n\n**Exit criteria:**\n- No critical issues\n- Metrics tracking working\n- Ready to expand\n\n### Phase 3: Expanded Pilot (Weeks 3-4)\n\n**Activities:**\n- Increased traffic (20-50%)\n- Ongoing monitoring\n- Weekly reviews\n- Optimization\n- User feedback collection\n\n**Deliverables:**\n- Weekly metrics reports\n- User feedback summary\n- Optimization log\n\n**Exit criteria:**\n- Success criteria trending positive\n- No major issues\n- User acceptance\n\n### Phase 4: Evaluation (Post-Pilot)\n\n**Activities:**\n- Final metrics compilation\n- Success criteria evaluation\n- Go/no-go recommendation\n- Full rollout planning\n\n**Deliverables:**\n- Final metrics report\n- Recommendation document\n- Rollout plan (if successful)\n\n---\n\n## Traffic Ramping\n\n### Conservative Ramp\n\n```\nWeek 1: 0% (Setup)\nWeek 2: 10%\nWeek 3: 20%\nWeek 4: 30%\n```\n\n**Use when:**\n- First pilot with this customer type\n- Complex integration\n- High-risk use case\n\n### Standard Ramp\n\n```\nWeek 1: 10%\nWeek 2: 25%\nWeek 3: 40%\nWeek 4: 50%\n```\n\n**Use when:**\n- Similar to previous successful pilots\n- Straightforward integration\n- Moderate risk\n\n### Aggressive Ramp\n\n```\nWeek 1: 25%\nWeek 2: 50%\nWeek 3: 75%\nWeek 4: 100%\n```\n\n**Use when:**\n- Very confident in fit\n- Customer needs fast results\n- Low-risk use case\n\n---\n\n## Scope Containment\n\n### Hard Boundaries\n\nDefine explicitly:\n- Which use cases\n- Which channels\n- Which users/customers\n- Which geographies\n- Which languages\n\n### Scope Creep Risks\n\n| Risk | Prevention |\n|------|------------|\n| \"While we're at it...\" | Written scope doc |\n| Additional use cases | Phase 2 bucket |\n| More traffic | Pre-agreed ramp |\n| Timeline extension | Hard end date |\n\n### Change Process\n\nIf scope change needed:\n1. Document the request\n2. Assess impact on timeline/success\n3. Get written approval\n4. Update scope document\n5. Communicate to all stakeholders\n\n---\n\n## Pilot Team Structure\n\n### Customer Side\n\n| Role | Responsibility | Time Commitment |\n|------|----------------|-----------------|\n| Executive sponsor | Remove blockers, final decisions | 1-2 hrs/week |\n| Project lead | Day-to-day coordination | 3-5 hrs/week |\n| Technical lead | Integration, troubleshooting | 2-4 hrs/week |\n| Business lead | Use case, user feedback | 2-3 hrs/week |\n| End users | Testing, feedback | As needed |\n\n### Vendor Side\n\n| Role | Responsibility | Time Commitment |\n|------|----------------|-----------------|\n| Account owner | Relationship, escalation | 2-3 hrs/week |\n| Implementation lead | Technical delivery | Dedicated or heavy |\n| Technical support | Troubleshooting | On-call |\n| Product support | Feature questions | As needed |\n\n---\n\n## Communication Cadence\n\n### Daily (During Launch)\n\n- Quick status check (Slack)\n- Issue flag if needed\n\n### Weekly\n\n- Metrics review call (30 min)\n- Progress against success criteria\n- Issues and resolutions\n- Next week priorities\n\n### End of Phase\n\n- Formal review meeting\n- Metrics presentation\n- Go/no-go for next phase\n- Lessons learned\n\n### End of Pilot\n\n- Final presentation\n- Success criteria evaluation\n- Recommendation\n- Next steps discussion\n\n---\n\n## Risk Management\n\n### Risk Categories\n\n| Category | Examples |\n|----------|----------|\n| Technical | Integration fails, performance issues |\n| Business | Metrics not achieved, user adoption |\n| Timeline | Delays, resource availability |\n| Scope | Creep, requirements change |\n\n### Mitigation Strategies\n\n| Risk | Mitigation |\n|------|------------|\n| Integration fails | Test environment first, support ready |\n| Metrics not achieved | Conservative targets, early warning |\n| Delays | Buffer time, clear dependencies |\n| Scope creep | Written scope, change process |\n\n### Escalation Path\n\n```\nIssue detected\n    ↓\nTechnical team attempts fix (4 hours)\n    ↓\nProject leads notified\n    ↓\nAccount owner engaged (24 hours)\n    ↓\nExecutive escalation (48 hours)\n```\n\n---\n\n## Documentation Requirements\n\n### Pre-Pilot\n\n- [ ] Pilot scope document (signed)\n- [ ] Technical requirements\n- [ ] Success criteria\n- [ ] Communication plan\n- [ ] Risk register\n\n### During Pilot\n\n- [ ] Weekly metrics reports\n- [ ] Issue log\n- [ ] Change log\n- [ ] Meeting notes\n\n### Post-Pilot\n\n- [ ] Final metrics report\n- [ ] Success criteria evaluation\n- [ ] Recommendation document\n- [ ] Lessons learned\n- [ ] Rollout plan (if applicable)\n"
    },
    {
      "name": "success-criteria.md",
      "path": "references/success-criteria.md",
      "content": "# Success Criteria Reference\n\nHow to define and measure pilot success.\n\n## Criteria Categories\n\n### Must Achieve (Required)\n\n**Definition:** Pilot fails without these.\n\n**Characteristics:**\n- Non-negotiable\n- Clear pass/fail\n- Measurable\n- 3-5 criteria max\n\n**Examples:**\n- Automation rate >30%\n- Accuracy >90%\n- No critical security issues\n- Customer satisfaction maintained\n\n### Should Achieve (Important)\n\n**Definition:** Strongly desired, some flexibility.\n\n**Characteristics:**\n- Important but not blocking\n- Range acceptable\n- 3-5 criteria\n\n**Examples:**\n- Response time <30 seconds\n- Resolution rate >80%\n- User satisfaction positive\n- No major escalations\n\n### Nice to Have (Bonus)\n\n**Definition:** Would be great, not expected.\n\n**Characteristics:**\n- Bonus if achieved\n- Not factored into success\n- 2-3 criteria\n\n**Examples:**\n- CSAT improvement\n- Cost savings demonstrated\n- Additional use cases validated\n\n---\n\n## Common Metrics\n\n### Volume Metrics\n\n| Metric | Definition | Typical Target |\n|--------|------------|----------------|\n| Automation rate | % handled by AI | 30-50% |\n| Deflection rate | % not reaching human | 25-40% |\n| Escalation rate | % requiring human | <20% |\n\n### Quality Metrics\n\n| Metric | Definition | Typical Target |\n|--------|------------|----------------|\n| Accuracy | % correct responses | >90% |\n| Hallucination rate | % incorrect facts | <2% |\n| Error rate | % system errors | <1% |\n\n### Experience Metrics\n\n| Metric | Definition | Typical Target |\n|--------|------------|----------------|\n| CSAT | Customer satisfaction | No decrease |\n| Response time | Time to first response | <30 seconds |\n| Resolution time | Time to resolve | <5 minutes |\n| NPS | Net Promoter Score | No decrease |\n\n### Operational Metrics\n\n| Metric | Definition | Typical Target |\n|--------|------------|----------------|\n| Uptime | System availability | >99.5% |\n| Latency | Response generation | <2 seconds |\n| Agent satisfaction | Internal feedback | Positive |\n\n---\n\n## Setting Targets\n\n### Start with Baseline\n\nBefore pilot:\n1. Measure current state\n2. Document baseline metrics\n3. Set targets relative to baseline\n\n**Example:**\n```\nCurrent CSAT: 4.2/5\nTarget: ≥4.2/5 (no decrease)\nStretch: ≥4.3/5 (improvement)\n```\n\n### Conservative vs. Aggressive\n\n| Approach | When to Use | Risk |\n|----------|-------------|------|\n| Conservative | First pilot, skeptical customer | May not impress |\n| Standard | Typical scenario | Balanced |\n| Aggressive | Confident, need to impress | May fail |\n\n### Target Setting Framework\n\n```\nConservative = Industry average\nStandard = 10-20% above conservative\nAggressive = 30-50% above conservative\n```\n\n---\n\n## Measurement Methods\n\n### Automated Tracking\n\n**Best for:** Volume, performance, uptime\n\n**Implementation:**\n- Dashboard with real-time metrics\n- Automated daily/weekly reports\n- Alert on threshold breach\n\n### Sampling/Spot-Checks\n\n**Best for:** Quality, accuracy\n\n**Implementation:**\n- Random sample of conversations\n- Human review against rubric\n- Weekly quality report\n\n### Surveys\n\n**Best for:** Satisfaction, experience\n\n**Implementation:**\n- Post-conversation survey\n- Comparison to baseline period\n- Statistical significance check\n\n### Feedback Collection\n\n**Best for:** Qualitative insights\n\n**Implementation:**\n- Agent feedback forms\n- Customer verbatims\n- Stakeholder interviews\n\n---\n\n## Success Evaluation\n\n### Pass Criteria\n\n```\nPASS = All \"Must Achieve\" met\n       + Majority of \"Should Achieve\" met\n       + No critical issues\n```\n\n### Partial Pass\n\n```\nPARTIAL = Most \"Must Achieve\" met\n          + Issues are addressable\n          + Stakeholders see path forward\n```\n\n### Fail Criteria\n\n```\nFAIL = Any \"Must Achieve\" missed significantly\n       OR Critical issues unresolved\n       OR Stakeholder confidence lost\n```\n\n---\n\n## Reporting Template\n\n### Weekly Report\n\n```markdown\n# Pilot Week [X] Report\n\n## Summary\n- Overall status: On Track / At Risk / Off Track\n- Traffic: [X]% of target\n- Key metric: [Primary metric] at [value]\n\n## Metrics\n\n| Metric | Target | Actual | Status |\n|--------|--------|--------|--------|\n| Automation rate | >30% | 35% | ✓ |\n| Accuracy | >90% | 88% | ⚠️ |\n| CSAT | ≥4.2 | 4.3 | ✓ |\n\n## Issues\n- [Issue 1]: [Status]\n- [Issue 2]: [Status]\n\n## Next Week\n- [Priority 1]\n- [Priority 2]\n```\n\n### Final Report\n\n```markdown\n# Pilot Final Report\n\n## Executive Summary\n[1 paragraph: did it work, what did we learn, recommendation]\n\n## Success Criteria Results\n\n### Must Achieve\n| Criterion | Target | Result | Status |\n|-----------|--------|--------|--------|\n| ... | ... | ... | ✓/✗ |\n\n### Should Achieve\n| Criterion | Target | Result | Status |\n|-----------|--------|--------|--------|\n| ... | ... | ... | ✓/✗ |\n\n## Key Learnings\n1. [Learning 1]\n2. [Learning 2]\n3. [Learning 3]\n\n## Recommendation\n[ ] Proceed to full rollout\n[ ] Extend pilot\n[ ] Do not proceed\n\n## Next Steps\n[If proceeding: rollout plan summary]\n[If extending: what needs to change]\n[If not proceeding: why and what would change decision]\n```\n\n---\n\n## Common Pitfalls\n\n### Pitfall: Unclear Criteria\n\n**Problem:** \"Improve customer experience\"\n**Solution:** \"CSAT score ≥4.2/5\"\n\n### Pitfall: Too Many Criteria\n\n**Problem:** 15 success criteria\n**Solution:** 3-5 Must Achieve, prioritize\n\n### Pitfall: No Baseline\n\n**Problem:** \"30% improvement\" from unknown baseline\n**Solution:** Measure baseline before pilot\n\n### Pitfall: Moving Targets\n\n**Problem:** Changing criteria mid-pilot\n**Solution:** Lock criteria before start\n\n### Pitfall: Cherry-Picking\n\n**Problem:** Only reporting good metrics\n**Solution:** Report all pre-agreed metrics\n\n### Pitfall: Small Sample\n\n**Problem:** Drawing conclusions from small sample\n**Solution:** Adequate traffic and duration\n"
    }
  ],
  "tags": [
    "sales",
    "stage-specific",
    "prototype",
    "pilot",
    "scoping",
    "knopilot"
  ],
  "dependsOn": [
    "use-case-clarity",
    "deal-scoring"
  ]
}