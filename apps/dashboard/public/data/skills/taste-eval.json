{
  "id": "taste-eval",
  "name": "taste-eval",
  "version": "1.0.0",
  "description": "Execute taste evaluation against discovered dimensions. Scores each dimension 1-5 with evidence, calculates weighted scores, identifies gaps where score falls below floor, and determines ship status. Produces TASTE-EVAL.md and TASTE-GAPS.md.",
  "phase": "TASTE",
  "category": "engineering",
  "content": "# Taste Eval\n\nExecute taste evaluation and produce dimension scores.\n\n## When to Use\n\n- **After taste-discovery** — Second skill in TASTE phase\n- **Evaluating system quality** — Score each dimension with evidence\n- **Identifying gaps** — Find where quality falls below acceptable floors\n- When you say: \"evaluate the taste\", \"score the dimensions\", \"find quality gaps\"\n\n## Reference Requirements\n\n**MUST read before applying this skill:**\n\n| Reference | Why Required |\n|-----------|--------------|\n| `scoring-rubric.md` | Consistent scoring methodology |\n| `gap-identification.md` | When a score becomes a gap |\n\n**Read if applicable:**\n\n| Reference | When Needed |\n|-----------|-------------|\n| `ship-decision-matrix.md` | Determining ship status from scores |\n\n**Verification:** Ensure all dimensions are scored and gaps are identified.\n\n## Required Deliverables\n\n| Deliverable | Location | Condition |\n|-------------|----------|-----------|\n| `TASTE-EVAL.md` | Project root | Always |\n| `TASTE-GAPS.md` | Project root | Always (even if no gaps) |\n\n## Core Concept\n\nTaste Eval answers: **\"How does this system score on what matters?\"**\n\nEvaluation is:\n- **Evidence-based** — Every score has supporting observations\n- **Dimension-specific** — Uses project's defined quality criteria\n- **Gap-focused** — Identifies where quality falls short\n- **Decision-enabling** — Produces clear ship/polish/fix recommendation\n\n## The Evaluation Process\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                  EVALUATION PROCESS                         │\n│                                                             │\n│  1. LOAD DIMENSIONS                                         │\n│     └─→ From taste-discovery output in audit-state.json    │\n│                                                             │\n│  2. FOR EACH DIMENSION                                      │\n│     ├─→ Gather evidence (code, output samples, behavior)   │\n│     ├─→ Apply scoring rubric                               │\n│     └─→ Assign score 1-5 with evidence                     │\n│                                                             │\n│  3. CALCULATE SCORES                                        │\n│     ├─→ Category scores (weighted average)                 │\n│     └─→ Overall score (category-weighted average)          │\n│                                                             │\n│  4. IDENTIFY GAPS                                           │\n│     └─→ Where score < floor                                │\n│                                                             │\n│  5. DETERMINE SHIP STATUS                                   │\n│     └─→ Apply quality gates to overall score               │\n│                                                             │\n│  6. GENERATE DELIVERABLES                                   │\n│     ├─→ TASTE-EVAL.md (full scores)                        │\n│     └─→ TASTE-GAPS.md (identified gaps)                    │\n└─────────────────────────────────────────────────────────────┘\n```\n\n## Step 1: Load Dimensions\n\nRead dimensions from `audit-state.json`:\n\n```json\n{\n  \"taste\": {\n    \"dimensions\": [\n      {\n        \"name\": \"voice_fidelity\",\n        \"category\": \"content\",\n        \"weight\": 0.40,\n        \"floor\": 2.5\n      }\n    ]\n  }\n}\n```\n\n## Step 2: Score Each Dimension\n\nFor each dimension:\n\n1. **Gather evidence:**\n   - Review code that produces outputs\n   - Examine actual outputs/samples\n   - Test user flows\n   - Check error handling\n\n2. **Apply rubric:**\n   | Score | General Meaning |\n   |-------|-----------------|\n   | 5 | Exceeds expectations, delightful |\n   | 4 | Meets expectations, minor issues |\n   | 3 | Acceptable, has rough edges |\n   | 2 | Below expectations, frustrating |\n   | 1 | Fails to meet basic requirements |\n\n3. **Document evidence:**\n   ```yaml\n   dimension: voice_fidelity\n   score: 3.2\n   evidence:\n     - \"Generated tweets occasionally sound generic\"\n     - \"Personality markers present but inconsistent\"\n     - \"Tone matches target ~70% of time\"\n   ```\n\n## Step 3: Calculate Weighted Scores\n\n**Category score:**\n```\ncategory_score = Σ(dimension_score × dimension_weight)\n```\n\n**Overall score:**\n```\noverall_score = Σ(category_score × category_weight)\n```\n\nExample:\n```\nContent: (voice: 3.2×0.4) + (topic: 4.1×0.35) + (engage: 2.4×0.25) = 3.32\nUX: (responsive: 4.0×0.3) + (feedback: 2.8×0.3) + ... = 3.48\nOverall: (content: 3.32×0.6) + (ux: 3.48×0.4) = 3.38\n```\n\n## Step 4: Identify Gaps\n\nA **gap** exists when `score < floor`:\n\n| Gap Type | Condition | Priority |\n|----------|-----------|----------|\n| Critical | score < floor AND floor >= 3.0 | P1 |\n| Significant | score < floor AND floor < 3.0 | P2 |\n\nGap format:\n```yaml\nid: TG-001\ncategory: content\ndimension: engagement\nscore: 2.4\nfloor: 2.5\nstatus: gap\nevidence:\n  - \"Content lacks hooks\"\n  - \"Repetitive structure\"\ntraced_failure_modes: []  # Populated in REVIEW by taste-trace\n```\n\n## Step 5: Determine Ship Status\n\nApply quality gates:\n\n| Overall Score | Status | Action |\n|---------------|--------|--------|\n| >= ship threshold | SHIP | Ready to launch |\n| >= polish threshold | POLISH_THEN_SHIP | Address gaps, then launch |\n| < fix threshold | FIX_FIRST | Must improve before launch |\n\n**Special rule:** If ANY critical gap exists, status cannot be SHIP.\n\n## Step 6: Generate Deliverables\n\n### TASTE-EVAL.md\n\n```markdown\n# Taste Evaluation\n\n**Project:** [name]\n**Eval Source:** [manifest | convention | defaults]\n**Timestamp:** [ISO 8601]\n\n## Summary\n\n| Metric | Value |\n|--------|-------|\n| Overall Score | 3.38 |\n| Ship Status | POLISH_THEN_SHIP |\n| Gaps Found | 2 |\n| Critical Gaps | 1 |\n\n## Dimension Scores\n\n### Content Quality (weight: 60%)\n\n| Dimension | Weight | Score | Floor | Status |\n|-----------|--------|-------|-------|--------|\n| voice_fidelity | 40% | 3.2 | 2.5 | ✓ |\n| topic_relevance | 35% | 4.1 | 3.0 | ✓ |\n| engagement | 25% | 2.4 | 2.5 | ✗ GAP |\n\n**Category Score:** 3.32\n\n### UX Quality (weight: 40%)\n\n| Dimension | Weight | Score | Floor | Status |\n|-----------|--------|-------|-------|--------|\n| responsiveness | 30% | 4.0 | 3.0 | ✓ |\n| feedback_clarity | 30% | 2.8 | 3.0 | ✗ GAP |\n\n**Category Score:** 3.48\n\n## Evidence\n\n### voice_fidelity: 3.2\n- Generated tweets occasionally sound generic\n- Personality markers present but inconsistent\n\n### engagement: 2.4 (GAP)\n- Content lacks compelling hooks\n- Structure becomes repetitive\n- Missing variety in templates\n```\n\n### TASTE-GAPS.md\n\n```markdown\n# Taste Gaps\n\n**Project:** [name]\n**Gaps Found:** 2\n**Critical:** 1\n\n## TG-001: engagement (CRITICAL)\n\n| Attribute | Value |\n|-----------|-------|\n| Category | content |\n| Score | 2.4 |\n| Floor | 2.5 |\n| Delta | -0.1 |\n| Pipeline | P2 (likely) |\n\n**Evidence:**\n- Content lacks compelling hooks\n- Structure becomes repetitive\n- Missing variety in templates\n\n**Traced Failure Modes:** *(populated by taste-trace)*\n\n---\n\n## TG-002: feedback_clarity (SIGNIFICANT)\n\n| Attribute | Value |\n|-----------|-------|\n| Category | ux |\n| Score | 2.8 |\n| Floor | 3.0 |\n| Delta | -0.2 |\n| Pipeline | U2 (likely) |\n\n**Evidence:**\n- Loading states unclear during generation\n- Change summaries often missing\n```\n\n## Validation\n\nBefore completing, verify:\n\n- [ ] All dimensions have scores (1-5)\n- [ ] All scores have at least one evidence item\n- [ ] Category scores are calculated correctly\n- [ ] Overall score matches weighted calculation\n- [ ] All gaps are identified (score < floor)\n- [ ] Ship status matches quality gates\n- [ ] TASTE-EVAL.md is generated\n- [ ] TASTE-GAPS.md is generated (even if empty)\n\n## Common Issues\n\n| Issue | Resolution |\n|-------|------------|\n| Can't evaluate dimension | Mark as N/A, explain why, exclude from averages |\n| Score is borderline | Round to nearest 0.5, document uncertainty |\n| No evidence available | Cannot score - request access or mark as blocked |\n| Conflicting evidence | Average the implied scores, note the conflict |",
  "references": [
    {
      "name": "gap-identification.md",
      "path": "references/gap-identification.md",
      "content": "# Gap Identification\n\nHow to identify and classify taste gaps.\n\n## What is a Gap?\n\nA **gap** exists when a dimension's score falls below its floor:\n\n```\ngap = score < floor\n```\n\n## Gap Classification\n\n### Critical Gap\n- **Condition:** `score < floor` AND `floor >= 3.0`\n- **Meaning:** Quality is below minimum acceptable for a \"must-have\" dimension\n- **Priority:** P1 - Must address before ship\n- **ID Format:** TG-NNN\n\n### Significant Gap\n- **Condition:** `score < floor` AND `floor < 3.0`\n- **Meaning:** Quality is below minimum for a \"nice-to-have\" dimension\n- **Priority:** P2 - Should address, can ship with plan\n- **ID Format:** TG-NNN\n\n## Gap Severity Matrix\n\n| Score | Floor 2.0 | Floor 2.5 | Floor 3.0 | Floor 3.5 |\n|-------|-----------|-----------|-----------|-----------|\n| 4.0 | OK | OK | OK | OK |\n| 3.5 | OK | OK | OK | GAP (sig) |\n| 3.0 | OK | OK | OK | GAP (crit) |\n| 2.5 | OK | OK | GAP (sig) | GAP (crit) |\n| 2.0 | OK | GAP (sig) | GAP (sig) | GAP (crit) |\n| 1.5 | GAP (sig) | GAP (sig) | GAP (crit) | GAP (crit) |\n\n## Gap Documentation\n\nEach gap must include:\n\n```yaml\nid: TG-001\ncategory: content | ux | brand | custom\ndimension: dimension_name\nscore: 2.4\nfloor: 2.5\ndelta: -0.1\nstatus: critical | significant\npipeline: P1 | P2 | U1 | U2 | null  # Likely associated pipeline\nevidence:\n  - \"Specific observation 1\"\n  - \"Specific observation 2\"\ntraced_failure_modes: []  # Populated later by taste-trace\n```\n\n## Gap-to-Pipeline Mapping\n\nGaps often correlate with specific pipelines:\n\n| Gap Category | Likely Pipeline |\n|--------------|-----------------|\n| content.voice_fidelity | P2 (Content Generation) |\n| content.engagement | P2 (Content Generation) |\n| ux.responsiveness | U1, U2 (UI flows) |\n| ux.feedback_clarity | U1, U2 (UI flows) |\n| ux.error_recovery | P*, U* (varies) |\n\nThis is a heuristic - actual mapping done in taste-trace skill.\n\n## No Gaps Scenario\n\nIf no gaps are found:\n\n```markdown\n# Taste Gaps\n\n**Project:** [name]\n**Gaps Found:** 0\n\nAll dimensions meet or exceed their floor thresholds.\n\nLowest margin: voice_fidelity (3.2, floor 2.5, margin +0.7)\n```\n\n## Gap Aggregation\n\nWhen multiple gaps exist:\n\n1. **Count by severity:**\n   - Critical: N\n   - Significant: M\n\n2. **Count by category:**\n   - Content: N gaps\n   - UX: M gaps\n\n3. **Identify patterns:**\n   - Multiple gaps in same category = systemic issue\n   - Gaps across categories = distributed issues\n"
    },
    {
      "name": "scoring-rubric.md",
      "path": "references/scoring-rubric.md",
      "content": "# Scoring Rubric\n\nConsistent methodology for scoring taste dimensions.\n\n## The 5-Point Scale\n\n| Score | Label | General Definition |\n|-------|-------|---------------------|\n| 5 | Excellent | Exceeds expectations; delightful; would showcase |\n| 4 | Good | Meets expectations; works well; minor polish needed |\n| 3 | Acceptable | Functional; has rough edges; gets the job done |\n| 2 | Poor | Below expectations; frustrating; needs work |\n| 1 | Failed | Does not meet basic requirements; broken |\n\n## Scoring Principles\n\n### 1. Evidence-Based\nEvery score must have observable evidence:\n- Code behavior\n- Output samples\n- User flow observations\n- Error scenarios tested\n\n**Bad:** \"Voice feels off\" (no specifics)\n**Good:** \"Generated tweets use formal language when casual is expected; 'utilize' instead of 'use'\"\n\n### 2. Relative to Floor\nScores are absolute (1-5), but gaps are relative to floor:\n- Score 3.0 with floor 2.5 = Acceptable\n- Score 3.0 with floor 3.5 = Gap\n\n### 3. Half-Point Precision\nUse 0.5 increments for nuance:\n- 4.5 = Between good and excellent\n- 2.5 = Between poor and acceptable\n\n### 4. Dimension-Specific\nApply the dimension's specific rubric if defined, otherwise use general scale.\n\n## Scoring Process\n\n```\n1. Gather evidence (3-5 observations minimum)\n2. Map observations to rubric levels\n3. Determine predominant level\n4. Adjust ±0.5 based on balance of evidence\n5. Document score with key evidence\n```\n\n## Example: Scoring voice_fidelity\n\n**Evidence gathered:**\n- Tweet samples show 70% tone match\n- Formal words appear occasionally\n- Emoji usage matches target persona\n- Hashtag style is inconsistent\n- Opening hooks are strong\n\n**Mapping:**\n- 70% tone match → 3-4 range\n- Occasional formal words → -0.5\n- Emoji match → +0.5\n- Inconsistent hashtags → -0.5\n- Strong hooks → +0.5\n\n**Score:** 3.5 (acceptable-to-good, weighted toward acceptable)\n\n## Handling Edge Cases\n\n### Can't Evaluate\nIf dimension cannot be evaluated:\n```yaml\ndimension: brand_consistency\nscore: null\nstatus: N/A\nreason: \"No brand guidelines available for comparison\"\n```\n\n### Insufficient Evidence\nIf less than 3 observations:\n```yaml\ndimension: accessibility\nscore: 3.0\nconfidence: low\nnote: \"Limited testing; score based on 2 observations\"\n```\n\n### Conflicting Evidence\nIf evidence points different directions:\n```yaml\ndimension: engagement\nscore: 3.0\nnote: \"Mixed evidence: hooks are strong (4) but body is weak (2)\"\n```\n"
    },
    {
      "name": "ship-decision-matrix.md",
      "path": "references/ship-decision-matrix.md",
      "content": "# Ship Decision Matrix\n\nHow overall taste score and technical coverage combine to determine ship readiness.\n\n## Ship Status Values\n\n| Status | Meaning | Action |\n|--------|---------|--------|\n| SHIP | Ready to launch | Proceed to distribution |\n| POLISH_THEN_SHIP | Minor improvements needed | Address gaps, then ship |\n| FIX_FIRST | Significant issues | Must improve before ship consideration |\n| BLOCKED | Cannot ship | Critical issues prevent launch |\n\n## Primary Decision: Taste Score\n\n| Overall Score | Base Status |\n|---------------|-------------|\n| >= 4.0 | SHIP |\n| 3.0 - 4.0 | POLISH_THEN_SHIP |\n| < 3.0 | FIX_FIRST |\n\n## Override Rules\n\n### Critical Gap Override\nIf ANY critical gap exists (score < floor where floor >= 3.0):\n- Status cannot be SHIP\n- Minimum status: POLISH_THEN_SHIP\n\n### Multiple Gap Override\nIf >= 3 gaps exist (any severity):\n- Status downgrades one level\n- SHIP → POLISH_THEN_SHIP\n- POLISH_THEN_SHIP → FIX_FIRST\n\n### Severe Gap Override\nIf ANY dimension scores < 2.0:\n- Status: BLOCKED\n- Message: \"Critical quality failure in [dimension]\"\n\n## Combined Matrix (Taste + Coverage)\n\n| Taste Score | Tech Coverage | Decision |\n|-------------|---------------|----------|\n| >= 4.0 | >= 70% | SHIP |\n| >= 4.0 | < 70% | SHIP (fix coverage post-launch) |\n| 3.0 - 4.0 | >= 70% | POLISH_THEN_SHIP |\n| 3.0 - 4.0 | < 70% | POLISH_THEN_SHIP (fix both) |\n| < 3.0 | Any | FIX_FIRST (taste blocks) |\n\n**Key insight:** Taste < 3.0 always blocks ship, regardless of technical coverage.\n\n## Decision Output Format\n\n```\n═══════════════════════════════════════════════════════════════\n║  SHIP DECISION                                              ║\n║                                                             ║\n║  Taste Score: 3.38                                          ║\n║  Status: POLISH_THEN_SHIP                                   ║\n║                                                             ║\n║  Factors:                                                   ║\n║    ✓ Score above fix threshold (3.0)                        ║\n║    ✗ 1 critical gap (engagement)                            ║\n║    ✗ Score below ship threshold (4.0)                       ║\n║                                                             ║\n║  Recommendation:                                            ║\n║    Address TG-001 (engagement) before launch                ║\n║    Target score: 3.8+ for confident ship                    ║\n═══════════════════════════════════════════════════════════════\n```\n\n## Quality Gate Customization\n\nProjects can customize thresholds in `.claude/taste-manifest.json`:\n\n```json\n{\n  \"quality_gates\": {\n    \"ship\": 4.0,    // Default: 3.5\n    \"polish\": 3.0,  // Default: 2.5\n    \"fix\": 2.5      // Default: 2.5\n  }\n}\n```\n\nHigher thresholds = stricter quality bar.\n"
    }
  ],
  "tags": [
    "audit",
    "taste",
    "quality",
    "evaluation",
    "scoring"
  ],
  "dependsOn": [
    "taste-discovery"
  ]
}