{
  "id": "metadata-extraction",
  "name": "metadata-extraction",
  "version": "2.0.0",
  "description": "Extract, parse, and normalize metadata from diverse content sources including URLs, HTTP headers, HTML meta tags, structured data formats, and document structural elements. Produces standardized metadata records conforming to Dublin Core, OpenGraph, JSON-LD, and schema.org vocabularies. Supports the inbox/second-brain pipeline by ensuring every ingested item has rich, consistent, machine-readable metadata.",
  "phase": "IMPLEMENT",
  "category": "meta",
  "content": "# Metadata Extraction\n\nExtract and normalize metadata from diverse content sources into standardized, machine-readable records.\n\n## When to Use\n\n- **Content enters the inbox pipeline** --- A new URL, document, or media item arrives and needs cataloging before downstream processing\n- **Source identification required** --- You need to determine what a piece of content is, where it came from, and who created it\n- **Structured data harvesting** --- A page or document contains embedded metadata (OpenGraph, JSON-LD, microdata) that should be captured\n- **Cross-platform normalization** --- Content from GitHub, YouTube, documentation sites, blogs, and other platforms needs a uniform metadata format\n- **Cataloging and classification** --- Building a knowledge base or second brain that requires consistent metadata across heterogeneous sources\n- **Attribution and provenance tracking** --- Need to establish authorship, publication dates, licensing, and source chains\n- **Quality assessment of sources** --- Evaluating metadata completeness and reliability before committing to deeper analysis\n- When you say: \"extract metadata\", \"catalog this\", \"what is this source\", \"parse this URL\", \"normalize these records\", \"tag this content\"\n\n## Reference Requirements\n\n**MUST read before applying this skill:**\n\n| Reference | Why Required |\n|-----------|--------------|\n| `metadata-schemas.md` | Canonical field definitions for Dublin Core, OpenGraph, JSON-LD, and schema.org mappings |\n| `platform-extractors.md` | Platform-specific extraction patterns for GitHub, YouTube, docs sites, blogs, and APIs |\n\n**Read if applicable:**\n\n| Reference | When Needed |\n|-----------|-------------|\n| `normalization-rules.md` | When merging metadata from multiple vocabularies or resolving conflicts between embedded schemas |\n| `structured-data-formats.md` | When parsing RDFa, Microdata, JSON-LD, or other embedded structured data from HTML documents |\n\n**Verification:** Ensure every extracted record contains at minimum: title, source_url (or source_path), content_type, date_accessed, and at least one topic tag. Records missing required fields must be flagged as incomplete.\n\n## Required Deliverables\n\n| Deliverable | Location | Condition |\n|-------------|----------|-----------|\n| Metadata record(s) | Inline or appended to source entry | Always --- at least one record per input source |\n| Extraction report | Inline summary | When 3+ sources processed --- completeness statistics and quality flags |\n| Normalization log | Inline notes | When schema conflicts detected --- decisions on field mapping and precedence |\n| Quality assessment | Appended to record | When metadata completeness falls below 70% --- flags and remediation suggestions |\n\n## Core Concept\n\nMetadata Extraction answers: **\"What is this content, where did it come from, and how should it be cataloged?\"**\n\nGood metadata extraction is:\n- **Comprehensive** --- Pulls from every available signal: URL structure, HTTP headers, HTML meta tags, structured data, visible content, and platform conventions\n- **Normalized** --- Maps heterogeneous source metadata into a single consistent schema regardless of origin platform\n- **Standards-aware** --- Leverages Dublin Core, OpenGraph, JSON-LD, and schema.org vocabularies rather than inventing ad-hoc fields\n- **Resilient** --- Degrades gracefully when metadata is sparse, falling back through extraction layers until something useful is found\n- **Honest** --- Reports confidence levels and flags incomplete or ambiguous metadata rather than guessing\n\nMetadata Extraction is NOT:\n- Content analysis or summarization (that is `content-analysis`)\n- Source evaluation or reliability scoring (that is `context-ingestion`)\n- Semantic understanding or theme extraction (that is `context-cultivation`)\n- Full-text indexing or search optimization\n- Data transformation or ETL processing\n\n## The Metadata Extraction Process\n\n```\n+-----------------------------------------------------------------+\n|               METADATA EXTRACTION PROCESS                        |\n|                                                                  |\n|  1. SOURCE IDENTIFICATION                                        |\n|     +---> Parse URL, detect file type, identify platform         |\n|                                                                  |\n|  2. STRUCTURAL METADATA EXTRACTION                               |\n|     +---> Titles, headings, dates, authors, descriptions         |\n|                                                                  |\n|  3. EMBEDDED SCHEMA EXTRACTION                                   |\n|     +---> OpenGraph, JSON-LD, Microdata, Dublin Core, RDFa       |\n|                                                                  |\n|  4. PLATFORM-SPECIFIC EXTRACTION                                 |\n|     +---> GitHub, YouTube, docs sites, blogs, APIs               |\n|                                                                  |\n|  5. SEMANTIC METADATA INFERENCE                                  |\n|     +---> Topics, categories, language, content class            |\n|                                                                  |\n|  6. SCHEMA NORMALIZATION                                         |\n|     +---> Map all fields to canonical schema, resolve conflicts  |\n|                                                                  |\n|  7. QUALITY ASSESSMENT                                           |\n|     +---> Completeness score, reliability flags, gap report      |\n|                                                                  |\n|  8. OUTPUT FORMATTING                                            |\n|     +---> Produce standardized metadata record                   |\n+-----------------------------------------------------------------+\n```\n\n## Step 1: Source Identification\n\nBefore extracting metadata, determine what you are looking at. The source type dictates which extraction strategies apply.\n\n### URL Parsing\n\nDecompose URLs to extract embedded metadata signals:\n\n| URL Component | Metadata Signal | Example |\n|---------------|-----------------|---------|\n| **Protocol** | Security, access type | `https` = secure; `file` = local |\n| **Domain** | Publisher, platform | `github.com` = code repository |\n| **Subdomain** | Content division | `docs.example.com` = documentation |\n| **Path segments** | Content hierarchy, type | `/blog/2025/01/title` = blog post, dated |\n| **Path extensions** | File format | `.pdf`, `.md`, `.html` |\n| **Query parameters** | View state, filters | `?v=xxxxx` = YouTube video ID |\n| **Fragment** | Section reference | `#installation` = specific section |\n\n### URL Pattern Recognition\n\n```markdown\n## Common URL Patterns\n\n### GitHub\n- `github.com/{owner}/{repo}` --> Repository root\n- `github.com/{owner}/{repo}/blob/{branch}/{path}` --> File view\n- `github.com/{owner}/{repo}/issues/{n}` --> Issue\n- `github.com/{owner}/{repo}/pull/{n}` --> Pull request\n- `github.com/{owner}/{repo}/releases/tag/{tag}` --> Release\n\n### YouTube\n- `youtube.com/watch?v={id}` --> Video\n- `youtube.com/playlist?list={id}` --> Playlist\n- `youtube.com/@{handle}` --> Channel\n- `youtu.be/{id}` --> Short video link\n\n### Documentation Sites\n- `docs.{product}.com/{path}` --> Product documentation\n- `{product}.readthedocs.io/{path}` --> ReadTheDocs project\n- `developer.{company}.com/{path}` --> Developer portal\n- `{domain}/api/{version}/{path}` --> API documentation\n\n### Blogs and Articles\n- `{domain}/blog/{year}/{month}/{slug}` --> Dated blog post\n- `{domain}/posts/{slug}` --> Undated post\n- `medium.com/@{author}/{slug}` --> Medium article\n- `dev.to/{author}/{slug}` --> Dev.to article\n```\n\n### Content Type Detection\n\nDetermine content type through multiple signals, in priority order:\n\n| Priority | Signal | Method |\n|----------|--------|--------|\n| 1 | **HTTP Content-Type header** | Direct server declaration; most authoritative |\n| 2 | **File extension** | `.pdf`, `.html`, `.json`, `.md`, `.mp4` |\n| 3 | **URL pattern** | Platform-specific patterns (see above) |\n| 4 | **Content sniffing** | First bytes / magic numbers of file content |\n| 5 | **Heuristic** | Presence of HTML tags, JSON structure, markdown syntax |\n\n### Content Type Taxonomy\n\n```markdown\n## Content Classes\n\n- **document**: PDF, Word, slides, spreadsheets\n- **webpage**: HTML pages, blog posts, articles\n- **code**: Source files, repositories, gists, notebooks\n- **media**: Video, audio, images, podcasts\n- **data**: JSON, CSV, XML, YAML data files\n- **api**: API documentation, endpoint references, schemas\n- **conversation**: Forum threads, Q&A, chat logs, comments\n- **reference**: Wiki pages, encyclopedic entries, glossaries\n```\n\n### Source Identification Checklist\n\n```markdown\n- [ ] URL parsed into components (protocol, domain, path, query, fragment)\n- [ ] Platform identified (GitHub, YouTube, docs site, blog, generic)\n- [ ] Content type determined (document, webpage, code, media, data, api)\n- [ ] File format identified if applicable (PDF, HTML, MD, JSON)\n- [ ] Access method confirmed (public, authenticated, local)\n```\n\n## Step 2: Structural Metadata Extraction\n\nExtract metadata from the visible and structural elements of the content.\n\n### HTML Document Metadata\n\n| Element | Extraction Target | Fallback |\n|---------|-------------------|----------|\n| `<title>` | Page title | First `<h1>`, then `<h2>` |\n| `<meta name=\"description\">` | Page description | First `<p>` of main content |\n| `<meta name=\"author\">` | Author name | Byline element, schema.org author |\n| `<meta name=\"keywords\">` | Topic keywords | None (often absent or unreliable) |\n| `<meta name=\"date\">` / `<time>` | Publication date | URL date pattern, last-modified header |\n| `<link rel=\"canonical\">` | Canonical URL | Current URL |\n| `<html lang=\"...\">` | Content language | Heuristic detection |\n\n### Date Extraction Priority\n\nDates are critical metadata but notoriously inconsistent. Extract in this priority order:\n\n| Priority | Source | Reliability | Format Variants |\n|----------|--------|-------------|-----------------|\n| 1 | `<meta property=\"article:published_time\">` | High | ISO 8601 |\n| 2 | `<time datetime=\"...\">` element | High | ISO 8601 |\n| 3 | JSON-LD `datePublished` | High | ISO 8601 |\n| 4 | HTTP `Last-Modified` header | Medium | RFC 7231 |\n| 5 | URL path date pattern (`/2025/01/15/`) | Medium | Year/month/day |\n| 6 | Visible text pattern (\"Published January 15, 2025\") | Low | Natural language |\n| 7 | Copyright year in footer | Low | Year only |\n\n### Date Normalization\n\nAll extracted dates must be normalized to ISO 8601 format:\n\n```\nFull:      2025-01-15T14:30:00Z\nDate only: 2025-01-15\nYear-month: 2025-01\nYear only:  2025\nUnknown:   null (with flag: \"date_unknown\": true)\n```\n\n### Author Extraction\n\n| Source | Pattern | Confidence |\n|--------|---------|------------|\n| `<meta name=\"author\">` | Direct declaration | High |\n| Schema.org `author` property | Structured data | High |\n| Byline element (`class=\"author\"`, `class=\"byline\"`) | Convention-based | Medium |\n| GitHub commit / profile | Platform API | High |\n| YouTube channel name | Platform convention | High |\n| Text pattern (\"By John Smith\") | Regex heuristic | Low |\n\n### Structural Elements Checklist\n\n```markdown\n- [ ] Title extracted (with source noted: <title>, <h1>, og:title, etc.)\n- [ ] Description extracted or generated from first paragraph\n- [ ] Author identified (or marked \"Unknown\" with confidence: low)\n- [ ] Publication date extracted and normalized to ISO 8601\n- [ ] Language identified (ISO 639-1 code)\n- [ ] Canonical URL determined\n- [ ] Word count or content length estimated\n```\n\n## Step 3: Embedded Schema Extraction\n\nModern web pages embed structured metadata in multiple overlapping formats. Extract from all available schemas, then normalize in Step 6.\n\n### OpenGraph Protocol (og:)\n\nOpenGraph tags are the most widely deployed structured metadata on the web. Extract from `<meta property=\"og:...\">` tags.\n\n| Property | Maps To | Notes |\n|----------|---------|-------|\n| `og:title` | title | Often more descriptive than `<title>` |\n| `og:description` | description | Social-sharing optimized description |\n| `og:type` | content_type | `article`, `video.other`, `website`, `profile` |\n| `og:url` | canonical_url | Authoritative URL for the content |\n| `og:image` | thumbnail_url | Preview image URL |\n| `og:site_name` | publisher | Site or brand name |\n| `og:locale` | language | Format: `en_US` |\n| `article:published_time` | date_published | ISO 8601 datetime |\n| `article:modified_time` | date_modified | ISO 8601 datetime |\n| `article:author` | author_url | URL to author profile |\n| `article:section` | category | Content section/category |\n| `article:tag` | topics[] | Content tags (may repeat) |\n\n### JSON-LD (Linked Data)\n\nJSON-LD is the most machine-readable format, embedded in `<script type=\"application/ld+json\">`. Extract and parse the JSON structure.\n\n```json\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"Article\",\n  \"headline\": \"Example Article Title\",\n  \"author\": {\n    \"@type\": \"Person\",\n    \"name\": \"Jane Smith\",\n    \"url\": \"https://example.com/authors/jane\"\n  },\n  \"datePublished\": \"2025-01-15T10:00:00Z\",\n  \"dateModified\": \"2025-01-20T14:30:00Z\",\n  \"publisher\": {\n    \"@type\": \"Organization\",\n    \"name\": \"Example Publisher\",\n    \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://example.com/logo.png\" }\n  },\n  \"description\": \"A description of the article content.\",\n  \"image\": \"https://example.com/article-image.jpg\",\n  \"mainEntityOfPage\": \"https://example.com/article-url\"\n}\n```\n\n### Key schema.org Types\n\n| @type | Expected Properties | Content Class |\n|-------|-------------------|---------------|\n| `Article` / `NewsArticle` / `BlogPosting` | headline, author, datePublished, publisher | webpage |\n| `WebPage` / `WebSite` | name, url, description | webpage |\n| `SoftwareSourceCode` / `SoftwareApplication` | name, author, programmingLanguage, codeRepository | code |\n| `VideoObject` | name, description, duration, uploadDate, thumbnailUrl | media |\n| `HowTo` / `TechArticle` | name, step[], proficiencyLevel | reference |\n| `Person` / `Organization` | name, url, sameAs[] | entity |\n| `Dataset` | name, description, distribution, license | data |\n| `APIReference` | name, description, programmingModel | api |\n\n### Dublin Core Metadata\n\nDublin Core elements appear as `<meta name=\"DC....\" content=\"...\">` or `<meta name=\"dcterms....\">`. This is common in academic, government, and library contexts.\n\n| DC Element | Maps To | Notes |\n|------------|---------|-------|\n| `DC.title` | title | Formal title |\n| `DC.creator` | author | Creator/author name |\n| `DC.subject` | topics[] | Subject keywords |\n| `DC.description` | description | Content description |\n| `DC.publisher` | publisher | Publishing entity |\n| `DC.date` | date_published | Publication date |\n| `DC.type` | content_type | DCMI Type Vocabulary |\n| `DC.format` | format | MIME type |\n| `DC.identifier` | identifier | DOI, ISBN, URI |\n| `DC.language` | language | ISO 639 code |\n| `DC.rights` | license | Rights statement |\n| `DC.source` | source_url | Derived-from source |\n| `DC.relation` | related[] | Related resources |\n| `DC.coverage` | coverage | Spatial/temporal scope |\n\n### Microdata and RDFa\n\nThese formats embed metadata directly in HTML attributes:\n\n```html\n<!-- Microdata -->\n<div itemscope itemtype=\"https://schema.org/Article\">\n  <h1 itemprop=\"headline\">Article Title</h1>\n  <span itemprop=\"author\">Jane Smith</span>\n  <time itemprop=\"datePublished\" datetime=\"2025-01-15\">Jan 15, 2025</time>\n</div>\n\n<!-- RDFa -->\n<div vocab=\"https://schema.org/\" typeof=\"Article\">\n  <h1 property=\"headline\">Article Title</h1>\n  <span property=\"author\">Jane Smith</span>\n  <time property=\"datePublished\" datetime=\"2025-01-15\">Jan 15, 2025</time>\n</div>\n```\n\n### Schema Extraction Checklist\n\n```markdown\n- [ ] OpenGraph tags extracted (og:title, og:description, og:type, og:url, og:image)\n- [ ] JSON-LD blocks parsed (all <script type=\"application/ld+json\"> elements)\n- [ ] Dublin Core elements checked (DC.* and dcterms.* meta tags)\n- [ ] Microdata scanned (itemscope/itemprop attributes)\n- [ ] RDFa scanned (vocab/typeof/property attributes)\n- [ ] Twitter Card tags checked (twitter:title, twitter:description, twitter:image)\n- [ ] Schema conflicts noted (e.g., og:title differs from JSON-LD headline)\n```\n\n## Step 4: Platform-Specific Extraction\n\nDifferent platforms expose metadata through platform-specific conventions, APIs, and page structures. Apply targeted extractors based on the platform identified in Step 1.\n\n### GitHub\n\n| Metadata Field | Extraction Source |\n|----------------|-------------------|\n| Repository name | URL path: `/{owner}/{repo}` |\n| Owner / organization | URL path: `/{owner}/` |\n| Description | `<meta property=\"og:description\">` or repo about section |\n| Primary language | Language bar / `linguist` data |\n| Topics | Repository topics (tags below description) |\n| Stars / forks | Social proof metrics |\n| License | `LICENSE` file or API `license` field |\n| Last updated | Most recent commit date or push date |\n| README content | `README.md` at repository root |\n| Contributors | Contributor count from page or API |\n| Open issues | Issue count for activity assessment |\n\n### YouTube\n\n| Metadata Field | Extraction Source |\n|----------------|-------------------|\n| Video title | `og:title` or JSON-LD `name` |\n| Channel name | `og:site_name` or channel link text |\n| Upload date | JSON-LD `uploadDate` or `datePublished` |\n| Duration | JSON-LD `duration` (ISO 8601 duration) |\n| Description | `og:description` (often truncated) or JSON-LD |\n| View count | JSON-LD `interactionCount` |\n| Thumbnail | `og:image` or JSON-LD `thumbnailUrl` |\n| Tags | `<meta name=\"keywords\">` (comma-separated) |\n| Category | JSON-LD `genre` or visible category link |\n| Captions available | Accessibility metadata or API |\n\n### Documentation Sites\n\n| Metadata Field | Extraction Source |\n|----------------|-------------------|\n| Product / project name | Site header, `og:site_name`, breadcrumb root |\n| Doc version | URL segment (`/v2/`, `/latest/`), version selector |\n| Section / category | Breadcrumb trail, sidebar navigation context |\n| Page title | `<h1>` or `og:title` (strip product prefix) |\n| Last updated | Footer date, git blame date, meta tag |\n| Navigation context | Previous/next links, breadcrumb hierarchy |\n| API version | Path segment or header declaration |\n\n### Blog / Article Platforms\n\n| Platform | Author Source | Date Source | Tags Source |\n|----------|-------------|-------------|------------|\n| **Medium** | Author card, `@{handle}` in URL | `<time>` element | Bottom-of-article tags |\n| **Dev.to** | URL `/{author}/`, profile card | `<time>` element | Visible tag list |\n| **WordPress** | `<meta name=\"author\">`, byline | `<time class=\"entry-date\">` | `<a rel=\"tag\">` elements |\n| **Ghost** | JSON-LD author, byline | JSON-LD datePublished | JSON-LD keywords |\n| **Substack** | Publication name + author | `<time>` or JSON-LD | Categories if present |\n| **Hugo / Jekyll** | YAML frontmatter `author` | Frontmatter `date` | Frontmatter `tags` |\n\n### Platform Extraction Checklist\n\n```markdown\n- [ ] Platform identified from URL pattern\n- [ ] Platform-specific extractor applied\n- [ ] Platform-unique fields captured (stars, views, duration, etc.)\n- [ ] Author profile URL captured (not just name)\n- [ ] Platform-specific content type mapped to canonical type\n```\n\n## Step 5: Semantic Metadata Inference\n\nWhen explicit metadata is absent or sparse, infer semantic properties from content analysis. These inferred fields carry lower confidence than extracted fields.\n\n### Topic Inference\n\nDerive topics from available signals, in priority order:\n\n| Priority | Signal | Method | Confidence |\n|----------|--------|--------|------------|\n| 1 | Explicit tags / keywords | Direct extraction | High |\n| 2 | Article section / category | Platform categorization | High |\n| 3 | Title keywords | Key noun phrases from title | Medium |\n| 4 | Heading structure | H2/H3 topics across the document | Medium |\n| 5 | URL path segments | Meaningful path words | Low |\n| 6 | Content body analysis | Frequent terms and phrases | Low |\n\n### Content Classification\n\nAssign a primary content class based on structural signals:\n\n| Content Class | Signals |\n|---------------|---------|\n| **tutorial** | Step-numbered headings, \"how to\" in title, code blocks interspersed with prose |\n| **reference** | Table-heavy, alphabetical ordering, definition lists, API signatures |\n| **conceptual** | Explanatory prose, minimal code, \"what is\" / \"understanding\" in title |\n| **news** | Dateline, recent date, event-driven topic, publication attribution |\n| **opinion** | First-person voice, evaluative language, \"I think\" / \"my experience\" |\n| **announcement** | \"Introducing\", \"announcing\", \"releasing\", version numbers, changelog format |\n| **discussion** | Multiple voices, thread structure, Q&A format |\n| **specification** | Formal language, MUST/SHALL/MAY keywords (RFC 2119), numbered requirements |\n\n### Language Detection\n\n| Method | Reliability | Application |\n|--------|-------------|-------------|\n| `<html lang=\"...\">` attribute | High | Declared by page author |\n| `Content-Language` HTTP header | High | Server-declared |\n| `og:locale` property | High | OpenGraph declaration |\n| Heuristic character analysis | Medium | Script detection (Latin, CJK, Arabic, Cyrillic) |\n| n-gram frequency analysis | Medium | Statistical language identification |\n\n### Semantic Inference Checklist\n\n```markdown\n- [ ] Topics assigned (with source: explicit, inferred, or both)\n- [ ] Content class determined (tutorial, reference, conceptual, etc.)\n- [ ] Language identified (ISO 639-1 code)\n- [ ] Reading level estimated if applicable (technical depth)\n- [ ] Inferred fields marked with confidence: medium or confidence: low\n```\n\n## Step 6: Schema Normalization\n\nMap all extracted metadata --- from structural elements, embedded schemas, platform-specific fields, and inferred properties --- into a single canonical record.\n\n### Canonical Metadata Schema\n\n```yaml\n# Required fields\ntitle: \"string\"              # Content title\nsource_url: \"string\"         # URL or file path of the source\ncontent_type: \"string\"       # Canonical type: webpage, document, code, media, data, api, conversation, reference\ndate_accessed: \"ISO 8601\"    # When this metadata was extracted\ntopics: [\"string\"]           # At least one topic tag\n\n# Strongly recommended fields\ndescription: \"string\"        # Content summary (1-3 sentences)\nauthor: \"string\"             # Primary author name\nauthor_url: \"string\"         # URL to author profile\ndate_published: \"ISO 8601\"   # Publication or creation date\ndate_modified: \"ISO 8601\"    # Last modification date\nlanguage: \"string\"           # ISO 639-1 language code\npublisher: \"string\"          # Publishing platform or organization\ncanonical_url: \"string\"      # Authoritative URL (may differ from source_url)\n\n# Optional enrichment fields\nlicense: \"string\"            # License identifier (SPDX or description)\nthumbnail_url: \"string\"      # Preview image URL\nword_count: \"number\"         # Approximate content length\nreading_time_minutes: \"number\"  # Estimated reading time\ncontent_class: \"string\"      # tutorial, reference, conceptual, news, opinion, etc.\nplatform: \"string\"           # github, youtube, medium, docs, blog, etc.\nformat: \"string\"             # MIME type or file format\nidentifier: \"string\"         # DOI, ISBN, or other formal identifier\nrelated: [\"string\"]          # URLs of related content\ntags_explicit: [\"string\"]    # Tags declared by the source\ntags_inferred: [\"string\"]    # Tags inferred during extraction\n\n# Quality fields\nmetadata_completeness: \"number\"  # 0.0-1.0 score\nextraction_confidence: \"string\"  # high, medium, low\nextraction_notes: [\"string\"]     # Flags, warnings, or decisions made during extraction\n```\n\n### Field Precedence Rules\n\nWhen multiple sources provide the same field, apply this precedence:\n\n| Field | First Choice | Second Choice | Third Choice | Last Resort |\n|-------|-------------|---------------|--------------|-------------|\n| **title** | JSON-LD `headline` | `og:title` | `<title>` | First `<h1>` |\n| **description** | JSON-LD `description` | `og:description` | `<meta name=\"description\">` | First paragraph |\n| **author** | JSON-LD `author.name` | `<meta name=\"author\">` | Byline element | Platform profile |\n| **date_published** | JSON-LD `datePublished` | `article:published_time` | `<time datetime>` | URL date pattern |\n| **topics** | Explicit tags + `article:tag` | DC.subject | `<meta name=\"keywords\">` | Inferred from title |\n| **content_type** | JSON-LD `@type` mapped | `og:type` mapped | Platform convention | Heuristic |\n\n### Conflict Resolution\n\nWhen extracted values conflict across schemas:\n\n| Conflict Type | Resolution Strategy |\n|---------------|---------------------|\n| **Minor wording difference** | Prefer the more specific or complete version |\n| **Substantive disagreement** | Prefer JSON-LD > OpenGraph > meta tags > inferred |\n| **Date discrepancy** | Prefer the earliest plausible date as published; note discrepancy |\n| **Author mismatch** | Prefer structured data (JSON-LD) over unstructured (byline text) |\n| **Multiple types** | Use most specific type; note alternative classification |\n\n### Normalization Checklist\n\n```markdown\n- [ ] All extracted fields mapped to canonical schema\n- [ ] Field precedence applied where conflicts exist\n- [ ] Dates normalized to ISO 8601\n- [ ] Language normalized to ISO 639-1\n- [ ] Content type mapped to canonical taxonomy\n- [ ] Conflict resolution decisions documented in extraction_notes\n- [ ] Required fields present (title, source_url, content_type, date_accessed, topics)\n```\n\n## Step 7: Quality Assessment\n\nAssess the completeness and reliability of the extracted metadata record before finalizing.\n\n### Completeness Scoring\n\nCalculate metadata completeness as a ratio of populated fields to total applicable fields:\n\n```\nCompleteness = (populated required fields / 5) * 0.5\n             + (populated recommended fields / 7) * 0.3\n             + (populated optional fields / total optional) * 0.2\n\nScore ranges:\n  0.90 - 1.00  =  EXCELLENT  -->  Rich metadata, high confidence\n  0.70 - 0.89  =  GOOD       -->  Sufficient for cataloging and discovery\n  0.50 - 0.69  =  FAIR       -->  Usable but with notable gaps\n  0.30 - 0.49  =  POOR       -->  Significant gaps, flag for manual review\n  0.00 - 0.29  =  MINIMAL    -->  Only basic identification possible\n```\n\n### Reliability Indicators\n\n| Indicator | Positive Signal | Negative Signal |\n|-----------|----------------|-----------------|\n| **Source authority** | Known publisher, verified author | Anonymous, unverifiable source |\n| **Schema richness** | JSON-LD + OpenGraph + meta tags | No structured data at all |\n| **Date availability** | Published date with timezone | No dates anywhere |\n| **Cross-schema consistency** | All schemas agree on key fields | Contradictions between schemas |\n| **Platform recognition** | Known platform with established patterns | Unknown site with no conventions |\n| **Content structure** | Clear headings, semantic HTML | Flat text, no structure |\n\n### Quality Flags\n\nFlag any of the following conditions in `extraction_notes`:\n\n```markdown\n## Quality Flags\n\n- MISSING_DATE: No publication date found from any source\n- MISSING_AUTHOR: No author identified; attribution not possible\n- INFERRED_ONLY: Key fields populated only through inference (no explicit metadata)\n- SCHEMA_CONFLICT: Conflicting values found across metadata schemas\n- STALE_CONTENT: Content appears outdated (date > 2 years old)\n- TRUNCATED_DESCRIPTION: Description was cut off or incomplete\n- NO_STRUCTURED_DATA: No JSON-LD, OpenGraph, or Dublin Core found\n- REDIRECT_DETECTED: Source URL redirected; canonical may differ\n- PAYWALL_SUSPECTED: Full content may not be accessible\n- GENERATED_CONTENT: Content appears AI-generated (metadata pattern)\n```\n\n### Quality Assessment Checklist\n\n```markdown\n- [ ] Completeness score calculated\n- [ ] Reliability indicators assessed\n- [ ] Quality flags applied where applicable\n- [ ] Missing required fields explicitly noted\n- [ ] Confidence level assigned (high / medium / low)\n- [ ] Remediation suggestions provided for POOR or MINIMAL scores\n```\n\n## Step 8: Output Formatting\n\nProduce the final metadata record in the standardized format.\n\n### Record Assembly\n\nCombine all extraction, normalization, and quality assessment into the final output. Include provenance information showing which extraction step produced each field.\n\n### Final Record Validation\n\nBefore outputting, verify:\n\n```markdown\n- [ ] All required fields present and non-empty\n- [ ] All dates in ISO 8601 format\n- [ ] All URLs are absolute (not relative)\n- [ ] Topics array has at least one entry\n- [ ] content_type is from canonical taxonomy\n- [ ] metadata_completeness score is calculated\n- [ ] extraction_confidence is set\n- [ ] extraction_notes captures any flags or decisions\n```\n\n## Output Formats\n\n### Quick Format (single source, inline use)\n\n```markdown\n**Metadata: [Title]**\n- **Source:** [URL or path]\n- **Type:** [content_type] | **Platform:** [platform]\n- **Author:** [author] | **Published:** [date_published]\n- **Language:** [language] | **License:** [license]\n- **Topics:** [topic1, topic2, topic3]\n- **Description:** [description]\n- **Completeness:** [score] ([EXCELLENT/GOOD/FAIR/POOR/MINIMAL])\n- **Flags:** [any quality flags]\n```\n\n### Full Format (detailed record, cataloging use)\n\n```yaml\n---\n# Metadata Record\ntitle: \"[Title]\"\nsource_url: \"[URL]\"\ncanonical_url: \"[Canonical URL]\"\ncontent_type: \"[type]\"\ncontent_class: \"[class]\"\nplatform: \"[platform]\"\nformat: \"[MIME type or format]\"\n\n# Attribution\nauthor: \"[Author Name]\"\nauthor_url: \"[Author Profile URL]\"\npublisher: \"[Publisher Name]\"\n\n# Temporal\ndate_published: \"[ISO 8601]\"\ndate_modified: \"[ISO 8601]\"\ndate_accessed: \"[ISO 8601]\"\n\n# Classification\nlanguage: \"[ISO 639-1]\"\ntopics:\n  - \"[topic1]\"\n  - \"[topic2]\"\ntags_explicit:\n  - \"[tag1]\"\ntags_inferred:\n  - \"[tag2]\"\n\n# Enrichment\ndescription: \"[1-3 sentence description]\"\nthumbnail_url: \"[URL]\"\nword_count: [number]\nreading_time_minutes: [number]\nlicense: \"[SPDX or description]\"\nidentifier: \"[DOI, ISBN, etc.]\"\nrelated:\n  - \"[URL]\"\n\n# Quality\nmetadata_completeness: [0.0-1.0]\nextraction_confidence: \"[high/medium/low]\"\nextraction_notes:\n  - \"[Note or flag]\"\n\n# Provenance\nextracted_by: \"metadata-extraction v2.0.0\"\nextraction_date: \"[ISO 8601]\"\nschemas_found: [\"json-ld\", \"opengraph\", \"dublin-core\"]\n---\n```\n\n## Common Patterns\n\n### Web Page Extraction\n\nProcess a standard web page (blog post, article, documentation page) through the full pipeline. Start with URL parsing to identify the platform, then extract HTML structural metadata, harvest all embedded schemas (OpenGraph, JSON-LD, Dublin Core), apply platform-specific extractors, infer any missing semantic fields, normalize, and assess quality.\n\n**Use when:** The source is an HTML page accessible via URL. This is the most common extraction scenario and exercises all pipeline steps.\n\n### API Documentation Extraction\n\nExtract metadata from API reference pages, focusing on technical specificity. Capture the API product name, version, endpoint paths, authentication requirements, and rate limits. Map to schema.org `APIReference` or `TechArticle` types. Pay special attention to version information embedded in URLs (`/v2/`, `/latest/`) and documentation framework metadata (Swagger/OpenAPI, Redoc, Slate).\n\n**Use when:** The source is API documentation, SDK reference, or developer portal content. These sources have distinctive structural patterns and specialized metadata needs.\n\n### Video and Media Extraction\n\nExtract metadata from video platforms (YouTube, Vimeo) and podcast hosts. Focus on duration, upload date, creator/channel, view metrics, and associated text content (descriptions, transcripts, show notes). JSON-LD on video platforms is typically rich; prefer it over OpenGraph for structured fields like duration.\n\n**Use when:** The source is a video, podcast episode, or other media content. These sources carry temporal metadata (duration) and engagement metrics not found in text content.\n\n### Code Repository Extraction\n\nExtract metadata from code hosting platforms (GitHub, GitLab, Bitbucket). Capture repository name, owner, description, primary language, topics/tags, license, star/fork counts, contributor count, and last activity date. README content provides the richest description source. API endpoints (when accessible) provide the most structured data.\n\n**Use when:** The source is a code repository, gist, or code-sharing platform. These sources have a unique metadata vocabulary (stars, forks, languages) that must be mapped to canonical fields.\n\n## Relationship to Other Skills\n\n| Skill | Relationship |\n|-------|--------------|\n| `context-ingestion` | Ingestion invokes metadata-extraction as a sub-process during source registration; extracted metadata populates the CONTEXT-SOURCES.md entries |\n| `content-analysis` | Content analysis operates on the content body; metadata-extraction provides the structural envelope (title, author, date, type) that frames the analysis |\n| `context-cultivation` | Cultivation uses metadata fields (topics, dates, authors) to group and cross-reference sources during thematic coding |\n| `priority-matrix` | Source metadata (recency, authority, content type) informs priority weighting and relevance scoring |\n| `proposal-builder` | Extracted metadata provides attribution data for source citations in proposals |\n\n## Key Principles\n\n**Extract before you infer.** Always attempt to find explicitly declared metadata before falling back to inference. Declared metadata from the content author is more reliable than algorithmically derived values. Only infer when explicit sources are exhausted.\n\n**Standards over invention.** Use Dublin Core, OpenGraph, JSON-LD, and schema.org vocabularies. These standards exist because metadata interoperability is a solved problem at the vocabulary level. Custom fields should be exceptional, not default.\n\n**Degrade gracefully.** Not every source has rich metadata. A PDF with no embedded metadata still has a filename, a file size, and a creation date. The extraction pipeline must produce a usable record from even the sparsest inputs, clearly marking what was found versus inferred.\n\n**Provenance is non-negotiable.** Every field in the output record should be traceable to a specific extraction step and source. When downstream consumers question a metadata value, the extraction notes must answer \"where did this come from?\"\n\n**Completeness is measurable.** Do not hand-wave about metadata quality. Calculate a completeness score. Flag gaps explicitly. A record that honestly reports 40% completeness is more useful than one that silently omits the assessment.\n\n**Normalize relentlessly.** The entire value of metadata extraction collapses if dates are in five formats, content types use three taxonomies, and languages are sometimes codes and sometimes names. Every field must conform to its canonical format, every time, without exception.\n\n## References\n\n- `references/metadata-schemas.md`: Canonical field definitions, Dublin Core element set, OpenGraph property catalog, schema.org type mappings, and cross-schema equivalence tables\n- `references/platform-extractors.md`: Platform-specific extraction patterns for GitHub, YouTube, Medium, Dev.to, WordPress, ReadTheDocs, and common documentation frameworks\n- `references/normalization-rules.md`: Date format normalization, language code mapping, content type taxonomy, and conflict resolution procedures\n- `references/structured-data-formats.md`: Parsing guides for JSON-LD, RDFa, Microdata, and embedded metadata in PDF, DOCX, and image EXIF headers",
  "references": [
    {
      "name": "metadata-schemas.md",
      "path": "references/metadata-schemas.md",
      "content": "# Metadata Schemas Reference\n\nCanonical field definitions and cross-schema mappings for the orchestrator's metadata extraction pipeline.\n\n## Orchestrator Internal Schema\n\nThe orchestrator normalizes all extracted metadata into this canonical form:\n\n| Field            | Type       | Required | Description                              |\n|------------------|------------|----------|------------------------------------------|\n| `title`          | string     | yes      | Primary title of the resource            |\n| `description`    | string     | no       | Summary or abstract (max 500 chars)      |\n| `author`         | string[]   | no       | Ordered list of creator names            |\n| `datePublished`  | string     | no       | ISO 8601 publication date                |\n| `dateModified`   | string     | no       | ISO 8601 last-modified date              |\n| `language`       | string     | no       | ISO 639-1 language code                  |\n| `contentType`    | string     | yes      | Orchestrator taxonomy type               |\n| `sourceUrl`      | string     | yes      | Canonical URL of the resource            |\n| `tags`           | string[]   | no       | Subject keywords, lowercased             |\n| `license`        | string     | no       | SPDX identifier or free-text license     |\n| `thumbnailUrl`   | string     | no       | Representative image URL                 |\n| `publisher`      | string     | no       | Organization or platform name            |\n\n## Dublin Core Element Set (DC-15)\n\nThe 15 core Dublin Core elements and their orchestrator mappings:\n\n| DC Element      | Definition                                    | Maps To             |\n|-----------------|-----------------------------------------------|---------------------|\n| `dc:title`      | Name given to the resource                    | `title`             |\n| `dc:creator`    | Entity primarily responsible for content      | `author`            |\n| `dc:subject`    | Topic of the resource                         | `tags`              |\n| `dc:description`| Account of the resource                       | `description`       |\n| `dc:publisher`  | Entity responsible for making available       | `publisher`         |\n| `dc:contributor`| Entity contributing to the resource           | (stored in extras)  |\n| `dc:date`       | Date associated with lifecycle event          | `datePublished`     |\n| `dc:type`       | Nature or genre of the resource               | `contentType`       |\n| `dc:format`     | File format or medium                         | (MIME in extras)    |\n| `dc:identifier` | Unambiguous reference (DOI, ISBN, URL)        | `sourceUrl`         |\n| `dc:source`     | Derived-from resource                         | (stored in extras)  |\n| `dc:language`   | Language of the resource                      | `language`          |\n| `dc:relation`   | Related resource reference                    | (stored in extras)  |\n| `dc:coverage`   | Spatial or temporal scope                     | (stored in extras)  |\n| `dc:rights`     | Rights held in/over the resource              | `license`           |\n\n## OpenGraph Property Catalog\n\nProperties extracted from `<meta property=\"og:...\" />` tags:\n\n| OG Property       | Maps To         | Notes                                   |\n|--------------------|-----------------|----------------------------------------|\n| `og:title`         | `title`         | Preferred over `<title>` when present  |\n| `og:description`   | `description`   | Preferred over meta description        |\n| `og:url`           | `sourceUrl`     | Canonical URL                          |\n| `og:image`         | `thumbnailUrl`  | First image only                       |\n| `og:type`          | `contentType`   | Requires type mapping (see below)      |\n| `og:locale`        | `language`      | Convert `en_US` to `en`               |\n| `og:site_name`     | `publisher`     | Platform or site name                  |\n| `og:updated_time`  | `dateModified`  | ISO 8601 expected                      |\n| `article:author`          | `author`    | URL or name string               |\n| `article:published_time`  | `datePublished` | ISO 8601                     |\n| `article:tag`             | `tags`      | One tag per meta element               |\n\n### OG Type to Content Type Mapping\n\n| `og:type`         | Orchestrator `contentType` |\n|--------------------|---------------------------|\n| `article`          | `article`                 |\n| `website`          | `webpage`                 |\n| `video.other`      | `video`                   |\n| `music.song`       | `audio`                   |\n| `profile`          | `profile`                 |\n| `book`             | `document`                |\n\n## Schema.org Type Mappings\n\nExtracted from JSON-LD or microdata `@type` values:\n\n| Schema.org Type    | Orchestrator `contentType` | Key Properties Extracted           |\n|--------------------|----------------------------|------------------------------------|\n| `Article`          | `article`                  | headline, author, datePublished    |\n| `BlogPosting`      | `article`                  | headline, author, datePublished    |\n| `WebPage`          | `webpage`                  | name, description, url             |\n| `VideoObject`      | `video`                    | name, description, thumbnailUrl    |\n| `AudioObject`      | `audio`                    | name, duration, encodingFormat     |\n| `SoftwareSourceCode` | `repository`             | name, programmingLanguage          |\n| `SoftwareApplication` | `software`              | name, operatingSystem, offers      |\n| `HowTo`           | `tutorial`                  | name, step, totalTime              |\n| `QAPage`          | `discussion`                | name, mainEntity                   |\n| `Dataset`         | `dataset`                   | name, distribution, license        |\n| `ScholarlyArticle`| `paper`                     | headline, author, citation         |\n| `TechArticle`     | `article`                   | headline, proficiencyLevel         |\n| `APIReference`    | `api-doc`                   | name, description                  |\n\n## Cross-Schema Equivalence Table\n\nQuick lookup for the same concept across schemas:\n\n| Concept      | Orchestrator   | Dublin Core      | OpenGraph            | Schema.org         |\n|-------------|----------------|------------------|----------------------|--------------------|\n| Title       | `title`        | `dc:title`       | `og:title`           | `name`/`headline`  |\n| Summary     | `description`  | `dc:description` | `og:description`     | `description`      |\n| Creator     | `author`       | `dc:creator`     | `article:author`     | `author`           |\n| Published   | `datePublished`| `dc:date`        | `article:published_time` | `datePublished`|\n| Modified    | `dateModified` | --               | `og:updated_time`    | `dateModified`     |\n| Language    | `language`     | `dc:language`    | `og:locale`          | `inLanguage`       |\n| Category    | `contentType`  | `dc:type`        | `og:type`            | `@type`            |\n| Link        | `sourceUrl`    | `dc:identifier`  | `og:url`             | `url`              |\n| Image       | `thumbnailUrl` | --               | `og:image`           | `thumbnailUrl`     |\n| Rights      | `license`      | `dc:rights`      | --                   | `license`          |\n| Keywords    | `tags`         | `dc:subject`     | `article:tag`        | `keywords`         |\n| Publisher   | `publisher`    | `dc:publisher`   | `og:site_name`       | `publisher`        |\n\n## Extraction Priority\n\nWhen the same field appears in multiple schemas, prefer in this order:\n\n1. **JSON-LD / Schema.org** -- most structured and explicit\n2. **OpenGraph** -- widely adopted, usually curated by authors\n3. **Dublin Core** -- common in academic and institutional pages\n4. **HTML meta tags** -- fallback (`<title>`, `<meta name=\"description\">`)\n5. **Inferred from content** -- last resort (first `<h1>`, first paragraph)\n"
    },
    {
      "name": "normalization-rules.md",
      "path": "references/normalization-rules.md",
      "content": "# Normalization Rules Reference\n\nRules for transforming raw extracted metadata into the orchestrator's canonical schema.\n\n## Date Format Normalization\n\n**Target format:** ISO 8601 -- `YYYY-MM-DDTHH:mm:ssZ` (UTC preferred)\n\n| Input Pattern               | Example                      | Normalized Output         |\n|-----------------------------|------------------------------|---------------------------|\n| ISO 8601 with offset        | `2025-03-15T10:30:00+05:00`  | `2025-03-15T05:30:00Z`   |\n| ISO 8601 no timezone        | `2025-03-15T10:30:00`        | `2025-03-15T10:30:00Z` * |\n| Date only                   | `2025-03-15`                 | `2025-03-15T00:00:00Z`   |\n| US / EU slash format        | `03/15/2025`                 | `2025-03-15T00:00:00Z`   |\n| Long English                | `March 15, 2025`             | `2025-03-15T00:00:00Z`   |\n| Unix timestamp (sec/ms)     | `1710489000`                 | `2024-03-15T10:30:00Z`   |\n| Relative                    | `3 days ago`                 | Compute from current time |\n\n\\* Dates without timezone assume UTC. Flag `timezone_assumed: true` in extras.\n\n**Disambiguation:** For `01/02/2025`, prefer MM/DD for `.com` domains, DD/MM for `.co.uk`, `.de`, `.fr`. Use locale metadata if available. Flag `date_ambiguous: true` if unresolvable.\n\n**Validation:** Reject dates before `1990-01-01` or more than 1 day in the future. If `dateModified < datePublished`, swap and flag `dates_swapped: true`.\n\n## Language Code Mapping\n\n**Target:** ISO 639-1 two-letter codes, lowercase.\n\n| Input Variants                          | Normalized |\n|-----------------------------------------|------------|\n| `en`, `en-US`, `en_US`, `en-GB`, `eng` | `en`       |\n| `fr`, `fr-FR`, `fr_CA`, `fra`          | `fr`       |\n| `de`, `de-DE`, `de_AT`, `deu`          | `de`       |\n| `zh`, `zh-CN`, `zh_TW`, `zho`          | `zh`       |\n| `ja`, `ja-JP`, `jpn`                   | `ja`       |\n\nRules: Strip region subtags. Convert ISO 639-2/T three-letter codes. Lowercase. Map full language names to codes. Omit if unknown.\n\n## Content Type Taxonomy\n\n**Orchestrator canonical types** (closed vocabulary):\n\n| Content Type    | Description                      | Typical MIME Types             |\n|-----------------|----------------------------------|--------------------------------|\n| `article`       | Blog post, news, essay           | `text/html`                    |\n| `webpage`       | Generic web page                 | `text/html`                    |\n| `documentation` | Technical docs, API references   | `text/html`                    |\n| `tutorial`      | Step-by-step guide               | `text/html`                    |\n| `video`         | Video content                    | `video/*`                      |\n| `audio`         | Podcast, recording               | `audio/*`                      |\n| `repository`    | Source code repository           | --                             |\n| `issue`         | Bug report, feature request      | --                             |\n| `pull-request`  | Code review / merge request      | --                             |\n| `discussion`    | Forum thread, Q&A                | --                             |\n| `paper`         | Academic paper                   | `application/pdf`              |\n| `document`      | PDF, DOCX, general document      | `application/pdf`, `app/vnd.*` |\n| `dataset`       | Structured data file             | `text/csv`, `application/json` |\n| `software`      | Application or tool              | --                             |\n| `profile`       | Person or organization page      | --                             |\n| `image`         | Standalone image                 | `image/*`                      |\n| `api-doc`       | API specification                | `application/json`, `text/yaml`|\n| `other`         | Uncategorized                    | --                             |\n\n**Inference order:** Schema.org `@type` > `og:type` > URL patterns (`/docs/`, `/blog/`) > MIME type > defaults (`webpage` for HTML, `document` for PDF).\n\n## Author Name Normalization\n\n1. **Trim whitespace**, collapse multiple spaces.\n2. **Strip titles/suffixes:** `Dr.`, `Prof.`, `PhD`, `Jr.` -- store original in extras.\n3. **\"Last, First\" format:** convert `Doe, John` to `John Doe`.\n4. **Usernames:** Strip `@` prefix. Prefer display name over username when both available.\n5. **Deduplicate** case-insensitively across sources.\n6. **Organizations:** Keep as-is (e.g., `Google Developers`). Do not split.\n\n| Raw Input              | Normalized          |\n|------------------------|---------------------|\n| `  John   Doe  `      | `John Doe`          |\n| `Doe, John`            | `John Doe`          |\n| `@jdoe`               | `jdoe`              |\n| `Dr. Jane Smith, PhD` | `Jane Smith`        |\n\n## URL Canonicalization Rules\n\n1. **Enforce HTTPS** (unless site lacks support).\n2. **Lowercase hostname** (path case preserved).\n3. **Remove default ports** (`:443`, `:80`).\n4. **Remove trailing slash** (unless path is `/`).\n5. **Strip tracking params:** `utm_*`, `ref`, `fbclid`, `gclid`, `mc_cid`.\n6. **Remove fragment** unless SPA route (`#!/`).\n7. **Resolve shorteners:** `t.co`, `bit.ly`, `goo.gl` to final destination.\n8. **Prefer** `<link rel=\"canonical\">` over `og:url` over fetched URL.\n\n| Platform | Input                                  | Canonical                          |\n|----------|----------------------------------------|------------------------------------|\n| GitHub   | `github.com/owner/repo/tree/main`      | `github.com/owner/repo`            |\n| YouTube  | `youtu.be/dQw4w9WgXcQ`                | `youtube.com/watch?v=dQw4w9WgXcQ`  |\n| YouTube  | `youtube.com/watch?v=x&feature=shared` | `youtube.com/watch?v=x`            |\n\n## Conflict Resolution\n\n### Priority Order (highest to lowest)\n\n1. **Explicit structured data** -- JSON-LD, microdata\n2. **Platform API** -- GitHub API, YouTube API, etc.\n3. **OpenGraph meta tags**\n4. **Dublin Core meta tags**\n5. **HTML meta tags / DOM heuristics**\n6. **HTTP headers**\n\n### Field-Specific Rules\n\n- **Title:** Prefer shortest non-truncated version. Strip ` | Site Name` suffixes.\n- **Date:** Prefer the most specific value (datetime over date-only). Specificity overrides source priority.\n- **Author:** Merge unique authors from all sources. Order: structured data, OG, DOM.\n- **Description:** Prefer longest version up to 500 chars. OG descriptions preferred over auto-generated.\n- **URL:** `rel=canonical` wins.\n\nLog all conflict resolutions with chosen value, source, and rejected alternatives.\n"
    },
    {
      "name": "platform-extractors.md",
      "path": "references/platform-extractors.md",
      "content": "# Platform Extractors Reference\n\nPlatform-specific extraction patterns, selectors, and API endpoints for metadata extraction.\n\n## GitHub\n\n### Repository Metadata\n\n**API:** `GET /repos/{owner}/{repo}`\n\n| API Field          | Maps To         | Notes                 |\n|--------------------|-----------------|-----------------------|\n| `full_name`        | `title`         | `owner/repo` format   |\n| `description`      | `description`   |                       |\n| `owner.login`      | `author[0]`     | Repository owner      |\n| `created_at`       | `datePublished` | ISO 8601              |\n| `updated_at`       | `dateModified`  | ISO 8601              |\n| `topics`           | `tags`          | Merge with `language` |\n| `license.spdx_id`  | `license`       | SPDX identifier       |\n| `html_url`         | `sourceUrl`     |                       |\n\n### Issues and Pull Requests\n\n**APIs:** `GET /repos/{owner}/{repo}/issues/{number}`, `.../pulls/{number}`\n\nFields: `title`, `body` (truncate to 500), `user.login`, `created_at`, `updated_at`, `labels[].name`, `html_url`. Content type: `issue` or `pull-request`.\n\n### Discussions\n\n**GraphQL:** `repository.discussion(number)` -- fields: `title`, `body`, `author.login`, `createdAt`, `category.name`.\n\n### HTML Fallback (no API token)\n\n```\ntitle         -> meta[property=\"og:title\"] || .markdown-title\ndescription   -> meta[property=\"og:description\"]\nauthor        -> .author a (first match)\ndatePublished -> relative-time[datetime]\ntags          -> .topic-tag\n```\n\n## YouTube\n\n### Video Metadata\n\n**API:** `GET /youtube/v3/videos?part=snippet,contentDetails&id={videoId}`\n\n| API Field                     | Maps To         | Notes               |\n|-------------------------------|-----------------|----------------------|\n| `snippet.title`               | `title`         |                      |\n| `snippet.description`         | `description`   | Truncate to 500      |\n| `snippet.channelTitle`        | `author[0]`     |                      |\n| `snippet.publishedAt`         | `datePublished` | ISO 8601             |\n| `snippet.tags`                | `tags`          |                      |\n| `snippet.thumbnails.high.url` | `thumbnailUrl`  | Prefer high quality  |\n\nContent type: `video`. Channels (`/channels?part=snippet&id={id}`): content type `profile`.\n\n### HTML Fallback (no API key)\n\nYouTube embeds JSON-LD (`@type: VideoObject`) -- parse that first. Also: `meta[property=\"og:title\"]`, `meta[itemprop=\"datePublished\"]`, `meta[property=\"og:video:tag\"]`.\n\n## Medium / Dev.to\n\n### Medium\n\nNo public API. Extract from HTML meta tags and JSON-LD (`@type: NewsArticle`):\n\n```\ntitle         -> meta[property=\"og:title\"]\ndescription   -> meta[property=\"og:description\"]\nauthor        -> meta[name=\"author\"] || link[rel=\"author\"]\ndatePublished -> meta[property=\"article:published_time\"]\ntags          -> meta[property=\"article:tag\"] (multiple)\npublisher     -> \"Medium\"\n```\n\n### Dev.to\n\n**API:** `GET /api/articles/{id_or_slug}`\n\nFields: `title`, `description`, `user.name` (author), `published_at`, `edited_at`, `tag_list`, `cover_image`, `url`. Content type: `article`.\n\n## Documentation Sites\n\n### ReadTheDocs\n\n**URL pattern:** `https://{project}.readthedocs.io/en/{version}/{path}`\n**API:** `GET /api/v3/projects/{slug}/` (project name, description, language).\n\nSelectors: `h1:first-of-type` (title), `meta[name=\"description\"]`, `.last-updated` (dateModified). Content type: `documentation`.\n\n### GitBook\n\n**URL pattern:** `https://{org}.gitbook.io/{space}/{path}`\n\nRenders as SPA; prefer server-rendered meta tags: `og:title`, `og:description`, `og:image`, `og:site_name`. Content type: `documentation`.\n\n### Docusaurus\n\nBlog posts embed JSON-LD (`@type: BlogPosting`). Selectors: `meta[property=\"og:title\"]`, `.authorName` (blog), `time[datetime]` (blog), `.tag` (blog) or breadcrumbs (docs). Content type: `documentation` (docs) or `article` (blog).\n\n## General Fallback Strategy\n\nWhen platform-specific extraction fails, apply this cascade:\n\n1. **JSON-LD blocks** -- `<script type=\"application/ld+json\">`\n2. **OpenGraph meta** -- `meta[property^=\"og:\"]`\n3. **Twitter Card meta** -- `meta[name^=\"twitter:\"]`\n4. **Dublin Core meta** -- `meta[name^=\"dc.\"]` or `meta[name^=\"DC.\"]`\n5. **Standard HTML meta** -- `<title>`, `meta[name=\"description\"]`, `meta[name=\"author\"]`\n6. **DOM heuristics** -- first `<h1>`, first `<p>` with >100 chars, `<time>` elements\n7. **HTTP headers** -- `Last-Modified`, `Content-Language`, `Content-Type`\n\nCollect from all layers; higher-priority sources override lower ones during normalization (see normalization-rules.md).\n"
    },
    {
      "name": "structured-data-formats.md",
      "path": "references/structured-data-formats.md",
      "content": "# Structured Data Formats Reference\n\nParsing guides for JSON-LD, RDFa, microdata, and embedded file metadata.\n\n## JSON-LD Parsing Guide\n\nJSON-LD is the preferred structured data format. Found in `<script type=\"application/ld+json\">` blocks.\n\n### Extraction Steps\n\n1. Select all `<script type=\"application/ld+json\">` elements.\n2. Parse each as JSON. Skip malformed blocks.\n3. Handle single objects and `@graph` arrays.\n4. Match `@type` against known Schema.org types to find the primary entity.\n5. For `@graph`, find the node whose `@id` matches the page URL or has the most specific `@type`.\n\n### Example (single entity)\n\n```json\n{\n  \"@context\": \"https://schema.org\", \"@type\": \"Article\",\n  \"headline\": \"Understanding Metadata\",\n  \"author\": { \"@type\": \"Person\", \"name\": \"Jane Doe\" },\n  \"datePublished\": \"2025-03-15T10:00:00Z\",\n  \"publisher\": { \"@type\": \"Organization\", \"name\": \"Tech Blog\" }\n}\n```\n\nFor `@graph` patterns, prefer the most specific type: `BlogPosting` over `Article` over `WebPage`.\n\n### Author Forms\n\n| Form                                   | Extraction                    |\n|----------------------------------------|-------------------------------|\n| `\"author\": \"Jane Doe\"`                | Use string directly           |\n| `\"author\": { \"name\": \"Jane Doe\" }`    | Extract `name` property       |\n| `\"author\": [{ \"name\": \"Jane\" }, ...]` | Extract all `name` values     |\n| `\"author\": { \"@id\": \"#person1\" }`     | Resolve `@id` within `@graph` |\n\n### Edge Cases\n\n- **Multiple blocks:** Process all; extract from the content-bearing type (skip BreadcrumbList, Organization-only blocks).\n- **Nested objects:** Always check `publisher.name`, `author.name`, `image.url` before treating as strings.\n- **Missing `@context`:** Still parse; treat property names as Schema.org terms.\n- **`@type` arrays:** Use the most specific type from the array.\n\n## RDFa Extraction Patterns\n\nRDFa embeds structured data in HTML attributes: `vocab`, `typeof`, `property`, `resource`, `content`.\n\n### Extraction Steps\n\n1. Find elements with `typeof` to identify entity boundaries.\n2. Collect descendant elements with `property` attributes.\n3. Extract values from: `content` attribute (preferred), `href`/`src`, or text content.\n4. Map property names using the active `vocab` or `prefix` declarations.\n\n### Example\n\n```html\n<div vocab=\"https://schema.org/\" typeof=\"Article\">\n  <h1 property=\"headline\">Understanding RDFa</h1>\n  <span property=\"author\" typeof=\"Person\">\n    <span property=\"name\">Jane Doe</span>\n  </span>\n  <meta property=\"datePublished\" content=\"2025-03-15\" />\n</div>\n```\n\n## Microdata Extraction\n\nUses `itemscope`, `itemtype`, and `itemprop` attributes.\n\n### Extraction Steps\n\n1. Find elements with `itemscope` and `itemtype` (filter for `https://schema.org/` types).\n2. Collect descendant `itemprop` elements (stop at nested `itemscope` boundaries).\n3. Extract values by element type:\n\n| Element Type    | Value Source           |\n|-----------------|------------------------|\n| `<meta>`        | `content` attribute    |\n| `<a>`, `<link>` | `href` attribute       |\n| `<img>`         | `src` attribute        |\n| `<time>`        | `datetime` attribute   |\n| `<data>`        | `value` attribute      |\n| All others      | Text content (trimmed) |\n\nNested items (`itemprop` + `itemscope`): extract the nested item's properties and associate with the parent property.\n\n## Embedded File Metadata\n\n### PDF Properties\n\nExtract from the document info dictionary using a PDF library (`pdf-parse`, `pdfjs-dist`).\n\n| PDF Property   | Maps To         | Notes                                 |\n|----------------|-----------------|---------------------------------------|\n| `Title`        | `title`         |                                       |\n| `Author`       | `author`        | May be semicolon-separated            |\n| `Subject`      | `description`   |                                       |\n| `Keywords`     | `tags`          | Comma or semicolon-separated          |\n| `CreationDate` | `datePublished` | Format: `D:YYYYMMDDHHmmssOHH'mm'`    |\n| `ModDate`      | `dateModified`  | Same format                           |\n\n### DOCX Metadata\n\nExtract from `docProps/core.xml` inside the ZIP archive. Uses Dublin Core elements: `dc:title`, `dc:creator`, `dc:description`, `dc:subject`, `dcterms:created`, `dcterms:modified`, `cp:keywords`.\n\n### Image EXIF Headers\n\nExtract using an EXIF library (`exif-reader`, `sharp`).\n\n| EXIF Tag              | Maps To         | Notes                              |\n|-----------------------|-----------------|------------------------------------|\n| `ImageDescription`    | `description`   |                                    |\n| `Artist`              | `author`        |                                    |\n| `Copyright`           | `license`       | Free-text copyright                |\n| `DateTimeOriginal`    | `datePublished` | Format: `YYYY:MM:DD HH:mm:ss`     |\n| `DateTime`            | `dateModified`  | Replace first two `:` with `-`     |\n| `GPSLatitude/Long`    | extras.geo      | Convert DMS to decimal             |\n\n## Parsing Priority Order\n\n| Priority | Format        | Rationale                                          |\n|----------|---------------|----------------------------------------------------|\n| 1        | JSON-LD       | Most explicit; not mixed with presentation markup  |\n| 2        | Microdata     | Clear attribute contracts in HTML                  |\n| 3        | RDFa          | Similar to microdata, less common on modern sites  |\n| 4        | Meta tags     | OpenGraph, Twitter Cards, Dublin Core              |\n| 5        | File-embedded | PDF, DOCX, EXIF -- only for non-HTML resources     |\n\n**Merge strategy:** Extract from all formats. Higher-priority sources provide primary values. Fill missing fields from lower-priority sources. Log all contributing sources for provenance.\n\n**Date exception:** Specificity overrides source priority. If JSON-LD has `2025-03-15` but OG has `2025-03-15T10:30:00Z`, prefer the OG value. See normalization-rules.md for full conflict resolution.\n"
    }
  ],
  "tags": [
    "meta",
    "analysis",
    "utilities",
    "parsing"
  ],
  "dependsOn": []
}